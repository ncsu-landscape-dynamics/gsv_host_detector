{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90233a93-8670-4ebd-9fc2-39807c29b341",
   "metadata": {},
   "source": [
    "# Setup, Training, and Evaluating CNNs for Tree Genera Classification\n",
    "\n",
    "The following Jupyter Notebook includes code to setup and train a convolutional neural network with Python and Pytorch.\n",
    "\n",
    "Version: April 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f37d09-22ad-4965-89ea-63af7fae1da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports for Pytorch\n",
    "import torch # version 2.1.2\n",
    "import torchvision # version 0.16.2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn # contains base class for all neural network modules\n",
    "import torch.nn.functional as F #https://pytorch.org/docs/stable/nn.functional.html contains common functions for training NNs (convolutions, losses, etc..)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Image processing and display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "# Other Imports\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a698887d",
   "metadata": {},
   "source": [
    "## Setup new testing and training datasets, save their metadata as csvs, and print number of images to console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a43c91-ae82-44a0-a622-baa3d2490ed9",
   "metadata": {},
   "source": [
    "### Functions to create new testing and training datasets, export metadata, and print number of images to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6fbfe-b7d0-46c3-9481-9f217c19a612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Functions to create datasets for training and testing, export metadata to csv, and print directory information\n",
    "# Function to export metadata to csv\n",
    "def process_existing_files(root_directory, csv_path, export_csv=False):\n",
    "    \"\"\"\n",
    "    Process existing files in the root directory and write to csv.\n",
    "\n",
    "    Parameters:\n",
    "    root_directory (str): The path to the root directory containing images of tree genera.\n",
    "\n",
    "    Returns:\n",
    "    Print statement with the file path to the csv.\n",
    "    \"\"\"\n",
    "    existing_files = {}\n",
    "\n",
    "    # Get the list of genus names from the root directory\n",
    "    genera = os.listdir(root_directory)\n",
    "\n",
    "    for genus in genera:\n",
    "        genus_dir = os.path.join(root_directory, genus)\n",
    "        genus_files = os.listdir(genus_dir)\n",
    "        existing_files[genus] = genus_files\n",
    "\n",
    "    # Create a dataframe from the dictionary\n",
    "    df = pd.DataFrame(existing_files.items(), columns=['genus', 'files'])\n",
    "    df = df.explode('files')\n",
    "\n",
    "    # Add additional column for data source\n",
    "    if \"inat\" in root_directory.lower():\n",
    "        df['data_source'] = \"iNaturalist\"\n",
    "    else:\n",
    "        df['data_source'] = \"Autoarborist\"\n",
    "    \n",
    "    if export_csv:\n",
    "        # Write to csv\n",
    "        csv_filepath = os.path.join(csv_path, os.path.basename(root_directory) + \".csv\")\n",
    "        df.to_csv(csv_filepath, index=False)\n",
    "        print(f\"Existing files for {root_directory} written to csv.\")\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "# Function to print directory information\n",
    "def print_directory_info(root_directory):\n",
    "    \"\"\"\n",
    "    Print the number of files in each directory in the root directory.\n",
    "\n",
    "    Parameters:\n",
    "    root_directory (str): The path to the root directory containing images of tree genera.\n",
    "\n",
    "    Returns:\n",
    "    Print statement with the number of files in each directory.\n",
    "    \"\"\"\n",
    "    for genus_folder in os.listdir(root_directory):\n",
    "        genus_path = os.path.join(root_directory, genus_folder)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(genus_path):\n",
    "            # Count the number of files in the directory\n",
    "            num_files = len([f for f in os.listdir(genus_path) if os.path.isfile(os.path.join(genus_path, f))])\n",
    "            \n",
    "            print(f\"Directory: {genus_folder}, Number of Files: {num_files}\")\n",
    "    return None\n",
    "\n",
    "# Function to create datasets for training and testing: Autoarborist or iNaturalist\n",
    "def create_datasets (training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root, \n",
    "                     training_destination_root, existing_training_root, existing_testing_root, append, csv_path):\n",
    "    \"\"\"\n",
    "    Create training and testing datasets for selected genera from any source image dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    training_ratio (float): The ratio of training images to total images.\n",
    "    max_training_images_og (int): The maximum number of training images to select.\n",
    "    max_testing_images_og (int): The maximum number of testing images to select.\n",
    "    selected_genera (list): The list of selected genera to include in the training and testing datasets.\n",
    "    source_root (str): The path to the source directory containing all available images of tree genera from Autoarborist.\n",
    "    testing_destination_root (str): The path to the destination directory for images of tree genera as testing data.\n",
    "    training_destination_root (str): The path to the destination directory for images of tree genera as training data.\n",
    "    existing_training_root (str): The path to the existing directory containing images of tree genera as training data used in previous experiments.\n",
    "    existing_testing_root (str): The path to the existing directory containing images of tree genera as testing data used in previous experiments.\n",
    "    append (bool): A logical statement to append new images to existing training and testing data.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Iterate through the source directory\n",
    "    for genus_folder in os.listdir(source_root):\n",
    "        max_training_images = max_training_images_og\n",
    "        max_testing_images = max_testing_images_og\n",
    "        # Keep track of starting time\n",
    "        start_time = time.time()\n",
    "        genus_path = os.path.join(source_root, genus_folder) # Get path to images for each genera\n",
    "    \n",
    "        # List all images in the current genus folder. Some images are .jpg and .jpeg format.\n",
    "        # If \"inat\" is found anywhere in the genus folder name, then the images are in the root folder.\n",
    "        if \"inat\" in genus_path.lower():\n",
    "            images = [image for image in os.listdir(genus_path) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        else:\n",
    "            images = [image for image in os.listdir(os.path.join(genus_path, 'images')) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        # Only select genera with >100 images.\n",
    "        if len(images) > 100:\n",
    "            # Check if it's a directory and if it's in the selected genera list\n",
    "            if os.path.isdir(genus_path) and genus_folder in selected_genera:\n",
    "                # Create destination folders for the training and testing data for the current genus\n",
    "                training_destination_genus_path = os.path.join(training_destination_root, genus_folder)\n",
    "                testing_destination_genus_path = os.path.join(testing_destination_root, genus_folder)\n",
    "                os.makedirs(training_destination_genus_path, exist_ok=True)\n",
    "                os.makedirs(testing_destination_genus_path, exist_ok=True)\n",
    "                # Append new images to existing training and testing data\n",
    "                if append:\n",
    "                    print(f\"Copying existing images for {genus_folder} to new training and testing folders.\")\n",
    "                    existing_training_genus_path = os.path.join(existing_training_root, genus_folder)\n",
    "                    existing_testing_genus_path = os.path.join(existing_testing_root, genus_folder)\n",
    "\n",
    "                    # Copy existing training images to the new training destination folder\n",
    "                    for image in os.listdir(existing_training_genus_path):\n",
    "                        source_image_path = os.path.join(existing_training_genus_path, image)\n",
    "                        destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                        _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                    # Copy existing testing images to the new testing destination folder\n",
    "                    for image in os.listdir(existing_testing_genus_path):\n",
    "                        source_image_path = os.path.join(existing_testing_genus_path, image)\n",
    "                        destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                        _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                    # Update the max_training_images and max_testing_images\n",
    "                    max_training_images = max_training_images - len(os.listdir(existing_training_genus_path))\n",
    "                    max_testing_images = max_testing_images - len(os.listdir(existing_testing_genus_path))\n",
    "                    print(f\"Updated max_training_images: {max_training_images}, max_testing_images: {max_testing_images}\")\n",
    "\n",
    "                    # Update images to exclude the existing training and testing images\n",
    "                    print(f\"Total number of available images: {len(images)} for {genus_folder}...\")\n",
    "                    existing_training_images = set(os.listdir(existing_training_genus_path))\n",
    "                    existing_testing_images = set(os.listdir(existing_testing_genus_path))\n",
    "                    images = [image for image in images if image not in existing_training_images and image not in existing_testing_images]\n",
    "                    print(f\"Total number of images after excluding existing training and testing images: {len(images)} for {genus_folder}...\")\n",
    "\n",
    "                # Randomly select a number of images from the folder here: (900 training + 100 testing).\n",
    "                if len(images) > max_training_images + max_testing_images:\n",
    "                    images = random.sample(images, max_training_images + max_testing_images) # file paths for images\n",
    "\n",
    "                # Randomly divide images into training and testing sets\n",
    "                num_total_images = len(images)\n",
    "                num_training_images_to_copy = min(int(num_total_images * training_ratio), max_training_images)\n",
    "\n",
    "                # Randomly shuffle the images before moving\n",
    "                random.shuffle(images)\n",
    "\n",
    "                # Split images into training and testing sets\n",
    "                training_images = images[:num_training_images_to_copy]\n",
    "                testing_images = images[num_training_images_to_copy:]\n",
    "            \n",
    "                # Copy training images to the training destination folder\n",
    "                print(f\"Copying new images for {genus_folder} to new training and testing folders.\")\n",
    "                for image in training_images:\n",
    "                    if \"inat\" in genus_path.lower():\n",
    "                        source_image_path = os.path.join(genus_path, image)\n",
    "                    else:\n",
    "                        source_image_path = os.path.join(genus_path, 'images', image)\n",
    "                    destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                # Copy testing images to the testing destination folder\n",
    "                for image in testing_images:\n",
    "                    if \"inat\" in genus_path.lower():\n",
    "                        source_image_path = os.path.join(genus_path, image)\n",
    "                    else:\n",
    "                        source_image_path = os.path.join(genus_path, 'images', image)\n",
    "                    destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "                # Keep track of ending time\n",
    "                end_time = time.time()\n",
    "                # Report time take in minutes\n",
    "                total_time = (end_time - start_time) / 60\n",
    "                print(f\"Images copied successfully for {genus_folder}. Time taken: {total_time} minutes.\")\n",
    "    print(f\"All images copied successfully for: {selected_genera}.\")\n",
    "    process_existing_files(training_destination_root, csv_path, export_csv=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Function to combine existing training and testing data\n",
    "\n",
    "def combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root):\n",
    "    \"\"\"\n",
    "    Combine the training datasets from Autoarborist and iNaturalist into a single testing or training dataset.\n",
    "    Combine the testing datasets from Autoarborist and iNaturalist into a single testing or training dataset.\n",
    "    Combine the metadata from Autoarborist and iNaturalist into a single metadata file.\n",
    "\n",
    "    Parameters:\n",
    "    autoarborist_dataset_root (str): The path to the Autoarborist testing or training dataset.\n",
    "    inaturalist_dataset_root (str): The path to the iNaturalist testing or training dataset.\n",
    "    combined_dataset_root (str): The path to the combined testing or training dataset.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create the combined training dataset directory\n",
    "    os.makedirs(combined_dataset_root, exist_ok=True)\n",
    "\n",
    "    # Copy the Autoarborist dataset to the combined dataset\n",
    "    for genus_folder in os.listdir(autoarborist_dataset_root):\n",
    "        genus_path = os.path.join(autoarborist_dataset_root, genus_folder)\n",
    "        destination_genus_path = os.path.join(combined_dataset_root, genus_folder)\n",
    "        os.makedirs(destination_genus_path, exist_ok=True)\n",
    "        print(f\"Copying Autoarborist images for {genus_folder} to the combined dataset.\")\n",
    "\n",
    "        for image in os.listdir(genus_path):\n",
    "            source_image_path = os.path.join(genus_path, image)\n",
    "            destination_image_path = os.path.join(destination_genus_path, image)\n",
    "            _= shutil.copy2(source_image_path, destination_image_path)\n",
    "        \n",
    "    \n",
    "    # Copy the iNaturalist dataset to the training dataset\n",
    "    for genus_folder in os.listdir(inaturalist_dataset_root):\n",
    "        genus_path = os.path.join(inaturalist_dataset_root, genus_folder)\n",
    "        destination_genus_path = os.path.join(combined_dataset_root, genus_folder)\n",
    "        os.makedirs(destination_genus_path, exist_ok=True)\n",
    "        print(f\"Copying iNaturalist images for {genus_folder} to the combined dataset.\")\n",
    "\n",
    "        for image in os.listdir(genus_path):\n",
    "            source_image_path = os.path.join(genus_path, image)\n",
    "            destination_image_path = os.path.join(destination_genus_path, image)\n",
    "            _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "    print(f\"Combined dataset created successfully.\")\n",
    "\n",
    "    # Combine the autoarborist_root, inaturalist_root, and combined_root metadata\n",
    "    roots = [autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root]\n",
    "    updated_roots = [os.path.join(os.path.join(root.rsplit('\\\\', 1)[0], os.path.basename(root) + \".csv\")) for root in roots]\n",
    "    \n",
    "    # Pull in the existing metadata for autoarborist\n",
    "    autoarborist_metadata = pd.read_csv(updated_roots[0])\n",
    "    # Pull in the existing metadata for inaturalist\n",
    "    inaturalist_metadata = pd.read_csv(updated_roots[1])\n",
    "    # Combine the metadata\n",
    "    combined_metadata = pd.concat([autoarborist_metadata, inaturalist_metadata], ignore_index=True)\n",
    "    # Write to csv\n",
    "    combined_metadata.to_csv(updated_roots[2], index=False)\n",
    "    print(f\"Combined metadata written to csv.\")\n",
    "    return None\n",
    "\n",
    "# Constants\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','fraxinus','gleditsia','juglans','juniperus', 'magnolia','phoenix','picea',\n",
    "                   'pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium', 'thuja','tilia','ulmus','washingtonia']\n",
    "training_ratio = 0.9 # ratio of training images to total images\n",
    "max_training_images_og = 1187 # maximum number of training images to select\n",
    "max_testing_images_og = 132 # maximum number of testing images to select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe88f9",
   "metadata": {},
   "source": [
    "### Autoarborist: Source, append, and create new testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5070c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: contains all available street view images of tree genera from Autoarborist\n",
    "source_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\autoarborist_original_data\\autoarborist_original_jpegs\\jpegs_streetlevel_genus_idx_label\"\n",
    "\n",
    "# Target: location for images of tree genera as training data \n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_apr624\"\n",
    "\n",
    "# Target: location for images of tree genera as testing data \n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as training data used in previous experiments\n",
    "existing_training_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_march624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as testing data used in previous experiments\n",
    "existing_testing_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_march624\"\n",
    "\n",
    "# Append: logical statement to append new images to existing training and testing data\n",
    "append = True\n",
    "\n",
    "# CSV path: location to save the CSV file containing the training and testing data\n",
    "csv_path = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\"\n",
    "\n",
    "# Select all genera\n",
    "#selected_genera = os.listdir(source_root)\n",
    "# create_datasets(training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root,\n",
    "#                     training_destination_root, existing_training_root, existing_testing_root, append)\n",
    "\n",
    "# Export metadata for existing training and testing data\n",
    "process_existing_files(training_destination_root, csv_path, export_csv=True)\n",
    "process_existing_files(testing_destination_root, csv_path, export_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1099f",
   "metadata": {},
   "source": [
    "### Autoarborist: Print the number of images for the new training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c99d6-6169-4053-933c-601f72b02f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc72c8",
   "metadata": {},
   "source": [
    "### iNaturalist: Source, append, and create new testing and training datasets for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3afcf1-3e9f-4c50-b543-ba359c2e04a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the paths for Autoarborist training and testing data\n",
    "\n",
    "# Source: contains all available street view images of tree genera from iNaturalist\n",
    "source_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inat\\images\\original_10k\"\n",
    "\n",
    "# Target: location for images of tree genera as training data \n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_apr624\"\n",
    "\n",
    "# Target: location for images of tree genera as testing data \n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as training data used in previous experiments\n",
    "existing_training_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as testing data used in previous experiments\n",
    "existing_testing_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Append: logical statement to append new images to existing training and testing data\n",
    "append = True\n",
    "\n",
    "# CSV path: location to save the CSV file containing the training and testing data\n",
    "csv_path = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\"\n",
    "\n",
    "# Select all genera\n",
    "selected_genera = os.listdir(source_root)\n",
    "create_datasets(training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root,\n",
    "                    training_destination_root, existing_training_root, existing_testing_root, append,csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9a9fa",
   "metadata": {},
   "source": [
    "### iNaturalist: Print the number of images for the new training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c596c9e",
   "metadata": {},
   "source": [
    "### Autoarborist + iNaturalist: Combine Training and Testing Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e80829-11c0-4fe9-8280-cbd3a30ceaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the training datasets\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_apr624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_apr624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\training_dataset_small_apr624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_apr624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_apr624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE CODE CHUNK AFTER PROCESSING\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_march624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_march624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\training_dataset_small_march624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_march624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_march624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\testing_dataset_small_march624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1664a",
   "metadata": {},
   "source": [
    "### Autoarborist + iNaturalist: Print the number of images for the new training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d30909",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\training_dataset_small_apr624\"\n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62102bfd",
   "metadata": {},
   "source": [
    "## Setup EfficientNetv2 model to run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ebf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to prepare a Basic Model for Image Classification\n",
    "\n",
    "class ImageClassificationBase(nn.Module): # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
    "    # Define a base class with functionality for model training, validation, and evaluation per epoch\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels) # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# Functions to define a CNN Model using EfficientNetV2-S\n",
    "\n",
    "class EfficientNetImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained EfficientNetV2-L Model\n",
    "        self.network = torchvision.models.efficientnet_v2_s(pretrained=True)\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = len(train_dataset.classes)\n",
    "        in_features = self.network.classifier[1].in_features\n",
    "        self.network.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "# Functions  to visualize training data\n",
    "def display_img(img,label):\n",
    "    print(f\"Label : {train_dataset.classes[label]}\")\n",
    "    plt.imshow(img.permute(1,2,0)) #reshape image from (3, H, W) to (H, W, 3)\n",
    "\n",
    "def show_batch(dl):\n",
    "    \"\"\"Plot images grid of single batch\"\"\"\n",
    "    for images, labels in dl:\n",
    "        fig,ax = plt.subplots(figsize = (16,12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n",
    "        break\n",
    "\n",
    "# Functions to define GPU device and load data to GPU\n",
    "def get_default_device():\n",
    "    \"\"\" Set Device to GPU or CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"Move data to the device\"\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking = True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n",
    "    \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\" Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches \"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "# Functions to define training and evaluation functions\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "# Fit model\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    # Create optimizer with initial learning rate\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        print(f\"Starting epoch {epoch+1}\")\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Forward pass: prediction & calculate loss\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            # Backward pass: backpropagate loss & calculate gradients\n",
    "            loss.backward()\n",
    "            optimizer.step() #update gradients\n",
    "            optimizer.zero_grad() #zero gradients for next training forward pass\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        end = time.time()\n",
    "        total = end-start/60\n",
    "        print(f\"Time taken for epoch {epoch+1}: {total} minutes\")\n",
    "        \n",
    "    return history\n",
    "\n",
    "# Functions to visualize the results\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "    # Reduce plot margins\n",
    "    plt.autoscale()\n",
    "    plt.margins(0.2)\n",
    "    plt.show()\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "    # Reduce plot margins\n",
    "    plt.autoscale()\n",
    "    plt.margins(0.2)\n",
    "    plt.show()\n",
    "\n",
    "# Constant variables: number of epochs, optimizer function, learning rate, and warmup epochs\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','cupaniopsis','erythrina','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "base_lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6891a53",
   "metadata": {},
   "source": [
    "### Experiment 1: The effect of decreased resolution (512x512) on CNN image classification performance.\n",
    "\n",
    "Hypothesis: decreased resolution will result in decreased performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b92ec",
   "metadata": {},
   "source": [
    "#### Define Image Augumentations - Update paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0358319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the training and testing datasets (AutoArborist, iNaturalist, or combined) by specifying the file paths.\n",
    "training_destination_root = r\"D:\\blaginh\\tree_classification\\aa_inat_combined\\training_dataset_small_march624\"\n",
    "testing_destination_root = r\"D:\\blaginh\\tree_classification\\aa_inat_combined\\testing_dataset_small_march624\"\n",
    "testing_destination_root_aa = r\"D:\\blaginh\\tree_classification\\autoarborist\\testing_dataset_small_march624\"\n",
    "testing_destination_root_inat = r\"D:\\blaginh\\tree_classification\\inat\\testing_dataset_small_march624\"\n",
    "\n",
    "# Use Pytorch ImageFolder class to prepare training and testing datasets\n",
    "train_data_dir = training_destination_root\n",
    "test_data_dir = testing_destination_root\n",
    "test_data_dir_aa = testing_destination_root_aa\n",
    "test_data_dir_inat = testing_destination_root_inat\n",
    "\n",
    "# Load the training and testing datasets as Pytorch Dataset Classes: https://pytorch.org/docs/stable/data.html\n",
    "# The Pytorch torchvision.transforms module provides preprocessing functions: https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    #v2.RandomResizedCrop(size=(512, 512), antialias=True),\n",
    "    v2.RandomResizedCrop(size=(256, 256), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Ensure images are resized during testing as same dimension for training\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    #v2.Resize(size=(512, 512), antialias=True),\n",
    "    v2.Resize(size=(256, 256), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(train_data_dir, transform = train_transforms)\n",
    "test_dataset = ImageFolder(test_data_dir, transform = test_transforms)\n",
    "test_dataset_aa = ImageFolder(test_data_dir_aa, transform = test_transforms)\n",
    "test_dataset_inat = ImageFolder(test_data_dir_inat, transform = test_transforms)\n",
    "\n",
    "# Examine the train_dataset object\n",
    "train_dataset\n",
    "\n",
    "# Examine image dimensions: (3 channels, height 64, width 64)\n",
    "img, label = train_dataset[0]\n",
    "print(img.shape,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b78453",
   "metadata": {},
   "source": [
    "#### Define training, validation, and testing data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe26fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into a validation set, and prepare dataset for training\n",
    "\n",
    "# Define batch size for training \n",
    "bs = 32\n",
    "\n",
    "# Define number of images for validation (typically, 10% of the training set)\n",
    "val_size = 2000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "# Randomly split training data into train_data and val_data sets\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Length of Train Data : {len(train_data)}\") # Length of Train Data : 20000\n",
    "print(f\"Length of Validation Data : {len(val_data)}\") # Length of Validation Data : 2000\n",
    "\n",
    "# Use Pytorch DataLoader Class to iterate over a dataset for training: https://pytorch.org/docs/stable/data\n",
    "\n",
    "train_dl = DataLoader(dataset = train_data, batch_size = bs, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(dataset = val_data, batch_size = bs*2, num_workers = 4, pin_memory = True)\n",
    "test_dl = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 4, pin_memory = True)\n",
    "test_dl_aa = DataLoader(dataset = test_dataset_aa, batch_size = 1, num_workers = 4, pin_memory = True)\n",
    "test_dl_inat = DataLoader(dataset = test_dataset_inat, batch_size = 1, num_workers = 4, pin_memory = True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = EfficientNetImageClassification()\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f'Number of Model Parameters: ', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1411ca9",
   "metadata": {},
   "source": [
    "#### Print number of classes in train and test datasets, and visualize sample image and single batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many classes are in the training and testing datasets?\n",
    "print(\"Classes in the Training Dataset : /n\", len(train_dataset.classes))\n",
    "print(\"Classes in the Testing Dataset : /n\", len(test_dataset.classes))\n",
    "print(\"Classes in the Testing Dataset (Autoarborist Only) : /n\", len(test_dataset_aa.classes))\n",
    "\n",
    "# Display the first image in the dataset\n",
    "display_img(*train_dataset[2])\n",
    "\n",
    "# Visualize a single batch of images\n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae4680",
   "metadata": {},
   "source": [
    "#### Load data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GPU Device\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Load data to GPU\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)\n",
    "\n",
    "# Load the model to the GPU\n",
    "model = to_device(EfficientNetImageClassification(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028331b",
   "metadata": {},
   "source": [
    "#### Fit and Save Model & Model History - update paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee900cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and record result after epoch\n",
    "# Model history contains training loss, validation loss, and validation accuracy metrics\n",
    "history = fit(num_epochs, base_lr, model, train_dl, val_dl, opt_func)\n",
    "\n",
    "# Save the model weights file to path\n",
    "model_path = r'D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\tree-classification-autoarb_inat-25-genera-1000imgs-effnet2s-10epochs-lr001-aug-apr1124.pth'\n",
    "\n",
    "# Torch.Save model to file: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "#export the model history to a csv file\n",
    "history_path = r'D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\tree-classification-autoarb_inat-25-genera-1000imgs-effnet2s-10epochs-lr001-aug-apr1124.csv'\n",
    "history_df = pd.DataFrame(history)\n",
    "#add column for epoch\n",
    "history_df['epoch'] = history_df.index + 1\n",
    "history_df.to_csv(history_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70248",
   "metadata": {},
   "source": [
    "#### Visualize model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6789f",
   "metadata": {},
   "source": [
    "##### Accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model_path = r'D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\\\tree-classification-autoarb_inat-25-genera-1000imgs-effnet2s-10epochs-lr001-aug-apr1124.pth'\n",
    "\n",
    "# Get GPU Device\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Instantiate the model with the same architecture as the model which parameters you saved\n",
    "model = EfficientNetImageClassification()\n",
    "\n",
    "#load the model to the device\n",
    "model = to_device(EfficientNetImageClassification(), device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval() # Call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24cf5d",
   "metadata": {},
   "source": [
    "##### Confusion Matrix: All Images (Autoarborist & iNaturalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation with Confusion Matrix\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(output, dim=1).cpu().numpy()  # Extract predicted labels directly\n",
    "        y_pred.extend(output)\n",
    "        \n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=selected_genera)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "plt.savefig(r\"D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\exp1_confusion_matrix_all.png\", dpi=200)\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4fb0",
   "metadata": {},
   "source": [
    "##### Precision, recall, F1, support per class: All Images (Autoarborist & iNaturalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names = selected_genera))\n",
    "\n",
    "# Export classification report to csv\n",
    "report_data = classification_report(y_true, y_pred, target_names = selected_genera, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "report_df.to_csv(r\"D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\exp1_classification_report_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7acc3",
   "metadata": {},
   "source": [
    "##### Confusion Matrix: All Images (Autoarborist Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d94d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation with Confusion Matrix\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl_aa:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(output, dim=1).cpu().numpy()  # Extract predicted labels directly\n",
    "        y_pred.extend(output)\n",
    "        \n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=selected_genera)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "plt.savefig(r\"D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\exp1_confusion_matrix_aaonly.png\", dpi=200)\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09d12a",
   "metadata": {},
   "source": [
    "##### Precision, recall, F1, support per class: All Images (Autoarborist only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52eb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names = selected_genera))\n",
    "\n",
    "# Export classification report to csv\n",
    "report_data = classification_report(y_true, y_pred, target_names = selected_genera, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "report_df.to_csv(r\"D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\exp1_classification_report_aaonly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0b166",
   "metadata": {},
   "source": [
    "##### Confusion Matrix: All Images (iNaturalist Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation with Confusion Matrix\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl_inat:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(output, dim=1).cpu().numpy()  # Extract predicted labels directly\n",
    "        y_pred.extend(output)\n",
    "        \n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=selected_genera)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "plt.savefig(r\"D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\exp1_confusion_matrix_inatonly.png\", dpi=200)\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72073ad",
   "metadata": {},
   "source": [
    "##### Precision, recall, F1, support per class: All Images (iNaturalist only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81834820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names = selected_genera))\n",
    "\n",
    "# Export classification report to csv\n",
    "report_data = classification_report(y_true, y_pred, target_names = selected_genera, output_dict=True)\n",
    "report_df = pd.DataFrame(report_data).transpose()\n",
    "report_df.to_csv(r\"D:\\blaginh\\tree_classification\\model_outputs\\exp1_reduced_res\\exp1_classification_report_inatonly.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
