{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90233a93-8670-4ebd-9fc2-39807c29b341",
   "metadata": {},
   "source": [
    "# Setup and Training CNNs for Tree Genera Classification\n",
    "\n",
    "The following Jupyter Notebook includes code to setup and train a convolutional neural network with Python and Pytorch.\n",
    "\n",
    "Version: April 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34f37d09-22ad-4965-89ea-63af7fae1da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports for Pytorch\n",
    "import torch # version 2.1.2\n",
    "import torchvision # version 0.16.2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Image processing and display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Other Imports\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a43c91-ae82-44a0-a622-baa3d2490ed9",
   "metadata": {},
   "source": [
    "## Setup Training and Testing Data for AutoArborist Images\n",
    "\n",
    "Define Source and Target Directories for Training and Testing Datasets From AutoArborist Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f3afcf1-3e9f-4c50-b543-ba359c2e04a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the paths for Autoarborist training and testing data\n",
    "\n",
    "# Source: contains all available street view images of tree genera from Autoarborist\n",
    "source_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\autoarborist_original_data\\autoarborist_original_jpegs\\jpegs_streetlevel_genus_idx_label\"\n",
    "\n",
    "# Target: location for images of tree genera as training data \n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_10thp_apr624\"\n",
    "\n",
    "# Target: location for images of tree genera as testing data \n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_10thp_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as training data used in previous experiments\n",
    "existing_training_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_march624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as testing data used in previous experiments\n",
    "existing_testing_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_march624\"\n",
    "\n",
    "# Append: logical statement to append new images to existing training and testing data\n",
    "append = True\n",
    "\n",
    "# CSV path: location to save the CSV file containing the training and testing data\n",
    "csv_path = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41f8dd-fd01-4bb5-bdc5-e99c6c269d9a",
   "metadata": {},
   "source": [
    "### Create a directory with folders named for each class, using the PyTorch ImageFolder Class\n",
    "\n",
    "https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abb6fbfe-b7d0-46c3-9481-9f217c19a612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images for acer...\n",
      "Copying existing images for acer... to new training and testing folders.\n",
      "Updated max_training_images: 1350, max_testing_images: 150\n",
      "Total number of available images: 82051 for acer...\n",
      "Total number of images after excluding existing training and testing images: 81051 for acer...\n",
      "Copying 1350 training images for acer...\n",
      "Copying 150 testing images for acer...\n",
      "Images copied successfully for acer. Time taken: 3.804543137550354 minutes.\n",
      "Processing images for ailanthus...\n",
      "Copying existing images for ailanthus... to new training and testing folders.\n",
      "Updated max_training_images: 1350, max_testing_images: 150\n",
      "Total number of available images: 3723 for ailanthus...\n",
      "Total number of images after excluding existing training and testing images: 2723 for ailanthus...\n",
      "Copying 1350 training images for ailanthus...\n",
      "Copying 150 testing images for ailanthus...\n",
      "Images copied successfully for ailanthus. Time taken: 2.947280395030975 minutes.\n",
      "Processing images for betula...\n",
      "Copying existing images for betula... to new training and testing folders.\n",
      "Updated max_training_images: 1350, max_testing_images: 150\n",
      "Total number of available images: 13161 for betula...\n",
      "Total number of images after excluding existing training and testing images: 12161 for betula...\n",
      "Copying 1350 training images for betula...\n",
      "Copying 150 testing images for betula...\n",
      "Images copied successfully for betula. Time taken: 3.5638782143592835 minutes.\n",
      "Processing images for citrus...\n",
      "Copying existing images for citrus... to new training and testing folders.\n",
      "Updated max_training_images: 1350, max_testing_images: 150\n",
      "Total number of available images: 2299 for citrus...\n",
      "Total number of images after excluding existing training and testing images: 1299 for citrus...\n",
      "Copying 1169 training images for citrus...\n",
      "Copying 130 testing images for citrus...\n",
      "Images copied successfully for citrus. Time taken: 2.9362401564915976 minutes.\n",
      "Processing images for fraxinus...\n",
      "Copying existing images for fraxinus... to new training and testing folders.\n"
     ]
    }
   ],
   "source": [
    "# Create a directory of images with folders named for each class, using the PyTorch ImageFolder Class\n",
    "# https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n",
    "# Each directory should contain a set of images labelled to genus\n",
    "\n",
    "# Ratio of training to testing images\n",
    "training_ratio = 0.9\n",
    "testing_ratio = 0.1\n",
    "\n",
    "# Maximum number of images for training and testing\n",
    "max_training_images_reset = 2250\n",
    "max_testing_images_reset = 250\n",
    "\n",
    "# Dictionary to keep track of selected training images for each genus\n",
    "selected_training_images = {}\n",
    "\n",
    "# Selected set of genera\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "\n",
    "# Select all genera\n",
    "#selected_genera = os.listdir(source_root)\n",
    "\n",
    "# Iterate through the source directory\n",
    "for genus_folder in os.listdir(source_root):\n",
    "    max_training_images = max_training_images_reset\n",
    "    max_testing_images = max_testing_images_reset\n",
    "    # Keep track of starting time\n",
    "    start_time = time.time()\n",
    "    genus_path = os.path.join(source_root, genus_folder) # Get path to images for each genera\n",
    "    \n",
    "    # List all images in the current genus folder. Some images are .jpg and .jpeg foramt.\n",
    "    images = [image for image in os.listdir(os.path.join(genus_path, 'images')) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Only select genera with >100 images.\n",
    "    if len(images) > 100:\n",
    "        # Check if it's a directory and if it's in the selected genera list\n",
    "        if os.path.isdir(genus_path) and genus_folder in selected_genera:\n",
    "            print(f\"Processing images for {genus_folder}...\")\n",
    "            # Create destination folders for the training and testing data for the current genus\n",
    "            training_destination_genus_path = os.path.join(training_destination_root, genus_folder)\n",
    "            testing_destination_genus_path = os.path.join(testing_destination_root, genus_folder)\n",
    "            os.makedirs(training_destination_genus_path, exist_ok=True)\n",
    "            os.makedirs(testing_destination_genus_path, exist_ok=True)\n",
    "\n",
    "            # If append is True, first copy existing training and testing images to the new training and testing folders\n",
    "            # Update the max_training_images and max_testing_images to reflect the new number of images\n",
    "            # Update images to exclude the existing training and testing images\n",
    "            if append:\n",
    "                print(f\"Copying existing images for {genus_folder}... to new training and testing folders.\")\n",
    "                existing_training_genus_path = os.path.join(existing_training_root, genus_folder)\n",
    "                existing_testing_genus_path = os.path.join(existing_testing_root, genus_folder)\n",
    "\n",
    "                # Copy existing training images to the new training destination folder\n",
    "                for image in os.listdir(existing_training_genus_path):\n",
    "                    source_image_path = os.path.join(existing_training_genus_path, image)\n",
    "                    destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                # Copy existing testing images to the new testing destination folder\n",
    "                for image in os.listdir(existing_testing_genus_path):\n",
    "                    source_image_path = os.path.join(existing_testing_genus_path, image)\n",
    "                    destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                # Update the max_training_images and max_testing_images\n",
    "\n",
    "                max_training_images = max_training_images - len(os.listdir(existing_training_genus_path))\n",
    "                max_testing_images = max_testing_images - len(os.listdir(existing_testing_genus_path))\n",
    "                print(f\"Updated max_training_images: {max_training_images}, max_testing_images: {max_testing_images}\")\n",
    "\n",
    "                # Update images to exclude the existing training and testing images\n",
    "                print(f\"Total number of available images: {len(images)} for {genus_folder}...\")\n",
    "                existing_training_images = set(os.listdir(existing_training_genus_path))\n",
    "                existing_testing_images = set(os.listdir(existing_testing_genus_path))\n",
    "                images = [image for image in images if image not in existing_training_images and image not in existing_testing_images]\n",
    "                print(f\"Total number of images after excluding existing training and testing images: {len(images)} for {genus_folder}...\")\n",
    "\n",
    "            # Randomly select a number of images from the folder here: (900 training + 100 testing).\n",
    "            if len(images) > max_training_images + max_testing_images:\n",
    "                images = random.sample(images, max_training_images + max_testing_images) # file paths for images\n",
    "\n",
    "            # Randomly divide images into training and testing sets\n",
    "            num_total_images = len(images)\n",
    "            num_training_images_to_copy = min(int(num_total_images * training_ratio), max_training_images)\n",
    "            num_testing_images_to_copy = min(num_total_images - num_training_images_to_copy, max_testing_images)\n",
    "\n",
    "            # Randomly shuffle the images before moving\n",
    "            random.shuffle(images)\n",
    "\n",
    "            # Split images into training and testing sets\n",
    "            training_images = images[:num_training_images_to_copy]\n",
    "            testing_images = images[num_training_images_to_copy:]\n",
    "\n",
    "            # Copy training images to the training destination folder\n",
    "            print(f\"Copying {len(training_images)} training images for {genus_folder}...\")\n",
    "            for image in training_images:\n",
    "                source_image_path = os.path.join(genus_path, 'images', image)\n",
    "                destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "            # Copy testing images to the testing destination folder\n",
    "            print(f\"Copying {len(testing_images)} testing images for {genus_folder}...\")\n",
    "            for image in testing_images:\n",
    "                source_image_path = os.path.join(genus_path, 'images', image)\n",
    "                destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                _= shutil.copy2(source_image_path, destination_image_path)\n",
    "            # Keep track of ending time\n",
    "            end_time = time.time()\n",
    "            # Report time take in minutes\n",
    "            total_time = (end_time - start_time) / 60\n",
    "            print(f\"Images copied successfully for {genus_folder}. Time taken: {total_time} minutes.\")\n",
    "\n",
    "print(f\"All images copied successfully for: {selected_genera}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3105e2f",
   "metadata": {},
   "source": [
    "### Create CSV files (metadata) documenting image filenames in the testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2f2cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files processed successfully. CSV file saved at Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\n",
      "Testing files processed successfully. CSV file saved at Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\n"
     ]
    }
   ],
   "source": [
    "# # Selected set of genera\n",
    "# selected_genera = ['acer','ailanthus','betula','citrus','fraxinus','gleditsia','juglans','juniperus',\n",
    "#                    'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "#                    'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "# def process_existing_files(root_directory, file_type):\n",
    "#     existing_files = {}\n",
    "\n",
    "#     for genus in selected_genera:\n",
    "#         genus_dir = os.path.join(root_directory, genus)\n",
    "#         genus_files = os.listdir(genus_dir)\n",
    "#         existing_files[genus] = genus_files\n",
    "\n",
    "#     # Export as table with keys as columns\n",
    "#     df = pd.DataFrame(existing_files)\n",
    "\n",
    "#     # Write to csv\n",
    "#     csv_filepath = os.path.join(csv_path, os.path.basename(root_directory) + \".csv\")\n",
    "#     df.to_csv(csv_filepath, index=False)\n",
    "\n",
    "#     print(f\"{file_type.capitalize()} files processed successfully. CSV file saved at {csv_path}\")\n",
    "\n",
    "# # Process existing training files\n",
    "# process_existing_files(existing_training_root, \"training\")\n",
    "\n",
    "# # Process existing testing files\n",
    "# process_existing_files(existing_testing_root, \"testing\")\n",
    "\n",
    "# # To do: This workflow will be updated in the future so that it's created after each new testing and training dataset is created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1099f",
   "metadata": {},
   "source": [
    "### Print the number of images in the training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c99d6-6169-4053-933c-601f72b02f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many images are contained in the training and testing directories?\n",
    "\n",
    "def print_directory_info(root_directory):\n",
    "    for genus_folder in os.listdir(root_directory):\n",
    "        genus_path = os.path.join(root_directory, genus_folder)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(genus_path):\n",
    "            # Count the number of files in the directory\n",
    "            num_files = len([f for f in os.listdir(genus_path) if os.path.isfile(os.path.join(genus_path, f))])\n",
    "            \n",
    "            print(f\"Directory: {genus_folder}, Number of Files: {num_files}\")\n",
    "\n",
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221fd29-e755-477c-9809-2216189b140d",
   "metadata": {},
   "source": [
    "## Setup Training and Testing Data for iNaturalist images\n",
    "\n",
    "Define Source and Target Directories for Training and Testing Datasets From iNaturalist Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdb5ff-4e0a-41e0-849b-339bc7184aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Source: contains all available street view images of tree genera from iNaturalist\n",
    "source_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inat\\images\\original_10k\"\n",
    "\n",
    "# Target: location for images of tree genera as training data \n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_10thp_apr624\"\n",
    "\n",
    "# Target: location for images of tree genera as testing data \n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_10thp_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as training data used in previous experiments\n",
    "existing_training_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_march624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as testing data used in previous experiments\n",
    "existing_testing_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_march624\"\n",
    "\n",
    "# Append: logical statement to append new images to existing training and testing data\n",
    "append = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752bfbc",
   "metadata": {},
   "source": [
    "### Create a directory with folders named for each class, using the PyTorch ImageFolder Class\n",
    "\n",
    "https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e3044-806b-4063-a278-6f55afc9854f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory of images with folders named for each class, using the PyTorch ImageFolder Class: https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html\n",
    "# Each directory should contain a set of images labelled to genus\n",
    "\n",
    "# Ratio of training to testing images\n",
    "training_ratio = 0.9\n",
    "testing_ratio = 0.1\n",
    "\n",
    "# Maximum number of images for training and testing\n",
    "max_training_images = 13500\n",
    "max_testing_images = 1500\n",
    "\n",
    "# Dictionary to keep track of selected training images for each genus\n",
    "selected_training_images = {}\n",
    "\n",
    "# Selected set of genera\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','cupaniopsis','erythrina','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "# Iterate through the source directory\n",
    "for genus_folder in os.listdir(source_root):\n",
    "    max_training_images = max_training_images_reset\n",
    "    max_testing_images = max_testing_images_reset\n",
    "    start_time = time.time()\n",
    "    genus_path = os.path.join(source_root, genus_folder)\n",
    "    \n",
    "    # List all images in the current genus folder\n",
    "    images = [image for image in os.listdir(genus_path) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Only select genera with >100 images\n",
    "    if len(images) > 100:\n",
    "        print(f\"Processing images for {genus_folder}...\")\n",
    "        # Check if it's a directory and if it's in the selected genera list\n",
    "        if os.path.isdir(genus_path) and genus_folder in selected_genera:\n",
    "            # Create destination folders for the current genus\n",
    "            training_destination_genus_path = os.path.join(training_destination_root, genus_folder)\n",
    "            testing_destination_genus_path = os.path.join(testing_destination_root, genus_folder)\n",
    "            os.makedirs(training_destination_genus_path, exist_ok=True)\n",
    "            os.makedirs(testing_destination_genus_path, exist_ok=True)\n",
    "\n",
    "            # If append is True, first copy existing training and testing images to the new training and testing folders\n",
    "            # Update the max_training_images and max_testing_images to reflect the new number of images\n",
    "            # Update images to exclude the existing training and testing images\n",
    "            if append:\n",
    "                print(f\"Copying existing images for {genus_folder}... to new training and testing folders.\")\n",
    "                existing_training_genus_path = os.path.join(existing_training_root, genus_folder)\n",
    "                existing_testing_genus_path = os.path.join(existing_testing_root, genus_folder)\n",
    "\n",
    "                # Copy existing training images to the new training destination folder\n",
    "                for image in os.listdir(existing_training_genus_path):\n",
    "                    source_image_path = os.path.join(existing_training_genus_path, image)\n",
    "                    destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                # Copy existing testing images to the new testing destination folder\n",
    "                for image in os.listdir(existing_testing_genus_path):\n",
    "                    source_image_path = os.path.join(existing_testing_genus_path, image)\n",
    "                    destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                # Update the max_training_images and max_testing_images\n",
    "                max_training_images = max_training_images - len(os.listdir(existing_training_genus_path))\n",
    "                max_testing_images = max_testing_images - len(os.listdir(existing_testing_genus_path))\n",
    "                print(f\"Updated max_training_images: {max_training_images}, max_testing_images: {max_testing_images}\")\n",
    "\n",
    "                # Update images to exclude the existing training and testing images\n",
    "                print(f\"Total number of available images: {len(images)} for {genus_folder}...\")\n",
    "                existing_training_images = set(os.listdir(existing_training_genus_path))\n",
    "                existing_testing_images = set(os.listdir(existing_testing_genus_path))\n",
    "                images = [image for image in images if image not in existing_training_images and image not in existing_testing_images]\n",
    "                print(f\"Total number of images after excluding existing training and testing images: {len(images)} for {genus_folder}...\")\n",
    "\n",
    "            # Limit the number of images if it exceeds the maximum\n",
    "            if len(images) >= max_training_images + max_testing_images:\n",
    "                images = random.sample(images, max_training_images + max_testing_images)\n",
    "\n",
    "            # Randomly select images for training and testing\n",
    "            num_total_images = len(images)\n",
    "            num_training_images_to_copy = min(int(num_total_images * training_ratio), max_training_images)\n",
    "            num_testing_images_to_copy = min(num_total_images - num_training_images_to_copy, max_testing_images)\n",
    "\n",
    "            # Randomly shuffle the images\n",
    "            random.shuffle(images)\n",
    "\n",
    "            # Split images into training and testing sets\n",
    "            training_images = images[:num_training_images_to_copy]\n",
    "            testing_images = images[num_training_images_to_copy:]\n",
    "\n",
    "            # Copy training images to the training destination folder\n",
    "            print(f\"Copying {len(training_images)} training images for {genus_folder}...\")\n",
    "            for image in training_images:\n",
    "                source_image_path = os.path.join(genus_path, image)\n",
    "                destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "            # Copy testing images to the testing destination folder\n",
    "            print(f\"Copying {len(testing_images)} testing images for {genus_folder}...\")\n",
    "            for image in testing_images:\n",
    "                source_image_path = os.path.join(genus_path, image)\n",
    "                destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                _= shutil.copy2(source_image_path, destination_image_path)\n",
    "            end_time = time.time()\n",
    "            total_time = (end_time - start_time) / 60\n",
    "            print(f\"Images copied successfully for {genus_folder}. Time taken: {total_time} minutes.\")\n",
    "\n",
    "print(\"Images copied successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189eeb92",
   "metadata": {},
   "source": [
    "### Create CSV files (metadata) documenting image filenames in the testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9a98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files processed successfully. CSV file saved at Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\n",
      "Testing files processed successfully. CSV file saved at Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\n"
     ]
    }
   ],
   "source": [
    "# # Selected set of genera\n",
    "# selected_genera = ['acer','ailanthus','betula','citrus','fraxinus','gleditsia','juglans','juniperus',\n",
    "#                    'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "#                    'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "# def process_existing_files(root_directory, file_type):\n",
    "#     existing_files = {}\n",
    "\n",
    "#     for genus in selected_genera:\n",
    "#         genus_dir = os.path.join(root_directory, genus)\n",
    "#         genus_files = os.listdir(genus_dir)\n",
    "#         existing_files[genus] = genus_files\n",
    "\n",
    "#     # Export as table with keys as columns\n",
    "#     df = pd.DataFrame(existing_files)\n",
    "\n",
    "#     # Write to csv\n",
    "#     csv_filepath = os.path.join(csv_path, os.path.basename(root_directory) + \".csv\")\n",
    "#     df.to_csv(csv_filepath, index=False)\n",
    "\n",
    "#     print(f\"{file_type.capitalize()} files processed successfully. CSV file saved at {csv_path}\")\n",
    "\n",
    "# # Process existing training files\n",
    "# process_existing_files(existing_training_root, \"training\")\n",
    "\n",
    "# # Process existing testing files\n",
    "# process_existing_files(existing_testing_root, \"testing\")\n",
    "\n",
    "# # To do: This workflow will be updated in the future so that it's created after each new testing and training dataset is created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c66a7",
   "metadata": {},
   "source": [
    "### Print the number of images in the training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89f095-1782-4397-8be8-cd45ca4cf274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many images are contained in the training and testing directories?\n",
    "\n",
    "def print_directory_info(root_directory):\n",
    "    for genus_folder in os.listdir(root_directory):\n",
    "        genus_path = os.path.join(root_directory, genus_folder)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(genus_path):\n",
    "            # Count the number of files in the directory\n",
    "            num_files = len([f for f in os.listdir(genus_path) if os.path.isfile(os.path.join(genus_path, f))])\n",
    "            \n",
    "            print(f\"Directory: {genus_folder}, Number of Files: {num_files}\")\n",
    "\n",
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many images are contained in the training and testing directories?\n",
    "\n",
    "def print_directory_info(root_directory):\n",
    "    for genus_folder in os.listdir(root_directory):\n",
    "        genus_path = os.path.join(root_directory, genus_folder)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(genus_path):\n",
    "            # Count the number of files in the directory\n",
    "            num_files = len([f for f in os.listdir(genus_path) if os.path.isfile(os.path.join(genus_path, f))])\n",
    "            \n",
    "            print(f\"Directory: {genus_folder}, Number of Files: {num_files}\")\n",
    "\n",
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b442841-4782-4a4b-8ca5-883673037462",
   "metadata": {},
   "source": [
    "# Combine AutoArborist and iNatuarlist Data\n",
    "\n",
    "Create Training and Testing Records from the Combined Autoarborist + iNaturalist Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e80829-11c0-4fe9-8280-cbd3a30ceaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def combine_image_data(source_dirs, combined_dir):\n",
    "    for source_dir in source_dirs:\n",
    "        for dataset_type in os.listdir(source_dir):\n",
    "            dataset_type_dir = os.path.join(source_dir, dataset_type)\n",
    "            combined_dataset_type_dir = os.path.join(combined_dir, dataset_type)\n",
    "            os.makedirs(combined_dataset_type_dir, exist_ok=True)\n",
    "            for genus in os.listdir(dataset_type_dir):\n",
    "                genus_dir = os.path.join(dataset_type_dir, genus)\n",
    "                combined_genus_dir = os.path.join(combined_dataset_type_dir, genus)\n",
    "                os.makedirs(combined_genus_dir, exist_ok=True)\n",
    "                for filename in os.listdir(genus_dir):\n",
    "                    if filename.lower().endswith(('.jpg', '.jpeg', '.JPG')):\n",
    "                        src_file = os.path.join(genus_dir, filename)\n",
    "                        dst_file = os.path.join(combined_genus_dir, filename)\n",
    "                        shutil.copyfile(src_file, dst_file)\n",
    "\n",
    "# Source directories\n",
    "source_dirs = [\n",
    "    r'Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist',\n",
    "    r'Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist'\n",
    "]\n",
    "\n",
    "# Combined directory\n",
    "combined_dir = r'Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist_inaturalist_combined'\n",
    "\n",
    "# Combine image data\n",
    "combine_image_data(source_dirs, combined_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e860fe9-8370-4b31-a24a-8dc03033c626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many images are contained in the training and testing directories?\n",
    "\n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist_inaturalist_combined\\training_dataset_small_april624\"\n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist_inaturalist_combined\\testing_dataset_small_march624\"\n",
    "\n",
    "def print_directory_info(root_directory):\n",
    "    for genus_folder in os.listdir(root_directory):\n",
    "        genus_path = os.path.join(root_directory, genus_folder)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(genus_path):\n",
    "            # Count the number of files in the directory\n",
    "            num_files = len([f for f in os.listdir(genus_path) if os.path.isfile(os.path.join(genus_path, f))])\n",
    "            \n",
    "            print(f\"Directory: {genus_folder}, Number of Files: {num_files}\")\n",
    "\n",
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e17504-992f-4e65-b0a1-21f861b996ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1aba3-e66f-4fc9-bbfa-914b860e5927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# First, define the training and testing datasets (AutoArborist, iNaturalist, or combined) by specifying the file paths.\n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist_inaturalist_combined\\training_dataset_small_march624\"\n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist_inaturalist_combined\\testing_dataset_small_march624\"\n",
    "\n",
    "# Use Pytorch ImageFolder class to prepare training and testing datasets\n",
    "train_data_dir = training_destination_root\n",
    "test_data_dir = testing_destination_root\n",
    "\n",
    "# Load the training and testing datasets as Pytorch Dataset Classes: https://pytorch.org/docs/stable/data.html\n",
    "# The Pytorch torchvision.transforms module provides preprocessing functions: https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomResizedCrop(size=(512, 512), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Ensure images are resized during testing as same dimension for training\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(size=(512, 512), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(train_data_dir, transform = train_transforms)\n",
    "test_dataset = ImageFolder(test_data_dir, transform = test_transforms)\n",
    "\n",
    "# Examine the train_dataset object\n",
    "train_dataset\n",
    "\n",
    "# Examine image dimensions: (3 channels, height 64, width 64)\n",
    "img, label = train_dataset[0]\n",
    "print(img.shape,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c3c67-60f1-4685-899a-edeb4e4ea5e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many classes are in the training and testing datasets?\n",
    "print(\"Classes in the Training Dataset : /n\", len(train_dataset.classes))\n",
    "print(\"Classes in the Testing Dataset : /n\", len(test_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6c85b-dfed-437c-aa97-7f0894964eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc3497-0362-4acd-b8d7-9a5af318df98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize sample image in the training dataset\n",
    "\n",
    "def display_img(img,label):\n",
    "    print(f\"Label : {train_dataset.classes[label]}\")\n",
    "    plt.imshow(img.permute(1,2,0)) #reshape image from (3, H, W) to (H, W, 3)\n",
    "\n",
    "# Display the first image in the dataset\n",
    "display_img(*train_dataset[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cfc4a6-65cd-4512-a3e0-d6bce07dc0c4",
   "metadata": {},
   "source": [
    "# Define Training, Validation, and Testing DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca92d2-5579-4f73-8e43-3002e67b11b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split training data into a validation set, and prepare dataset for training\n",
    "\n",
    "# Define batch size for training \n",
    "bs = 32\n",
    "\n",
    "# Define number of images for validation (typically, 10% of the training set)\n",
    "val_size = 2000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "# Randomly split training data into train_data and val_data sets\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Length of Train Data : {len(train_data)}\") # Length of Train Data : 20000\n",
    "print(f\"Length of Validation Data : {len(val_data)}\") # Length of Validation Data : 2000\n",
    "\n",
    "# Use Pytorch DataLoader Class to iterate over a dataset for training: https://pytorch.org/docs/stable/data\n",
    "\n",
    "train_dl = DataLoader(dataset = train_data, batch_size = bs, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(dataset = val_data, batch_size = bs*2, num_workers = 4, pin_memory = True)\n",
    "test_dl = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 4, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32781b8-c9ba-4ec2-8f98-796aa745b69b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display one batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2cdeb-8ad3-470a-b2a9-f6c85e5bc7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize a single batch of images\n",
    "\n",
    "def show_batch(dl):\n",
    "    \"\"\"Plot images grid of single batch\"\"\"\n",
    "    for images, labels in dl:\n",
    "        fig,ax = plt.subplots(figsize = (16,12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n",
    "        break\n",
    "        \n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7a841-90da-49e4-88df-2e4be9b3b4b7",
   "metadata": {},
   "source": [
    "# Prepare the Image Classification Model\n",
    "\n",
    "The ImageClassificationBase Class inherits functionality from the nn.Module Class in Pytorch: https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47f661-38c0-4865-82e0-b4a5ed3d5c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare a Basic Model for Image Classification\n",
    "\n",
    "import torch.nn as nn # contains base class for all neural network modules\n",
    "import torch.nn.functional as F #https://pytorch.org/docs/stable/nn.functional.html contains common functions for training NNs (convolutions, losses, etc..)\n",
    "\n",
    "class ImageClassificationBase(nn.Module): # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
    "    # Define a base class with functionality for model training, validation, and evaluation per epoch\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels) # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc3311-7754-477f-a7f5-82ef30d8052b",
   "metadata": {},
   "source": [
    "# Create an EfficientNetV2 Model\n",
    "\n",
    "https://arxiv.org/abs/2104.00298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254bd5ca-ebba-421e-b9cc-e4d3a3550fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define a CNN Model using EfficientNetV2-S\n",
    "\n",
    "class EfficientNetImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained EfficientNetV2-L Model\n",
    "        self.network = torchvision.models.efficientnet_v2_s(pretrained=True)\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = len(train_dataset.classes)\n",
    "        in_features = self.network.classifier[1].in_features\n",
    "        self.network.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40feff04-1435-4d1f-9728-a12dd6ac280f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Instantiate the model\n",
    "model = EfficientNetImageClassification()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c649d-ad9f-441f-b9ca-db967ef46ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f'Number of Model Parameters: ', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad80810-be1a-4d91-9602-ebd3b63e0669",
   "metadata": {},
   "source": [
    "# Define GPU Device and Load Data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2cc363-adff-43e1-bc05-c0263e337d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function and class to load data to GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\" Set Device to GPU or CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"Move data to the device\"\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking = True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n",
    "    \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\" Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches \"\"\"\n",
    "        return len(self.dl)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96b227-8925-4c2f-9e7c-04e9a454e4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get GPU Device\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Load data to GPU\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc8a82-c10a-4831-8c15-a69eef0adeb3",
   "metadata": {},
   "source": [
    "# Define CNN Model Fit and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd848bd-ab15-4990-affb-0fb6a33a1992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Fit and Evaluation methods\n",
    "\n",
    "# Do not compute new gradients when evaluating a model\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "# Fit model\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    # Create optimizer with initial learning rate\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Forward pass: prediction & calculate loss\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            # Backward pass: backpropagate loss & calculate gradients\n",
    "            loss.backward()\n",
    "            optimizer.step() #update gradients\n",
    "            optimizer.zero_grad() #zero gradients for next training forward pass\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13643360-700e-4c5c-8087-aaddcc8786d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load model to device and specify training parameters\n",
    "\n",
    "- Epochs = 10\n",
    "- Optimizer (Gradient Descent): Adam\n",
    "- Learning Rate: 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb9c412-7cf2-4979-b045-9d90ac31ce99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the model to the device\n",
    "model = to_device(EfficientNetImageClassification(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59307f10-fe2e-4c3d-928a-8d444bab4754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set number of epochs, optimizer function, learning rate, and warmup epochs\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "base_lr = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dafb97-6703-4316-8839-01176eb796f2",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1dd77-257f-416a-b8ac-0fc5ee381020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit model with warmup, logit adjustment, and record results after each epoch\n",
    "\n",
    "# Fit model and record result after epoch\n",
    "history = fit(num_epochs, base_lr, model, train_dl, val_dl, opt_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca669b-713e-40e8-ab0e-27a5452b91db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Capture Fitted Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34851344-bfe6-4e0b-93ec-dbd44212d374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model history contains training loss, validation loss, and validation accuracy metrics\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e4a32-1dfd-49f0-ba05-3bb1e91aceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights file to path\n",
    "model_path = r'C:\\Users\\talake2\\Desktop\\tree-classification-autoarb_inat-25-genera-1000imgs-effnet2s-10epochs-lr001-aug-march724.pth'\n",
    "\n",
    "# Torch.Save model to file: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a2077-c56f-41aa-9e24-49ab6e0b43dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Accuracy and Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a77219-cabd-422c-b111-92985a2239a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "    \n",
    "\n",
    "plot_accuracies(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572b6cc-a76e-4452-8fdd-9b325e73d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7281a79b-cdba-4039-afbe-2168d23e96dc",
   "metadata": {},
   "source": [
    "# Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59792fe-e4bf-4f20-aa8b-e94ca3cf1481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Evaluation with Confusion Matrix\n",
    "# Iterate over test dataset and generate predictions for a confusion matrix\n",
    "\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','cupaniopsis','erythrina','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "#model.cuda()  # Move model to CUDA if not already there\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode.\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(output, dim=1).cpu().numpy()  # Extract predicted labels directly\n",
    "        y_pred.extend(output)\n",
    "        \n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a39e6-8f06-4cb8-8967-125404bb4b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=selected_genera)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "plt.savefig(r\"C:\\Users\\talake2\\Desktop\\auto_arborist_cvpr2022_v015\\pytorch_cnn_classifier_experiments_jan24\\autoarborist_inaturalist_models_march2024\\tree-classification-inat-25-genera-1000imgs-effnet2s-10epochs-lr001-march724.png\", dpi=200)\n",
    "#plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aacf43-0ab6-4e7d-9a6d-42a5fa922423",
   "metadata": {},
   "source": [
    "# Calculate precision, recall, F1, and support per class on the withheld testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2b94c-aadf-4efe-9e68-3c94af2e5f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names = selected_genera))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55735bab-5dc4-4f23-8424-e384e4368b7a",
   "metadata": {},
   "source": [
    "# Load a trained Image Classification Model (CNN) to run predictions and calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2dc8d-8106-416d-9c8f-b0c1fbd162c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports for Pytorch\n",
    "import torch # version 2.1.2\n",
    "import torchvision # version 0.16.2\n",
    "#from torchvision import transforms # https://pytorch.org/vision/stable/transforms.html # To do: implement Pytorch transforms v2 (faster, more functionality)\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "# Image Libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# General Imports\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc813102-e431-4641-ba62-f80f1bb86ad2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define Class for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054e6c7-141e-4c4e-b87b-ebf3ad255ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare a Basic Model for Image Classification\n",
    "\n",
    "import torch.nn as nn # contains base class for all neural network modules\n",
    "import torch.nn.functional as F #https://pytorch.org/docs/stable/nn.functional.html contains common functions for training NNs (convolutions, losses, etc..)\n",
    "\n",
    "class ImageClassificationBase(nn.Module): # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
    "    # Define a base class with functionality for model training, validation, and evaluation per epoch\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels) # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b36be-072b-48af-9960-47d02765541a",
   "metadata": {},
   "source": [
    "# Define CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03260ff-6d6e-4e63-b5f7-6b6dfd122aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a CNN Model using ResNet50\n",
    "class ResNet50ImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained ResNet model\n",
    "        self.network = torchvision.models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V2')\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = 25 # Set number of output classes\n",
    "        in_features = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    \n",
    "    \n",
    "# # Define a CNN Model using EfficientNetV2-S\n",
    "class EfficientNetImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained EfficientNetV2-L Model\n",
    "        self.network = torchvision.models.efficientnet_v2_s(pretrained=True)\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = 25 # Set number of output classes\n",
    "        in_features = self.network.classifier[1].in_features\n",
    "        self.network.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4cab5-838f-4551-84e8-aa089cadc654",
   "metadata": {},
   "source": [
    "# Load models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c724d42-baa8-457c-ad5d-dc44b22c27be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function and class to load data to GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\" Set Device to GPU or CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"Move data to the device\"\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking = True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n",
    "    \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\" Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches \"\"\"\n",
    "        return len(self.dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4647578f-0c18-44f8-88d9-6596beac4543",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add43d6-6817-40e2-bbc1-dbc15e2b37e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "training_destination_root = r\"C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/pytorch_cnn_classifier_experiments_jan24/datasets/autoarborist/training_dataset_small_march624\"\n",
    "testing_destination_root = r\"C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/pytorch_cnn_classifier_experiments_jan24/datasets/autoarborist/testing_dataset_small_march624\"\n",
    "\n",
    "# Use Pytorch ImageFolder class to prepare training and testing datasets\n",
    "train_data_dir = training_destination_root\n",
    "test_data_dir = testing_destination_root\n",
    "\n",
    "# Load the training and testing datasets as Pytorch Dataset Classes: https://pytorch.org/docs/stable/data.html\n",
    "# The Pytorch torchvision.transforms module provides preprocessing functions: https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(size=(512, 512), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "# Ensure images are resized during testing as same dimension for training\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.Resize(size=(512, 512), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(train_data_dir, transform = train_transforms)\n",
    "test_dataset = ImageFolder(test_data_dir, transform = test_transforms)\n",
    "\n",
    "# Examine the train_dataset object\n",
    "train_dataset\n",
    "\n",
    "# Examine image dimensions: (3 channels, height 64, width 64)\n",
    "img, label = train_dataset[0]\n",
    "print(img.shape,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e3631-4944-42e2-be2d-ed96583d441a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split training data into a validation set, and prepare dataset for training\n",
    "\n",
    "len(train_dataset.classes)\n",
    "len(test_dataset.classes)\n",
    "\n",
    "# Define batch size for training \n",
    "bs = 32\n",
    "\n",
    "# Define number of images for validation\n",
    "val_size = 2000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "# Randomly split training data into train_data and val_data sets\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Length of Train Data : {len(train_data)}\") # Length of Train Data : 17212\n",
    "print(f\"Length of Validation Data : {len(val_data)}\") # Length of Validation Data : 2000\n",
    "\n",
    "# Use Pytorch DataLoader Class to iterate over a dataset for training: https://pytorch.org/docs/stable/data\n",
    "\n",
    "train_dl = DataLoader(dataset = train_data, batch_size = bs, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(dataset = val_data, batch_size = bs*2, num_workers = 4, pin_memory = True)\n",
    "test_dl = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 4, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3092d4-6aa9-4f94-bb43-34a8360c6cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model_path = r'C:\\Users\\talake2\\Desktop\\\\tree-classification-inat-25-genera-1000imgs-effnet2s-10epochs-lr001-march724.pth'\n",
    "\n",
    "# Get GPU Device\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Instantiate the model with the same architecture as the model which parameters you saved\n",
    "model = EfficientNetImageClassification()\n",
    "\n",
    "#load the model to the device\n",
    "model = to_device(EfficientNetImageClassification(), device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval() # Call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4eaed-6fca-47fe-9406-9c0ff12c6880",
   "metadata": {},
   "source": [
    "# Load data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d15815-8558-4fa6-9b82-03ebf1ff6544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data to GPU\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e4857-c85f-4458-88ee-f26205c57d0f",
   "metadata": {},
   "source": [
    "# Predict on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b01fe-ae14-4c04-bcaf-eaa79aa10e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Evaluation with Confusion Matrix\n",
    "# Iterate over test dataset and generate predictions for a confusion matrix\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','cupaniopsis','erythrina','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "#model.cuda()  # Move model to CUDA if not already there\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(output, dim=1).cpu().numpy()  # Extract predicted labels directly\n",
    "        y_pred.extend(output)\n",
    "        \n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a388bcf-304d-439e-8fb3-d0e86546a9de",
   "metadata": {},
   "source": [
    "# Create confusion matrix and summary statistics for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11739ee-b64c-4992-aabf-cd87bde7d5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=selected_genera)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "plt.savefig(r\"C:\\Users\\talake2\\Desktop\\inat_cnn_effnet2s_evalon_autoarb_25_genera_march72024\", dpi=200)\n",
    "plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ea199-1415-4669-843d-51e4ec7a61b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names = selected_genera))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763963f-9acb-460b-b902-b46ea54748b7",
   "metadata": {},
   "source": [
    "# Run classification on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7682df-9731-4dae-9c63-6de82c41f54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Constant for classes    \n",
    "classes = ('acer', 'fraxinus', 'quercus', 'ulmus', 'prunus', 'tilia', 'gleditsia', 'malus', 'platanus', 'liquidambar', 'pinus', 'ginkgo', 'zelkova', 'celtis', 'crataegus', 'populus', 'carpinus', 'syringa', 'lagerstroemia', 'betula')\n",
    "\n",
    "img_path = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/auto_arborist_jpegs/jpegs_aerial_streetlevel_raw/all_cities_streetview/train/acer/streetlevel_4_7.jpg'\n",
    "img = imread(img_path)\n",
    "img.shape\n",
    "\n",
    "# Resize the image\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "# Convert image to tensor using torchvision.transforms.ToTensor()\n",
    "transform = transforms.ToTensor()\n",
    "img = transform(img) #Transforms image to [0-1] and channels first\n",
    "img = img.unsqueeze(0) #add first dimension of batch size\n",
    "img = img.cuda() #push to GPU\n",
    "\n",
    "#prdict image label\n",
    "output = model(img)\n",
    "\n",
    "# Get the index of the maximum value in the output tensor\n",
    "predicted_class_index = torch.argmax(output)\n",
    "\n",
    "# Use the index to get the corresponding class label\n",
    "predicted_class_label = classes[predicted_class_index.item()]\n",
    "\n",
    "print(\"Predicted Class Label:\", predicted_class_label)\n",
    "\n",
    "# Get the top 5 class predictions\n",
    "top5_probabilities, top5_indices = torch.topk(output, 5)\n",
    "\n",
    "# Convert indices to class labels\n",
    "top5_class_labels = [classes[i] for i in top5_indices.squeeze().tolist()]\n",
    "\n",
    "print(\"Top 5 Predicted Class Labels:\", top5_class_labels)\n",
    "print(\"Top 5 Predicted Probabilities:\", top5_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
