{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90233a93-8670-4ebd-9fc2-39807c29b341",
   "metadata": {},
   "source": [
    "# Setup, Training, and Evaluating CNNs for Tree Genera Classification\n",
    "\n",
    "The following Jupyter Notebook includes code to setup and train a convolutional neural network with Python and Pytorch.\n",
    "\n",
    "Version: April 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34f37d09-22ad-4965-89ea-63af7fae1da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports for Pytorch\n",
    "import torch # version 2.1.2\n",
    "import torchvision # version 0.16.2\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn # contains base class for all neural network modules\n",
    "import torch.nn.functional as F #https://pytorch.org/docs/stable/nn.functional.html contains common functions for training NNs (convolutions, losses, etc..)\n",
    "\n",
    "\n",
    "# Image processing and display\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Other Imports\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a698887d",
   "metadata": {},
   "source": [
    "## Setup new testing and training datasets, save their metadata as csvs, and print number of images to console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a43c91-ae82-44a0-a622-baa3d2490ed9",
   "metadata": {},
   "source": [
    "### Functions to create new testing and training datasets, export metadata, and print number of images to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abb6fbfe-b7d0-46c3-9481-9f217c19a612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Functions to create datasets for training and testing, export metadata to csv, and print directory information\n",
    "# Function to export metadata to csv\n",
    "def process_existing_files(root_directory, csv_path, export_csv=False):\n",
    "    \"\"\"\n",
    "    Process existing files in the root directory and write to csv.\n",
    "\n",
    "    Parameters:\n",
    "    root_directory (str): The path to the root directory containing images of tree genera.\n",
    "\n",
    "    Returns:\n",
    "    Print statement with the file path to the csv.\n",
    "    \"\"\"\n",
    "    existing_files = {}\n",
    "\n",
    "    # Get the list of genus names from the root directory\n",
    "    genera = os.listdir(root_directory)\n",
    "\n",
    "    for genus in genera:\n",
    "        genus_dir = os.path.join(root_directory, genus)\n",
    "        genus_files = os.listdir(genus_dir)\n",
    "        existing_files[genus] = genus_files\n",
    "\n",
    "    # Create a dataframe from the dictionary\n",
    "    df = pd.DataFrame(existing_files.items(), columns=['genus', 'files'])\n",
    "    df = df.explode('files')\n",
    "\n",
    "    # Add additional column for data source\n",
    "    if \"inat\" in root_directory.lower():\n",
    "        df['data_source'] = \"iNaturalist\"\n",
    "    else:\n",
    "        df['data_source'] = \"Autoarborist\"\n",
    "    \n",
    "    if export_csv:\n",
    "        # Write to csv\n",
    "        csv_filepath = os.path.join(csv_path, os.path.basename(root_directory) + \".csv\")\n",
    "        df.to_csv(csv_filepath, index=False)\n",
    "        print(f\"Existing files for {root_directory} written to csv.\")\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "# Function to print directory information\n",
    "def print_directory_info(root_directory):\n",
    "    \"\"\"\n",
    "    Print the number of files in each directory in the root directory.\n",
    "\n",
    "    Parameters:\n",
    "    root_directory (str): The path to the root directory containing images of tree genera.\n",
    "\n",
    "    Returns:\n",
    "    Print statement with the number of files in each directory.\n",
    "    \"\"\"\n",
    "    for genus_folder in os.listdir(root_directory):\n",
    "        genus_path = os.path.join(root_directory, genus_folder)\n",
    "        \n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(genus_path):\n",
    "            # Count the number of files in the directory\n",
    "            num_files = len([f for f in os.listdir(genus_path) if os.path.isfile(os.path.join(genus_path, f))])\n",
    "            \n",
    "            print(f\"Directory: {genus_folder}, Number of Files: {num_files}\")\n",
    "    return None\n",
    "\n",
    "# Function to create datasets for training and testing: Autoarborist or iNaturalist\n",
    "def create_datasets (training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root, \n",
    "                     training_destination_root, existing_training_root, existing_testing_root, append, csv_path):\n",
    "    \"\"\"\n",
    "    Create training and testing datasets for selected genera from any source image dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    training_ratio (float): The ratio of training images to total images.\n",
    "    max_training_images_og (int): The maximum number of training images to select.\n",
    "    max_testing_images_og (int): The maximum number of testing images to select.\n",
    "    selected_genera (list): The list of selected genera to include in the training and testing datasets.\n",
    "    source_root (str): The path to the source directory containing all available images of tree genera from Autoarborist.\n",
    "    testing_destination_root (str): The path to the destination directory for images of tree genera as testing data.\n",
    "    training_destination_root (str): The path to the destination directory for images of tree genera as training data.\n",
    "    existing_training_root (str): The path to the existing directory containing images of tree genera as training data used in previous experiments.\n",
    "    existing_testing_root (str): The path to the existing directory containing images of tree genera as testing data used in previous experiments.\n",
    "    append (bool): A logical statement to append new images to existing training and testing data.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Iterate through the source directory\n",
    "    for genus_folder in os.listdir(source_root):\n",
    "        max_training_images = max_training_images_og\n",
    "        max_testing_images = max_testing_images_og\n",
    "        # Keep track of starting time\n",
    "        start_time = time.time()\n",
    "        genus_path = os.path.join(source_root, genus_folder) # Get path to images for each genera\n",
    "    \n",
    "        # List all images in the current genus folder. Some images are .jpg and .jpeg format.\n",
    "        # If \"inat\" is found anywhere in the genus folder name, then the images are in the root folder.\n",
    "        if \"inat\" in genus_path.lower():\n",
    "            images = [image for image in os.listdir(genus_path) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        else:\n",
    "            images = [image for image in os.listdir(os.path.join(genus_path, 'images')) if image.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        # Only select genera with >100 images.\n",
    "        if len(images) > 100:\n",
    "            # Check if it's a directory and if it's in the selected genera list\n",
    "            if os.path.isdir(genus_path) and genus_folder in selected_genera:\n",
    "                # Create destination folders for the training and testing data for the current genus\n",
    "                training_destination_genus_path = os.path.join(training_destination_root, genus_folder)\n",
    "                testing_destination_genus_path = os.path.join(testing_destination_root, genus_folder)\n",
    "                os.makedirs(training_destination_genus_path, exist_ok=True)\n",
    "                os.makedirs(testing_destination_genus_path, exist_ok=True)\n",
    "                # Append new images to existing training and testing data\n",
    "                if append:\n",
    "                    print(f\"Copying existing images for {genus_folder} to new training and testing folders.\")\n",
    "                    existing_training_genus_path = os.path.join(existing_training_root, genus_folder)\n",
    "                    existing_testing_genus_path = os.path.join(existing_testing_root, genus_folder)\n",
    "\n",
    "                    # Copy existing training images to the new training destination folder\n",
    "                    for image in os.listdir(existing_training_genus_path):\n",
    "                        source_image_path = os.path.join(existing_training_genus_path, image)\n",
    "                        destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                        _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                    # Copy existing testing images to the new testing destination folder\n",
    "                    for image in os.listdir(existing_testing_genus_path):\n",
    "                        source_image_path = os.path.join(existing_testing_genus_path, image)\n",
    "                        destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                        _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                    # Update the max_training_images and max_testing_images\n",
    "                    max_training_images = max_training_images - len(os.listdir(existing_training_genus_path))\n",
    "                    max_testing_images = max_testing_images - len(os.listdir(existing_testing_genus_path))\n",
    "                    print(f\"Updated max_training_images: {max_training_images}, max_testing_images: {max_testing_images}\")\n",
    "\n",
    "                    # Update images to exclude the existing training and testing images\n",
    "                    print(f\"Total number of available images: {len(images)} for {genus_folder}...\")\n",
    "                    existing_training_images = set(os.listdir(existing_training_genus_path))\n",
    "                    existing_testing_images = set(os.listdir(existing_testing_genus_path))\n",
    "                    images = [image for image in images if image not in existing_training_images and image not in existing_testing_images]\n",
    "                    print(f\"Total number of images after excluding existing training and testing images: {len(images)} for {genus_folder}...\")\n",
    "\n",
    "                # Randomly select a number of images from the folder here: (900 training + 100 testing).\n",
    "                if len(images) > max_training_images + max_testing_images:\n",
    "                    images = random.sample(images, max_training_images + max_testing_images) # file paths for images\n",
    "\n",
    "                # Randomly divide images into training and testing sets\n",
    "                num_total_images = len(images)\n",
    "                num_training_images_to_copy = min(int(num_total_images * training_ratio), max_training_images)\n",
    "\n",
    "                # Randomly shuffle the images before moving\n",
    "                random.shuffle(images)\n",
    "\n",
    "                # Split images into training and testing sets\n",
    "                training_images = images[:num_training_images_to_copy]\n",
    "                testing_images = images[num_training_images_to_copy:]\n",
    "            \n",
    "                # Copy training images to the training destination folder\n",
    "                print(f\"Copying new images for {genus_folder} to new training and testing folders.\")\n",
    "                for image in training_images:\n",
    "                    if \"inat\" in genus_path.lower():\n",
    "                        source_image_path = os.path.join(genus_path, image)\n",
    "                    else:\n",
    "                        source_image_path = os.path.join(genus_path, 'images', image)\n",
    "                    destination_image_path = os.path.join(training_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "                # Copy testing images to the testing destination folder\n",
    "                for image in testing_images:\n",
    "                    if \"inat\" in genus_path.lower():\n",
    "                        source_image_path = os.path.join(genus_path, image)\n",
    "                    else:\n",
    "                        source_image_path = os.path.join(genus_path, 'images', image)\n",
    "                    destination_image_path = os.path.join(testing_destination_genus_path, image)\n",
    "                    _= shutil.copy2(source_image_path, destination_image_path)\n",
    "                # Keep track of ending time\n",
    "                end_time = time.time()\n",
    "                # Report time take in minutes\n",
    "                total_time = (end_time - start_time) / 60\n",
    "                print(f\"Images copied successfully for {genus_folder}. Time taken: {total_time} minutes.\")\n",
    "    print(f\"All images copied successfully for: {selected_genera}.\")\n",
    "    process_existing_files(training_destination_root, csv_path, export_csv=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Function to combine existing training and testing data\n",
    "\n",
    "def combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root):\n",
    "    \"\"\"\n",
    "    Combine the training datasets from Autoarborist and iNaturalist into a single testing or training dataset.\n",
    "    Combine the testing datasets from Autoarborist and iNaturalist into a single testing or training dataset.\n",
    "    Combine the metadata from Autoarborist and iNaturalist into a single metadata file.\n",
    "\n",
    "    Parameters:\n",
    "    autoarborist_dataset_root (str): The path to the Autoarborist testing or training dataset.\n",
    "    inaturalist_dataset_root (str): The path to the iNaturalist testing or training dataset.\n",
    "    combined_dataset_root (str): The path to the combined testing or training dataset.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create the combined training dataset directory\n",
    "    os.makedirs(combined_dataset_root, exist_ok=True)\n",
    "\n",
    "    # Copy the Autoarborist dataset to the combined dataset\n",
    "    for genus_folder in os.listdir(autoarborist_dataset_root):\n",
    "        genus_path = os.path.join(autoarborist_dataset_root, genus_folder)\n",
    "        destination_genus_path = os.path.join(combined_dataset_root, genus_folder)\n",
    "        os.makedirs(destination_genus_path, exist_ok=True)\n",
    "        print(f\"Copying Autoarborist images for {genus_folder} to the combined dataset.\")\n",
    "\n",
    "        for image in os.listdir(genus_path):\n",
    "            source_image_path = os.path.join(genus_path, image)\n",
    "            destination_image_path = os.path.join(destination_genus_path, image)\n",
    "            _= shutil.copy2(source_image_path, destination_image_path)\n",
    "        \n",
    "    \n",
    "    # Copy the iNaturalist dataset to the training dataset\n",
    "    for genus_folder in os.listdir(inaturalist_dataset_root):\n",
    "        genus_path = os.path.join(inaturalist_dataset_root, genus_folder)\n",
    "        destination_genus_path = os.path.join(combined_dataset_root, genus_folder)\n",
    "        os.makedirs(destination_genus_path, exist_ok=True)\n",
    "        print(f\"Copying iNaturalist images for {genus_folder} to the combined dataset.\")\n",
    "\n",
    "        for image in os.listdir(genus_path):\n",
    "            source_image_path = os.path.join(genus_path, image)\n",
    "            destination_image_path = os.path.join(destination_genus_path, image)\n",
    "            _= shutil.copy2(source_image_path, destination_image_path)\n",
    "\n",
    "    print(f\"Combined dataset created successfully.\")\n",
    "\n",
    "    # Combine the autoarborist_root, inaturalist_root, and combined_root metadata\n",
    "    roots = [autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root]\n",
    "    updated_roots = [os.path.join(os.path.join(root.rsplit('\\\\', 1)[0], os.path.basename(root) + \".csv\")) for root in roots]\n",
    "    \n",
    "    # Pull in the existing metadata for autoarborist\n",
    "    autoarborist_metadata = pd.read_csv(updated_roots[0])\n",
    "    # Pull in the existing metadata for inaturalist\n",
    "    inaturalist_metadata = pd.read_csv(updated_roots[1])\n",
    "    # Combine the metadata\n",
    "    combined_metadata = pd.concat([autoarborist_metadata, inaturalist_metadata], ignore_index=True)\n",
    "    # Write to csv\n",
    "    combined_metadata.to_csv(updated_roots[2], index=False)\n",
    "    print(f\"Combined metadata written to csv.\")\n",
    "    return None\n",
    "\n",
    "# Constants\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','fraxinus','gleditsia','juglans','juniperus', 'magnolia','phoenix','picea',\n",
    "                   'pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium', 'thuja','tilia','ulmus','washingtonia']\n",
    "training_ratio = 0.9 # ratio of training images to total images\n",
    "max_training_images_og = 1187 # maximum number of training images to select\n",
    "max_testing_images_og = 132 # maximum number of testing images to select\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe88f9",
   "metadata": {},
   "source": [
    "### Autoarborist: Source, append, and create new testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5070c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing files for Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_apr624 written to csv.\n",
      "Existing files for Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_apr624 written to csv.\n"
     ]
    }
   ],
   "source": [
    "# Source: contains all available street view images of tree genera from Autoarborist\n",
    "source_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\autoarborist_original_data\\autoarborist_original_jpegs\\jpegs_streetlevel_genus_idx_label\"\n",
    "\n",
    "# Target: location for images of tree genera as training data \n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_apr624\"\n",
    "\n",
    "# Target: location for images of tree genera as testing data \n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as training data used in previous experiments\n",
    "existing_training_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_march624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as testing data used in previous experiments\n",
    "existing_testing_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_march624\"\n",
    "\n",
    "# Append: logical statement to append new images to existing training and testing data\n",
    "append = True\n",
    "\n",
    "# CSV path: location to save the CSV file containing the training and testing data\n",
    "csv_path = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\"\n",
    "\n",
    "# Select all genera\n",
    "#selected_genera = os.listdir(source_root)\n",
    "# create_datasets(training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root,\n",
    "#                     training_destination_root, existing_training_root, existing_testing_root, append)\n",
    "\n",
    "# Export metadata for existing training and testing data\n",
    "process_existing_files(training_destination_root, csv_path, export_csv=True)\n",
    "process_existing_files(testing_destination_root, csv_path, export_csv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a1099f",
   "metadata": {},
   "source": [
    "### Autoarborist: Print the number of images for the new training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b14c99d6-6169-4053-933c-601f72b02f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Directory Information:\n",
      "Directory: acer, Number of Files: 1187\n",
      "Directory: ailanthus, Number of Files: 1187\n",
      "Directory: betula, Number of Files: 1187\n",
      "Directory: citrus, Number of Files: 1187\n",
      "Directory: fraxinus, Number of Files: 1187\n",
      "Directory: gleditsia, Number of Files: 1187\n",
      "Directory: juglans, Number of Files: 1187\n",
      "Directory: juniperus, Number of Files: 1187\n",
      "Directory: magnolia, Number of Files: 1187\n",
      "Directory: phoenix, Number of Files: 1187\n",
      "Directory: picea, Number of Files: 1187\n",
      "Directory: pinus, Number of Files: 1187\n",
      "Directory: prunus, Number of Files: 1187\n",
      "Directory: pseudotsuga, Number of Files: 1187\n",
      "Directory: pyrus, Number of Files: 1187\n",
      "Directory: quercus, Number of Files: 1187\n",
      "Directory: rhus, Number of Files: 1187\n",
      "Directory: sequoia, Number of Files: 1187\n",
      "Directory: taxodium, Number of Files: 1187\n",
      "Directory: thuja, Number of Files: 1187\n",
      "Directory: tilia, Number of Files: 1187\n",
      "Directory: ulmus, Number of Files: 1187\n",
      "Directory: washingtonia, Number of Files: 1187\n",
      "/nTesting Directory Information:\n",
      "Directory: acer, Number of Files: 132\n",
      "Directory: ailanthus, Number of Files: 132\n",
      "Directory: betula, Number of Files: 132\n",
      "Directory: citrus, Number of Files: 132\n",
      "Directory: fraxinus, Number of Files: 132\n",
      "Directory: gleditsia, Number of Files: 132\n",
      "Directory: juglans, Number of Files: 132\n",
      "Directory: juniperus, Number of Files: 132\n",
      "Directory: magnolia, Number of Files: 132\n",
      "Directory: phoenix, Number of Files: 132\n",
      "Directory: picea, Number of Files: 132\n",
      "Directory: pinus, Number of Files: 132\n",
      "Directory: prunus, Number of Files: 132\n",
      "Directory: pseudotsuga, Number of Files: 132\n",
      "Directory: pyrus, Number of Files: 132\n",
      "Directory: quercus, Number of Files: 132\n",
      "Directory: rhus, Number of Files: 132\n",
      "Directory: sequoia, Number of Files: 132\n",
      "Directory: taxodium, Number of Files: 132\n",
      "Directory: thuja, Number of Files: 132\n",
      "Directory: tilia, Number of Files: 132\n",
      "Directory: ulmus, Number of Files: 132\n",
      "Directory: washingtonia, Number of Files: 132\n"
     ]
    }
   ],
   "source": [
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc72c8",
   "metadata": {},
   "source": [
    "### iNaturalist: Source, append, and create new testing and training datasets for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f3afcf1-3e9f-4c50-b543-ba359c2e04a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying existing images for acer to new training and testing folders.\n",
      "Updated max_training_images: 1187, max_testing_images: 132\n",
      "Total number of available images: 10000 for acer...\n",
      "Total number of images after excluding existing training and testing images: 10000 for acer...\n",
      "Copying new images for acer to new training and testing folders.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Select all genera\u001b[39;00m\n\u001b[0;32m     25\u001b[0m selected_genera \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(source_root)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mcreate_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_training_images_og\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_testing_images_og\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_genera\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_destination_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtraining_destination_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_training_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexisting_testing_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 161\u001b[0m, in \u001b[0;36mcreate_datasets\u001b[1;34m(training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root, training_destination_root, existing_training_root, existing_testing_root, append, csv_path)\u001b[0m\n\u001b[0;32m    159\u001b[0m         source_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(genus_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n\u001b[0;32m    160\u001b[0m     destination_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(training_destination_genus_path, image)\n\u001b[1;32m--> 161\u001b[0m     _\u001b[38;5;241m=\u001b[39m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# Copy testing images to the testing destination folder\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m testing_images:\n",
      "File \u001b[1;32mc:\\Users\\blaginh\\AppData\\Local\\miniconda3\\envs\\pytorch\\Lib\\shutil.py:436\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    435\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 436\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\blaginh\\AppData\\Local\\miniconda3\\envs\\pytorch\\Lib\\shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    254\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    259\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set the paths for Autoarborist training and testing data\n",
    "\n",
    "# Source: contains all available street view images of tree genera from iNaturalist\n",
    "source_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inat\\images\\original_10k\"\n",
    "\n",
    "# Target: location for images of tree genera as training data \n",
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_apr624\"\n",
    "\n",
    "# Target: location for images of tree genera as testing data \n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as training data used in previous experiments\n",
    "existing_training_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_apr624\"\n",
    "\n",
    "# Existing Target: location for existing images of tree genera as testing data used in previous experiments\n",
    "existing_testing_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Append: logical statement to append new images to existing training and testing data\n",
    "append = True\n",
    "\n",
    "# CSV path: location to save the CSV file containing the training and testing data\n",
    "csv_path = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\"\n",
    "\n",
    "# Select all genera\n",
    "selected_genera = os.listdir(source_root)\n",
    "create_datasets(training_ratio, max_training_images_og, max_testing_images_og, selected_genera, source_root, testing_destination_root,\n",
    "                    training_destination_root, existing_training_root, existing_testing_root, append,csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9a9fa",
   "metadata": {},
   "source": [
    "### iNaturalist: Print the number of images for the new training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14d7d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Directory Information:\n",
      "Directory: acer, Number of Files: 1187\n",
      "Directory: ailanthus, Number of Files: 900\n",
      "Directory: betula, Number of Files: 1187\n",
      "Directory: citrus, Number of Files: 1187\n",
      "Directory: fraxinus, Number of Files: 1187\n",
      "Directory: gleditsia, Number of Files: 1187\n",
      "Directory: juglans, Number of Files: 1187\n",
      "Directory: juniperus, Number of Files: 1187\n",
      "Directory: magnolia, Number of Files: 1187\n",
      "Directory: phoenix, Number of Files: 1187\n",
      "Directory: picea, Number of Files: 1187\n",
      "Directory: pinus, Number of Files: 1187\n",
      "Directory: prunus, Number of Files: 1187\n",
      "Directory: pseudotsuga, Number of Files: 1187\n",
      "Directory: pyrus, Number of Files: 1187\n",
      "Directory: quercus, Number of Files: 1187\n",
      "Directory: rhus, Number of Files: 1187\n",
      "Directory: sequoia, Number of Files: 1187\n",
      "Directory: taxodium, Number of Files: 1187\n",
      "Directory: thuja, Number of Files: 1187\n",
      "Directory: tilia, Number of Files: 1187\n",
      "Directory: ulmus, Number of Files: 1187\n",
      "Directory: washingtonia, Number of Files: 1187\n",
      "/nTesting Directory Information:\n",
      "Directory: acer, Number of Files: 132\n",
      "Directory: ailanthus, Number of Files: 100\n",
      "Directory: betula, Number of Files: 132\n",
      "Directory: citrus, Number of Files: 132\n",
      "Directory: fraxinus, Number of Files: 132\n",
      "Directory: gleditsia, Number of Files: 132\n",
      "Directory: juglans, Number of Files: 132\n",
      "Directory: juniperus, Number of Files: 132\n",
      "Directory: magnolia, Number of Files: 132\n",
      "Directory: phoenix, Number of Files: 132\n",
      "Directory: picea, Number of Files: 132\n",
      "Directory: pinus, Number of Files: 132\n",
      "Directory: prunus, Number of Files: 132\n",
      "Directory: pseudotsuga, Number of Files: 132\n",
      "Directory: pyrus, Number of Files: 132\n",
      "Directory: quercus, Number of Files: 132\n",
      "Directory: rhus, Number of Files: 132\n",
      "Directory: sequoia, Number of Files: 132\n",
      "Directory: taxodium, Number of Files: 132\n",
      "Directory: thuja, Number of Files: 132\n",
      "Directory: tilia, Number of Files: 132\n",
      "Directory: ulmus, Number of Files: 132\n",
      "Directory: washingtonia, Number of Files: 132\n"
     ]
    }
   ],
   "source": [
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c596c9e",
   "metadata": {},
   "source": [
    "### Autoarborist + iNaturalist: Combine Training and Testing Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e80829-11c0-4fe9-8280-cbd3a30ceaed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Autoarborist images for acer to the combined dataset.\n",
      "Copying Autoarborist images for ailanthus to the combined dataset.\n",
      "Copying Autoarborist images for betula to the combined dataset.\n",
      "Copying Autoarborist images for citrus to the combined dataset.\n",
      "Copying Autoarborist images for fraxinus to the combined dataset.\n",
      "Copying Autoarborist images for gleditsia to the combined dataset.\n",
      "Copying Autoarborist images for juglans to the combined dataset.\n",
      "Copying Autoarborist images for juniperus to the combined dataset.\n",
      "Copying Autoarborist images for magnolia to the combined dataset.\n",
      "Copying Autoarborist images for phoenix to the combined dataset.\n",
      "Copying Autoarborist images for picea to the combined dataset.\n",
      "Copying Autoarborist images for pinus to the combined dataset.\n",
      "Copying Autoarborist images for prunus to the combined dataset.\n",
      "Copying Autoarborist images for pseudotsuga to the combined dataset.\n",
      "Copying Autoarborist images for pyrus to the combined dataset.\n",
      "Copying Autoarborist images for quercus to the combined dataset.\n",
      "Copying Autoarborist images for rhus to the combined dataset.\n",
      "Copying Autoarborist images for sequoia to the combined dataset.\n",
      "Copying Autoarborist images for taxodium to the combined dataset.\n",
      "Copying Autoarborist images for thuja to the combined dataset.\n",
      "Copying Autoarborist images for tilia to the combined dataset.\n",
      "Copying Autoarborist images for ulmus to the combined dataset.\n",
      "Copying Autoarborist images for washingtonia to the combined dataset.\n",
      "Copying iNaturalist images for acer to the combined dataset.\n",
      "Copying iNaturalist images for ailanthus to the combined dataset.\n",
      "Copying iNaturalist images for betula to the combined dataset.\n",
      "Copying iNaturalist images for citrus to the combined dataset.\n",
      "Copying iNaturalist images for fraxinus to the combined dataset.\n",
      "Copying iNaturalist images for gleditsia to the combined dataset.\n",
      "Copying iNaturalist images for juglans to the combined dataset.\n",
      "Copying iNaturalist images for juniperus to the combined dataset.\n",
      "Copying iNaturalist images for magnolia to the combined dataset.\n",
      "Copying iNaturalist images for phoenix to the combined dataset.\n",
      "Copying iNaturalist images for picea to the combined dataset.\n",
      "Copying iNaturalist images for pinus to the combined dataset.\n",
      "Copying iNaturalist images for prunus to the combined dataset.\n",
      "Copying iNaturalist images for pseudotsuga to the combined dataset.\n",
      "Copying iNaturalist images for pyrus to the combined dataset.\n",
      "Copying iNaturalist images for quercus to the combined dataset.\n",
      "Copying iNaturalist images for rhus to the combined dataset.\n",
      "Copying iNaturalist images for sequoia to the combined dataset.\n",
      "Copying iNaturalist images for taxodium to the combined dataset.\n",
      "Copying iNaturalist images for thuja to the combined dataset.\n",
      "Copying iNaturalist images for tilia to the combined dataset.\n",
      "Copying iNaturalist images for ulmus to the combined dataset.\n",
      "Copying iNaturalist images for washingtonia to the combined dataset.\n",
      "Combined dataset created successfully.\n",
      "Combined metadata written to csv.\n"
     ]
    }
   ],
   "source": [
    "# Combine the training datasets\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_apr624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_apr624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\training_dataset_small_apr624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_apr624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_apr624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fe9933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Autoarborist images for acer to the combined dataset.\n",
      "Copying Autoarborist images for ailanthus to the combined dataset.\n",
      "Copying Autoarborist images for betula to the combined dataset.\n",
      "Copying Autoarborist images for citrus to the combined dataset.\n",
      "Copying Autoarborist images for cupaniopsis to the combined dataset.\n",
      "Copying Autoarborist images for erythrina to the combined dataset.\n",
      "Copying Autoarborist images for fraxinus to the combined dataset.\n",
      "Copying Autoarborist images for gleditsia to the combined dataset.\n",
      "Copying Autoarborist images for juglans to the combined dataset.\n",
      "Copying Autoarborist images for juniperus to the combined dataset.\n",
      "Copying Autoarborist images for magnolia to the combined dataset.\n",
      "Copying Autoarborist images for phoenix to the combined dataset.\n",
      "Copying Autoarborist images for picea to the combined dataset.\n",
      "Copying Autoarborist images for pinus to the combined dataset.\n",
      "Copying Autoarborist images for prunus to the combined dataset.\n",
      "Copying Autoarborist images for pseudotsuga to the combined dataset.\n",
      "Copying Autoarborist images for pyrus to the combined dataset.\n",
      "Copying Autoarborist images for quercus to the combined dataset.\n",
      "Copying Autoarborist images for rhus to the combined dataset.\n",
      "Copying Autoarborist images for sequoia to the combined dataset.\n",
      "Copying Autoarborist images for taxodium to the combined dataset.\n",
      "Copying Autoarborist images for thuja to the combined dataset.\n",
      "Copying Autoarborist images for tilia to the combined dataset.\n",
      "Copying Autoarborist images for ulmus to the combined dataset.\n",
      "Copying Autoarborist images for washingtonia to the combined dataset.\n",
      "Copying iNaturalist images for acer to the combined dataset.\n",
      "Copying iNaturalist images for ailanthus to the combined dataset.\n",
      "Copying iNaturalist images for betula to the combined dataset.\n",
      "Copying iNaturalist images for citrus to the combined dataset.\n",
      "Copying iNaturalist images for cupaniopsis to the combined dataset.\n",
      "Copying iNaturalist images for erythrina to the combined dataset.\n",
      "Copying iNaturalist images for fraxinus to the combined dataset.\n",
      "Copying iNaturalist images for gleditsia to the combined dataset.\n",
      "Copying iNaturalist images for juglans to the combined dataset.\n",
      "Copying iNaturalist images for juniperus to the combined dataset.\n",
      "Copying iNaturalist images for magnolia to the combined dataset.\n",
      "Copying iNaturalist images for phoenix to the combined dataset.\n",
      "Copying iNaturalist images for picea to the combined dataset.\n",
      "Copying iNaturalist images for pinus to the combined dataset.\n",
      "Copying iNaturalist images for prunus to the combined dataset.\n",
      "Copying iNaturalist images for pseudotsuga to the combined dataset.\n",
      "Copying iNaturalist images for pyrus to the combined dataset.\n",
      "Copying iNaturalist images for quercus to the combined dataset.\n",
      "Copying iNaturalist images for rhus to the combined dataset.\n",
      "Copying iNaturalist images for sequoia to the combined dataset.\n",
      "Copying iNaturalist images for taxodium to the combined dataset.\n",
      "Copying iNaturalist images for thuja to the combined dataset.\n",
      "Copying iNaturalist images for tilia to the combined dataset.\n",
      "Copying iNaturalist images for ulmus to the combined dataset.\n",
      "Copying iNaturalist images for washingtonia to the combined dataset.\n",
      "Combined dataset created successfully.\n",
      "Combined metadata written to csv.\n",
      "Copying Autoarborist images for acer to the combined dataset.\n",
      "Copying Autoarborist images for ailanthus to the combined dataset.\n",
      "Copying Autoarborist images for betula to the combined dataset.\n",
      "Copying Autoarborist images for citrus to the combined dataset.\n",
      "Copying Autoarborist images for cupaniopsis to the combined dataset.\n",
      "Copying Autoarborist images for erythrina to the combined dataset.\n",
      "Copying Autoarborist images for fraxinus to the combined dataset.\n",
      "Copying Autoarborist images for gleditsia to the combined dataset.\n",
      "Copying Autoarborist images for juglans to the combined dataset.\n",
      "Copying Autoarborist images for juniperus to the combined dataset.\n",
      "Copying Autoarborist images for magnolia to the combined dataset.\n",
      "Copying Autoarborist images for phoenix to the combined dataset.\n",
      "Copying Autoarborist images for picea to the combined dataset.\n",
      "Copying Autoarborist images for pinus to the combined dataset.\n",
      "Copying Autoarborist images for prunus to the combined dataset.\n",
      "Copying Autoarborist images for pseudotsuga to the combined dataset.\n",
      "Copying Autoarborist images for pyrus to the combined dataset.\n",
      "Copying Autoarborist images for quercus to the combined dataset.\n",
      "Copying Autoarborist images for rhus to the combined dataset.\n",
      "Copying Autoarborist images for sequoia to the combined dataset.\n",
      "Copying Autoarborist images for taxodium to the combined dataset.\n",
      "Copying Autoarborist images for thuja to the combined dataset.\n",
      "Copying Autoarborist images for tilia to the combined dataset.\n",
      "Copying Autoarborist images for ulmus to the combined dataset.\n",
      "Copying Autoarborist images for washingtonia to the combined dataset.\n",
      "Copying iNaturalist images for acer to the combined dataset.\n",
      "Copying iNaturalist images for ailanthus to the combined dataset.\n",
      "Copying iNaturalist images for betula to the combined dataset.\n",
      "Copying iNaturalist images for citrus to the combined dataset.\n",
      "Copying iNaturalist images for cupaniopsis to the combined dataset.\n",
      "Copying iNaturalist images for erythrina to the combined dataset.\n",
      "Copying iNaturalist images for fraxinus to the combined dataset.\n",
      "Copying iNaturalist images for gleditsia to the combined dataset.\n",
      "Copying iNaturalist images for juglans to the combined dataset.\n",
      "Copying iNaturalist images for juniperus to the combined dataset.\n",
      "Copying iNaturalist images for magnolia to the combined dataset.\n",
      "Copying iNaturalist images for phoenix to the combined dataset.\n",
      "Copying iNaturalist images for picea to the combined dataset.\n",
      "Copying iNaturalist images for pinus to the combined dataset.\n",
      "Copying iNaturalist images for prunus to the combined dataset.\n",
      "Copying iNaturalist images for pseudotsuga to the combined dataset.\n",
      "Copying iNaturalist images for pyrus to the combined dataset.\n",
      "Copying iNaturalist images for quercus to the combined dataset.\n",
      "Copying iNaturalist images for rhus to the combined dataset.\n",
      "Copying iNaturalist images for sequoia to the combined dataset.\n",
      "Copying iNaturalist images for taxodium to the combined dataset.\n",
      "Copying iNaturalist images for thuja to the combined dataset.\n",
      "Copying iNaturalist images for tilia to the combined dataset.\n",
      "Copying iNaturalist images for ulmus to the combined dataset.\n",
      "Copying iNaturalist images for washingtonia to the combined dataset.\n",
      "Combined dataset created successfully.\n",
      "Combined metadata written to csv.\n"
     ]
    }
   ],
   "source": [
    "# DELETE CODE CHUNK AFTER PROCESSING\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\training_dataset_small_march624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\training_dataset_small_march624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\training_dataset_small_march624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)\n",
    "\n",
    "# Set the paths for the combined training dataset\n",
    "autoarborist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\autoarborist\\testing_dataset_small_march624\"\n",
    "inaturalist_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\inaturalist\\testing_dataset_small_march624\"\n",
    "combined_dataset_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\testing_dataset_small_march624\"\n",
    "\n",
    "# Combine the training datasets\n",
    "combine_datasets(autoarborist_dataset_root, inaturalist_dataset_root, combined_dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1664a",
   "metadata": {},
   "source": [
    "### Autoarborist + iNaturalist: Print the number of images for the new training and testing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2d30909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Directory Information:\n",
      "Directory: acer, Number of Files: 2374\n",
      "Directory: ailanthus, Number of Files: 2087\n",
      "Directory: betula, Number of Files: 2374\n",
      "Directory: citrus, Number of Files: 2374\n",
      "Directory: fraxinus, Number of Files: 2374\n",
      "Directory: gleditsia, Number of Files: 2374\n",
      "Directory: juglans, Number of Files: 2374\n",
      "Directory: juniperus, Number of Files: 2374\n",
      "Directory: magnolia, Number of Files: 2374\n",
      "Directory: phoenix, Number of Files: 2374\n",
      "Directory: picea, Number of Files: 2374\n",
      "Directory: pinus, Number of Files: 2374\n",
      "Directory: prunus, Number of Files: 2374\n",
      "Directory: pseudotsuga, Number of Files: 2374\n",
      "Directory: pyrus, Number of Files: 2374\n",
      "Directory: quercus, Number of Files: 2374\n",
      "Directory: rhus, Number of Files: 2374\n",
      "Directory: sequoia, Number of Files: 2374\n",
      "Directory: taxodium, Number of Files: 2374\n",
      "Directory: thuja, Number of Files: 2374\n",
      "Directory: tilia, Number of Files: 2374\n",
      "Directory: ulmus, Number of Files: 2374\n",
      "Directory: washingtonia, Number of Files: 2374\n",
      "/nTesting Directory Information:\n",
      "Directory: acer, Number of Files: 264\n",
      "Directory: ailanthus, Number of Files: 232\n",
      "Directory: betula, Number of Files: 264\n",
      "Directory: citrus, Number of Files: 264\n",
      "Directory: fraxinus, Number of Files: 264\n",
      "Directory: gleditsia, Number of Files: 264\n",
      "Directory: juglans, Number of Files: 264\n",
      "Directory: juniperus, Number of Files: 264\n",
      "Directory: magnolia, Number of Files: 264\n",
      "Directory: phoenix, Number of Files: 264\n",
      "Directory: picea, Number of Files: 264\n",
      "Directory: pinus, Number of Files: 264\n",
      "Directory: prunus, Number of Files: 264\n",
      "Directory: pseudotsuga, Number of Files: 264\n",
      "Directory: pyrus, Number of Files: 264\n",
      "Directory: quercus, Number of Files: 264\n",
      "Directory: rhus, Number of Files: 264\n",
      "Directory: sequoia, Number of Files: 264\n",
      "Directory: taxodium, Number of Files: 264\n",
      "Directory: thuja, Number of Files: 264\n",
      "Directory: tilia, Number of Files: 264\n",
      "Directory: ulmus, Number of Files: 264\n",
      "Directory: washingtonia, Number of Files: 264\n"
     ]
    }
   ],
   "source": [
    "training_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\training_dataset_small_apr624\"\n",
    "testing_destination_root = r\"Z:\\auto_arborist_cvpr2022_v0.15\\data\\tree_classification\\aa_inat_combined\\testing_dataset_small_apr624\"\n",
    "\n",
    "# Print information for the training directory\n",
    "print(\"Training Directory Information:\")\n",
    "print_directory_info(training_destination_root)\n",
    "\n",
    "# Print information for the testing directory\n",
    "print(\"/nTesting Directory Information:\")\n",
    "print_directory_info(testing_destination_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62102bfd",
   "metadata": {},
   "source": [
    "## Setup EfficientNetv2 model to run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c52ebf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to prepare a Basic Model for Image Classification\n",
    "\n",
    "class ImageClassificationBase(nn.Module): # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
    "    # Define a base class with functionality for model training, validation, and evaluation per epoch\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels) # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# Functions to define a CNN Model using EfficientNetV2-S\n",
    "\n",
    "class EfficientNetImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained EfficientNetV2-L Model\n",
    "        self.network = torchvision.models.efficientnet_v2_s(pretrained=True)\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = len(train_dataset.classes)\n",
    "        in_features = self.network.classifier[1].in_features\n",
    "        self.network.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "# Functions  to visualize training data\n",
    "def display_img(img,label):\n",
    "    print(f\"Label : {train_dataset.classes[label]}\")\n",
    "    plt.imshow(img.permute(1,2,0)) #reshape image from (3, H, W) to (H, W, 3)\n",
    "\n",
    "def show_batch(dl):\n",
    "    \"\"\"Plot images grid of single batch\"\"\"\n",
    "    for images, labels in dl:\n",
    "        fig,ax = plt.subplots(figsize = (16,12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n",
    "        break\n",
    "\n",
    "# Functions to define GPU device and load data to GPU\n",
    "def get_default_device():\n",
    "    \"\"\" Set Device to GPU or CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"Move data to the device\"\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking = True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n",
    "    \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\" Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches \"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "# Functions to define training and evaluation functions\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "# Fit model\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
    "    \n",
    "    history = []\n",
    "    # Create optimizer with initial learning rate\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            # Forward pass: prediction & calculate loss\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            # Backward pass: backpropagate loss & calculate gradients\n",
    "            loss.backward()\n",
    "            optimizer.step() #update gradients\n",
    "            optimizer.zero_grad() #zero gradients for next training forward pass\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history\n",
    "\n",
    "# Functions to visualize the results\n",
    "\n",
    "def plot_accuracies(history):\n",
    "    \"\"\" Plot the history of accuracies\"\"\"\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n",
    "\n",
    "def plot_losses(history):\n",
    "    \"\"\" Plot the losses in each epoch\"\"\"\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "\n",
    "# Constant variables: number of epochs, optimizer function, learning rate, and warmup epochs\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','fraxinus','gleditsia','juglans','juniperus', 'magnolia','phoenix','picea',\n",
    "                     'pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium', 'thuja','tilia','ulmus','washingtonia']\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "base_lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6891a53",
   "metadata": {},
   "source": [
    "### Experiment 1: The effect of decreased resolution (512x512) on CNN image classification performance.\n",
    "\n",
    "Hypothesis: decreased resolution will result in decreased performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b92ec",
   "metadata": {},
   "source": [
    "#### Define Image Augumentations - Update paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0358319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the training and testing datasets (AutoArborist, iNaturalist, or combined) by specifying the file paths.\n",
    "training_destination_root = r\"D:\\blaginh\\tree_classification\\aa_inat_combined\\training_dataset_small_march624\"\n",
    "testing_destination_root = r\"D:\\blaginh\\tree_classification\\aa_inat_combined\\testing_dataset_small_march624\"\n",
    "\n",
    "# Use Pytorch ImageFolder class to prepare training and testing datasets\n",
    "train_data_dir = training_destination_root\n",
    "test_data_dir = testing_destination_root\n",
    "\n",
    "# Load the training and testing datasets as Pytorch Dataset Classes: https://pytorch.org/docs/stable/data.html\n",
    "# The Pytorch torchvision.transforms module provides preprocessing functions: https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    #v2.RandomResizedCrop(size=(512, 512), antialias=True),\n",
    "    v2.RandomResizedCrop(size=(256, 256), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Ensure images are resized during testing as same dimension for training\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    #v2.Resize(size=(512, 512), antialias=True),\n",
    "    v2.Resize(size=(256, 256), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(train_data_dir, transform = train_transforms)\n",
    "test_dataset = ImageFolder(test_data_dir, transform = test_transforms)\n",
    "\n",
    "# Examine the train_dataset object\n",
    "train_dataset\n",
    "\n",
    "# Examine image dimensions: (3 channels, height 64, width 64)\n",
    "img, label = train_dataset[0]\n",
    "print(img.shape,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b78453",
   "metadata": {},
   "source": [
    "#### Define training, validation, and testing data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe26fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into a validation set, and prepare dataset for training\n",
    "\n",
    "# Define batch size for training \n",
    "bs = 32\n",
    "\n",
    "# Define number of images for validation (typically, 10% of the training set)\n",
    "val_size = 2000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "# Randomly split training data into train_data and val_data sets\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Length of Train Data : {len(train_data)}\") # Length of Train Data : 20000\n",
    "print(f\"Length of Validation Data : {len(val_data)}\") # Length of Validation Data : 2000\n",
    "\n",
    "# Use Pytorch DataLoader Class to iterate over a dataset for training: https://pytorch.org/docs/stable/data\n",
    "\n",
    "train_dl = DataLoader(dataset = train_data, batch_size = bs, shuffle = True, num_workers = 4, pin_memory = True)\n",
    "val_dl = DataLoader(dataset = val_data, batch_size = bs*2, num_workers = 4, pin_memory = True)\n",
    "test_dl = DataLoader(dataset = test_dataset, batch_size = 1, num_workers = 4, pin_memory = True)\n",
    "\n",
    "# Instantiate the model\n",
    "model = EfficientNetImageClassification()\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(f'Number of Model Parameters: ', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1411ca9",
   "metadata": {},
   "source": [
    "#### Print number of classes in train and test datasets, and visualize sample image and single batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many classes are in the training and testing datasets?\n",
    "print(\"Classes in the Training Dataset : /n\", len(train_dataset.classes))\n",
    "print(\"Classes in the Testing Dataset : /n\", len(test_dataset.classes))\n",
    "\n",
    "# Display the first image in the dataset\n",
    "display_img(*train_dataset[2])\n",
    "\n",
    "# Visualize a single batch of images\n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae4680",
   "metadata": {},
   "source": [
    "#### Load data to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GPU Device\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Load data to GPU\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "to_device(model, device)\n",
    "\n",
    "# Load the model to the GPU\n",
    "model = to_device(EfficientNetImageClassification(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1028331b",
   "metadata": {},
   "source": [
    "#### Fit and Save Model - update path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee900cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and record result after epoch\n",
    "# Model history contains training loss, validation loss, and validation accuracy metrics\n",
    "history = fit(num_epochs, base_lr, model, train_dl, val_dl, opt_func)\n",
    "\n",
    "# Save the model weights file to path\n",
    "model_path = r'C:\\Users\\talake2\\Desktop\\tree-classification-autoarb_inat-25-genera-1000imgs-effnet2s-10epochs-lr001-aug-march724.pth'\n",
    "\n",
    "# Torch.Save model to file: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d70248",
   "metadata": {},
   "source": [
    "#### Visualize model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6789f",
   "metadata": {},
   "source": [
    "##### Accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy and loss curves\n",
    "plot_accuracies(history)\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24cf5d",
   "metadata": {},
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation with Confusion Matrix\n",
    "# Iterate over test dataset and generate predictions for a confusion matrix\n",
    "selected_genera = ['acer','ailanthus','betula','citrus','cupaniopsis','erythrina','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "#model.cuda()  # Move model to CUDA if not already there\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode.\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(output, dim=1).cpu().numpy()  # Extract predicted labels directly\n",
    "        y_pred.extend(output)\n",
    "        \n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "disp = ConfusionMatrixDisplay(cf_matrix, display_labels=selected_genera)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', ax=ax)\n",
    "plt.savefig(r\"C:\\Users\\talake2\\Desktop\\auto_arborist_cvpr2022_v015\\pytorch_cnn_classifier_experiments_jan24\\autoarborist_inaturalist_models_march2024\\tree-classification-inat-25-genera-1000imgs-effnet2s-10epochs-lr001-march724.png\", dpi=200)\n",
    "#plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4fb0",
   "metadata": {},
   "source": [
    "##### Precision, recall, F1, support per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names = selected_genera))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a879242",
   "metadata": {},
   "source": [
    "##### Classification of single image - update path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant for classes    \n",
    "classes = selected_genera\n",
    "\n",
    "img_path = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/auto_arborist_jpegs/jpegs_aerial_streetlevel_raw/all_cities_streetview/train/acer/streetlevel_4_7.jpg'\n",
    "img = imread(img_path)\n",
    "img.shape\n",
    "\n",
    "# Resize the image\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "# Convert image to tensor using torchvision.transforms.ToTensor()\n",
    "transform = transforms.ToTensor()\n",
    "img = transform(img) #Transforms image to [0-1] and channels first\n",
    "img = img.unsqueeze(0) #add first dimension of batch size\n",
    "img = img.cuda() #push to GPU\n",
    "\n",
    "#prdict image label\n",
    "output = model(img)\n",
    "\n",
    "# Get the index of the maximum value in the output tensor\n",
    "predicted_class_index = torch.argmax(output)\n",
    "\n",
    "# Use the index to get the corresponding class label\n",
    "predicted_class_label = classes[predicted_class_index.item()]\n",
    "\n",
    "print(\"Predicted Class Label:\", predicted_class_label)\n",
    "\n",
    "# Get the top 5 class predictions\n",
    "top5_probabilities, top5_indices = torch.topk(output, 5)\n",
    "\n",
    "# Convert indices to class labels\n",
    "top5_class_labels = [classes[i] for i in top5_indices.squeeze().tolist()]\n",
    "\n",
    "print(\"Top 5 Predicted Class Labels:\", top5_class_labels)\n",
    "print(\"Top 5 Predicted Probabilities:\", top5_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
