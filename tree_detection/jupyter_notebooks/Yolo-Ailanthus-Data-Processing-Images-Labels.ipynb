{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3280e565-f137-471e-8352-d2cb7b700197",
   "metadata": {},
   "source": [
    "# Preprocess Labelled Image Data for use in YOLO Model\n",
    "\n",
    "This notebook contains a collection of functions/scripts to preprocess labelled images of target host trees for object detection.\n",
    "Included are functions to generate summaries of bounding boxes/ remove images with large bounding boxes (i.e. those for classification, not detection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013bd900-2b3b-4d5e-8411-8c0c53df0dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import Libraries\n",
    "import tqdm\n",
    "from glob import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Image Libraries\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c52965-aaaf-4e90-ac2c-4232a9275ce1",
   "metadata": {},
   "source": [
    "# Process and modify class labels in .txt files\n",
    "\n",
    "In YOLO models, all labels must match a corresponding image and should start from an index of 0.\n",
    "\n",
    "In one case, the \"tree\" class has the label 3.\n",
    "\n",
    "All instances of the \"Ailanthus\" should have the label 1.\n",
    "\n",
    "For positive Ailanthus labels, change the class value in each txt label file to the class index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "744353fc-9cb9-4e22-b888-808f3fa6afae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Indices in Labels: ['\\n' '0' '1']\n",
      "Number of Labels per Class: {'0': 22156, '\\n': 29479, '1': 7323}\n"
     ]
    }
   ],
   "source": [
    "# Count all unique class indices in the dataset (first value in labels.txt files)\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "#txt_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_2200ailanthus_10000trees_images_labels_dec23/all_labels'\n",
    "\n",
    "txt_directory = r'C:\\Users\\talake2\\Desktop\\auto_arborist_cvpr2022_v015\\yolov5\\datasets\\autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324\\all_labels'\n",
    "\n",
    "# Dictionary to store counts of each class\n",
    "class_counts = {}\n",
    "\n",
    "# Iterate through .txt files and modify the content\n",
    "for filename in os.listdir(txt_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        txt_file_path = os.path.join(txt_directory, filename)\n",
    "        with open(txt_file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            lines = file.readlines()\n",
    "            #print(lines)\n",
    "        \n",
    "        all_class_indices = []\n",
    "        for line in lines:\n",
    "            values = line.split(' ') # split values by space delimiter\n",
    "            class_index = values[0]\n",
    "\n",
    "            # Count occurrences of each class\n",
    "            if class_index in class_counts:\n",
    "                class_counts[class_index] += 1\n",
    "            else:\n",
    "                class_counts[class_index] = 1\n",
    "\n",
    "# Print unique class indices and their counts\n",
    "print(f'Class Indices in Labels: {np.unique(list(class_counts.keys()))}')\n",
    "print(f'Number of Labels per Class: {class_counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d639b2f-11ae-42a0-926d-0e885983d893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unwanted labels and label files\n",
    "# Here, we remove any lines that do not start with class 0 (Trees) and class 3 (Ailanthus)\n",
    "\n",
    "txt_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_images_labels_dec23/labels'\n",
    "\n",
    "# Iterate through .txt files and modify the content\n",
    "for filename in os.listdir(txt_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        txt_file_path = os.path.join(txt_directory, filename)\n",
    "        with open(txt_file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            lines = file.readlines()\n",
    "\n",
    "        modified_lines = []  # Modify the first value of each line\n",
    "        for line in lines:\n",
    "            values = line.split()  # Split values by space delimiter\n",
    "\n",
    "            # Check if the line starts with '0', keep it; otherwise, remove it\n",
    "            if values[0] == '0':\n",
    "                modified_lines.append(line)\n",
    "            if values[0] == '3':\n",
    "                modified_lines.append(line)\n",
    "\n",
    "        # Write the modified content back to the file\n",
    "        with open(txt_file_path, 'w') as file:\n",
    "            file.writelines(modified_lines)\n",
    "\n",
    "        print(f\"Modified {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb937b-55c3-422c-84c7-681a2824b736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify Class Labels for Trees to begin with 0 and Ailanthus to begin with index 1\n",
    "\n",
    "# Example Label: Ailanthus_altissima_112403.txt 1 0.497737556561086 0.4819004524886878 0.9864253393665159 0.9547511312217195\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "txt_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/googlestreetview_ailanthus_images_labels_dec23/labels'\n",
    "\n",
    "# Iterate through .txt files and modify the content\n",
    "for filename in os.listdir(txt_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        txt_file_path = os.path.join(txt_directory, filename)\n",
    "        with open(txt_file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            lines = file.readlines()\n",
    "            #print(lines)\n",
    "\n",
    "        modified_lines = []  # Modify the first value of each line\n",
    "        for line in lines:\n",
    "            values = line.split()  # Split values by space delimiter\n",
    "            #print(values[0])\n",
    "            if values[0] == '0':  # Check if the line contains the class label index specific to the speciesChange the first class index value to '1'\n",
    "                #print(\"Tree\")\n",
    "                values[0] = '1' # Change the label index to the correct index\n",
    "                modified_lines.append(' '.join(values) + os.linesep) #append each line with a Unix '/n' newline LF character\n",
    "            elif values[0] == '1':\n",
    "                values[0] = '0'\n",
    "                #print(\"Ailanthus\")\n",
    "                modified_lines.append(' '.join(values) + os.linesep) #append each line with a Unix '/n' newline LF character\n",
    "                \n",
    "\n",
    "        #print(modified_lines)\n",
    "        # Write the modified content back to the file\n",
    "        with open(txt_file_path, 'w') as file:\n",
    "            file.writelines(modified_lines)\n",
    "\n",
    "        print(f\"Modified {filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c930b37-5b6f-402e-9a86-14cba236d532",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get Images from Labels by Filename\n",
    "\n",
    "In LabelStudio, export labels as the \"YOLO\" Format. \n",
    "A .TXT format is created for each image file. Each txt file contains annotations for the corresponding image file, that is object class, object coordinates, height & width.\n",
    "\n",
    "As the .TXT format label files are named identically to the .JPG images, search through an image directory and pull the images to a new folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3731f-000b-48a7-87da-6c0e9819ada7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Path to the directory containing .txt files\n",
    "# This is the export directory from LabelStudio, often named 'project-number-at-year-month-day.zip'\n",
    "labels_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_images_labels_dec23/labels'\n",
    "\n",
    "# Network drive or local directory containing images to search for using labels\n",
    "network_drive = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/auto_arborist_jpegs/jpegs_streetlevel_genus_idx_label/ailanthus/images'\n",
    "\n",
    "# Destination directory to copy the images\n",
    "destination_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_images_labels_dec23/images'\n",
    "\n",
    "# Iterate through .txt files and copy corresponding images\n",
    "for filename in os.listdir(labels_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Extract the image file name without extension from the .txt file\n",
    "        image_filename = os.path.splitext(filename)[0] + '.jpeg'\n",
    "        \n",
    "        # Check if the corresponding image file exists in the network drive\n",
    "        source_image_path = os.path.join(network_drive, image_filename)\n",
    "        if os.path.exists(source_image_path):\n",
    "            # Copy the image file to the destination directory\n",
    "            destination_image_path = os.path.join(destination_directory, image_filename)\n",
    "            shutil.copy2(source_image_path, destination_image_path)\n",
    "            print(f\"Copied: {image_filename}\")\n",
    "\n",
    "print(\"Copying completed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d35a06-1f9c-405e-be0e-b0a539d47b4e",
   "metadata": {},
   "source": [
    "# Resize image dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6b033-0352-415a-9459-ee85ed317a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resize iNaturalist images to match dimensions of autoarborist dataset\n",
    "# Input iNaturalist image size: XXX x XXX pixels\n",
    "# Target image size: 768 x 1152 pixels\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Path to the directory containing .jpg images\n",
    "image_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_images_labels_dec23/test/images/'\n",
    "\n",
    "txt_directory = r'C:/Users/talake2/Desktop/ailanthus_labelstudio_nov1323/labels'\n",
    "\n",
    "# New dimensions for the resized image\n",
    "new_width = 768\n",
    "new_height = 768\n",
    "\n",
    "# Iterate through .jpg files and their corresponding .txt files\n",
    "for filename in os.listdir(image_directory):\n",
    "    if filename.endswith('.jpeg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize the image\n",
    "        resized_img = cv2.resize(img, (new_width, new_height))\n",
    "    \n",
    "        # Save resized image\n",
    "        cv2.imwrite(image_path, resized_img)\n",
    "        \n",
    "        print(f\"Resized and saved: {filename}\")\n",
    "\n",
    "print(\"Resizing completed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0b15b-25e7-4b11-9a25-022d821b47da",
   "metadata": {},
   "source": [
    "# Subset Autoarborist Tree Images and Labels for Training and Testing\n",
    "\n",
    "Randomly select Images of Trees from Autoarborist and Ailanthus (From Autoarborist) Combined into Training and Testing Directories\n",
    "\n",
    "Images are randomly shuffled and sampled to avoid duplicating images in both training and testing directories.\n",
    "\n",
    "Files are copied from their respective source directories to a common target directory containing the training and testing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604d9231-de98-40c6-8ac3-07baacd44a53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying 5739 training images and labels of Ailanthus: complete.\n",
      "Copying 1435 testing images and labels of Ailanthus: complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Subset Autoarborist Tree Images and Labels for Training and Testing\n",
    "\n",
    "# Define whether to copy images and labels to the training or testing directory, and how many to copy\n",
    "num_files_per_source = 7174 #total number of files in /images or /labels\n",
    "\n",
    "# Directory Structure\n",
    "# YOLO Model Datasets Directory -> 'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/'\n",
    "# Create Directory for Your Dataset -> 'autoarborist_ailanthus_images_nov2723/'\n",
    "# Create Training, Testing, and (optionally: Validation) Directories -> test/ train/\n",
    "# Within Each TTV Directory, Create /images (.jpegs) and /labels (.txt) to train the YOLO model\n",
    "\n",
    "\n",
    "# Source 1: Trees Data\n",
    "# Autoarborist Trees Images Directory (All Autoarborist tree images)\n",
    "autoarb_image_directory = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_full/train/images/'\n",
    "# Autoarborist Trees Labels Directory (All Autoarborist tree labels)\n",
    "autoarb_label_directory = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_full/train/labels/'\n",
    "\n",
    "\n",
    "# Source 2: Ailanthus Data\n",
    "# Autoarborist Ailanthus Images Directory\n",
    "autoarb_ailanthus_image_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324/all_images/'\n",
    "# Autoarborist Ailanthus Labels Directory\n",
    "autoarb_ailanthus_label_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324/all_labels/'\n",
    "\n",
    "\n",
    "# Target: YoloV5 Datasets with Trees and Ailanthus Data\n",
    "#### Training Directories\n",
    "# Target image directory\n",
    "yolo_training_image_directory = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324/train/images/'\n",
    "# Target label directory\n",
    "yolo_training_label_directory = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324/train/labels/'\n",
    "\n",
    "\n",
    "#### Testing Directories\n",
    "# Target image directory\n",
    "yolo_testing_image_directory = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324/test/images/'\n",
    "# Target label directory\n",
    "yolo_testing_label_directory = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324/test/labels/'\n",
    "\n",
    "\n",
    "# Get a list of all image files in the source directories\n",
    "trees_image_files = [filename for filename in os.listdir(autoarb_image_directory) if filename.endswith((\".jpg\", \".jpeg\"))]\n",
    "ailanthus_image_files = [filename for filename in os.listdir(autoarb_ailanthus_image_directory) if filename.endswith((\".jpg\", \".jpeg\"))]\n",
    "\n",
    "# Shuffle the lists of image files\n",
    "random.shuffle(trees_image_files)\n",
    "random.shuffle(ailanthus_image_files)\n",
    "\n",
    "# Sample an equal number of images from each source directory\n",
    "selected_trees_images = random.sample(trees_image_files, num_files_per_source)\n",
    "selected_ailanthus_images = random.sample(ailanthus_image_files, num_files_per_source)\n",
    "\n",
    "# Split the selected images into training and testing sets\n",
    "split_index = int(0.8 * num_files_per_source)  # 80% for training, 20% for testing\n",
    "trees_training_images = selected_trees_images[:split_index]\n",
    "trees_testing_images = selected_trees_images[split_index:]\n",
    "\n",
    "ailanthus_training_images = selected_ailanthus_images[:split_index]\n",
    "ailanthus_testing_images = selected_ailanthus_images[split_index:]\n",
    "\n",
    "def copy_files(source_image_directory, source_label_directory, target_image_directory, target_label_directory, files):\n",
    "    for file in files:\n",
    "        # Extract the file name without extension to find the corresponding label file\n",
    "        file_name_without_extension, _ = os.path.splitext(file)\n",
    "        label_file = file_name_without_extension + \".txt\"\n",
    "\n",
    "        # Create source and target file paths\n",
    "        source_image_path = os.path.join(source_image_directory, file)\n",
    "        source_label_path = os.path.join(source_label_directory, label_file)\n",
    "        target_image_path = os.path.join(target_image_directory, file)\n",
    "        target_label_path = os.path.join(target_label_directory, label_file)\n",
    "\n",
    "        #print(source_image_path)\n",
    "        #print(source_label_path)\n",
    "        #print(target_image_path)\n",
    "        #print(target_label_path)\n",
    "        \n",
    "        # Check if the label file exists before copying\n",
    "        if os.path.exists(source_label_path):\n",
    "            if os.path.exists(source_image_path):\n",
    "                #print(\"Path Exists, Copying Data\")\n",
    "                # Copy matching image and label files to the target directories\n",
    "                shutil.copy2(source_image_path, target_image_path)\n",
    "                shutil.copy2(source_label_path, target_label_path)\n",
    "        else:\n",
    "            pass\n",
    "            #print(f\"Label file not found for {file}. Skipping.\")\n",
    "\n",
    "\n",
    "# Training Data\n",
    "# Copy trees training images and labels\n",
    "#copy_files(autoarb_image_directory, autoarb_label_directory, yolo_training_image_directory, yolo_training_label_directory, trees_training_images)\n",
    "#print(f\"Copying {len(trees_training_images)} training images and labels of Trees: complete.\")\n",
    "\n",
    "# Copy ailanthus training images and labels\n",
    "copy_files(autoarb_ailanthus_image_directory, autoarb_ailanthus_label_directory, yolo_training_image_directory, yolo_training_label_directory, ailanthus_training_images)\n",
    "print(f\"Copying {len(ailanthus_training_images)} training images and labels of Ailanthus: complete.\")\n",
    "\n",
    "# Testing Data\n",
    "# Copy trees training images and labels\n",
    "#copy_files(autoarb_image_directory, autoarb_label_directory, yolo_testing_image_directory, yolo_testing_label_directory, trees_testing_images)\n",
    "#print(f\"Copying {len(trees_testing_images)} testing images and labels of Trees: complete.\")\n",
    "\n",
    "# Copy aialanthus training images and labels\n",
    "copy_files(autoarb_ailanthus_image_directory, autoarb_ailanthus_label_directory, yolo_testing_image_directory, yolo_testing_label_directory, ailanthus_testing_images)\n",
    "print(f\"Copying {len(ailanthus_testing_images)} testing images and labels of Ailanthus: complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5e616-e9a8-4c4a-9e3e-9c853dfca94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(trees_training_images))\n",
    "print(len(trees_testing_images))\n",
    "print(len(ailanthus_training_images))\n",
    "print(len(ailanthus_testing_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c438102-8912-42e0-97d2-5b9b632dc997",
   "metadata": {},
   "source": [
    "# Experiments with Curriculum Learning\n",
    "\n",
    "Non-randomly select Images of Trees from Autoarborist and Ailanthus (From Autoarborist) Combined into Training and Testing Directories\n",
    "\n",
    "From available genera of trees - some genera are likely to be \"easier\" or \"harder\" to classify/misclassify as Ailanthus.\n",
    "\n",
    "Images are randomly shuffled and sampled to avoid duplicating images in both training and testing directories.\n",
    "\n",
    "Files are copied from their respective source directories to a common target directory containing the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0e97b-7a6a-4e03-845a-6ecb41ab30e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select Specific Trees Genera From Autoarborist to Include For Training based on Difficulty of Sample (Experiment: Easy vs Hard Samples)\n",
    "\n",
    "# 'Hard' Genera are those that are often misclassified as Ailanthus, or those with prior knowledge to be Ailanthus 'lookalikes'\n",
    "\n",
    "# 'Easy' Genera are those that are not frequently misclassified as Ailanthus, or those with prior knowledge to not be visually similar to Ailanthus\n",
    "\n",
    "# Ailanthus is included as an 'easy' example as it should always be included during training\n",
    "\n",
    "genera_list = [\n",
    "    'melia', 'cassia', 'jacaranda', 'cupaniopsis', 'erythrina', 'albizia', 'ceiba', 'harpephyllum',\n",
    "    'schefflera', 'catalpa', 'viburnum', 'juglans', 'styphnolobium', 'koelreuteria', 'sassafras',\n",
    "    'pterocarya', 'calodendrum', 'paulownia', 'ficus', 'heteromeles', 'pittosporum', 'hymenosporum',\n",
    "    'castanea', 'lyonothamnus', 'feijoa', 'robinia', 'sambucus', 'gymnocladus', 'eriobotrya', 'persea',\n",
    "    'maclura', 'parkinsonia', 'broussonetia', 'livistona', 'handroanthus', 'maackia', 'casimiroa',\n",
    "    'lophostemon', 'psidium', 'phellodendron', 'tristania', 'grevillea', 'strelitzia', 'tabebuia',\n",
    "    'sophora', 'syzygium', 'eucalyptus', 'tsuga', 'elaeagnus', 'dracaena', 'bauhinia', 'rhus', 'platanus',\n",
    "    'corymbia', 'aesculus', 'carya', 'libocedrus', 'punica', 'morus', 'musa', 'xylosma', 'cotoneaster',\n",
    "    'dodonaea', 'yucca', 'umbellularia', 'ilex', 'cordyline', 'magnolia', 'acacia', 'sapium', 'euonymus',\n",
    "    'leucaena', 'pistacia', 'nerium', 'brachychiton', 'diospyros', 'chionanthus', 'tipuana', 'ceratonia',\n",
    "    'juniperus', 'rhamnus', 'citrus', 'hibiscus', 'corylus', 'thuja', 'salix', 'callistemon', 'tristaniopsis',\n",
    "    'chamaerops', 'stenocarpus', 'myoporum', 'chamaecyparis', 'araucaria', 'taxus', 'arbutus', 'gleditsia',\n",
    "    'camellia', 'halesia', 'archontophoenix', 'celtis', 'alnus', 'cupressus', 'olea', 'populus', 'cornus',\n",
    "    'agonis', 'laburnum', 'melaleuca', 'cladrastis', 'ostrya', 'cotinus', 'cedrus', 'cocos', 'prunus',\n",
    "    'cercis', 'sorbus', 'cycas', 'taxodium', 'eugenia', 'ceanothus', 'sequoia', 'calocedrus', 'syringa',\n",
    "    'schinus', 'abies', 'lagunaria', 'ligustrum', 'pseudotsuga', 'ginkgo', 'podocarpus', 'rhaphiolepis',\n",
    "    'picea', 'platycladus', 'angophora', 'rhododendron', 'leptospermum', 'hamamelis', 'casuarina', 'eucommia',\n",
    "    'acer', 'maytenus', 'pyrus', 'solanum', 'triadica', 'malus', 'photinia', 'zelkova', 'metasequoia',\n",
    "    'lagerstroemia', 'trachycarpus', 'geijera', 'liriodendron', 'fagus', 'liquidambar', 'butia', 'betula',\n",
    "    'quercus', 'afrocarpus', 'ulmus', 'cinnamomum', 'sequoiadendron', 'fraxinus', 'pyracantha', 'pinus',\n",
    "    'chilopsis', 'ziziphus', 'laurus', 'washingtonia', 'jubaea', 'cryptomeria', 'amelanchier', 'phoenix',\n",
    "    'escallonia', 'crataegus', 'carpinus', 'nothofagus', 'nyssa', 'stewartia', 'arctostaphylos', 'euphorbia',\n",
    "    'metrosideros', 'tamarix', 'syagrus', 'brahea', 'larix', 'clerodendrum', 'oxydendrum', 'cercidiphyllum',\n",
    "    'dypsis', 'caragana', 'styrax', 'tilia', 'davidia', 'parrotia'\n",
    "]\n",
    "\n",
    "data_list = [\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard',\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard',\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard',\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard',\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard',\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard', 'Hard',\n",
    "    'Hard', 'Hard', 'Hard', 'Hard', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy',\n",
    "    'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy', 'Easy'\n",
    "]\n",
    "\n",
    "# Combine genera and criteria list into dict\n",
    "genera_difficulty_dict = dict(zip(genera_list, data_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b329b7-c841-46c9-a375-e206b4771324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genera_difficulty_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da678281-dbfa-41b5-a3e1-2da8f094fd6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set the path to the root directory containing genera of trees with images and labels\n",
    "root_dir = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/jpegs_genus_idx_label'\n",
    "\n",
    "# Set the path to the target directory for easy genera\n",
    "# This directory contains images and labels of tree genera that are \"easy\" to classify\n",
    "target_easy_training_dir = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_3600imgstrain_5ktrees_easy_hard_images_labels_dec1123/train_easy'\n",
    "target_easy_testing_dir = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_3600imgstrain_5ktrees_easy_hard_images_labels_dec1123/test_easy'\n",
    "\n",
    "# Set the path to the target directory for hard genera\n",
    "# This directory contains images and labels of tree genera that are both \"easy\" and \"hard\" to classify\n",
    "target_hard_training_dir = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_3600imgstrain_5ktrees_easy_hard_images_labels_dec1123/train_easy_hard'\n",
    "target_hard_testing_dir = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist_ailanthus_3600imgstrain_5ktrees_easy_hard_images_labels_dec1123/test_easy_hard'\n",
    "\n",
    "# Define the ratio of samples for testing\n",
    "test_ratio = 0.2  # 20% of the samples will be used for testing\n",
    "\n",
    "# Define the maximum number of samples to copy to the training/testing directories per genera\n",
    "max_samples_per_genera = 10\n",
    "\n",
    "# Iterate through genera directories to sample N genera per directory for training/testing\n",
    "for genus, difficulty in genera_difficulty_dict.items():\n",
    "    \n",
    "    print(f'{genus} is {difficulty}')\n",
    "    \n",
    "    # Setup directories to each genera\n",
    "    genera_dir_images = os.path.join(root_dir, genus, 'images') # Directory containing genera images\n",
    "    genera_dir_labels = os.path.join(root_dir, genus, 'labels') # Directory containing genera labels\n",
    "    \n",
    "    # Create the target directories for training and testing images and labels, with both \"easy\" and \"hard\" genera cases\n",
    "    target_easy_training_images_dir = os.path.join(target_easy_training_dir, 'images')\n",
    "    target_easy_training_labels_dir = os.path.join(target_easy_training_dir, 'labels')\n",
    "    target_easy_testing_images_dir = os.path.join(target_easy_testing_dir, 'images')\n",
    "    target_easy_testing_labels_dir = os.path.join(target_easy_testing_dir, 'labels')\n",
    "    \n",
    "    target_hard_training_images_dir = os.path.join(target_hard_training_dir, 'images')\n",
    "    target_hard_training_labels_dir = os.path.join(target_hard_training_dir, 'labels')\n",
    "    target_hard_testing_images_dir = os.path.join(target_hard_testing_dir, 'images')\n",
    "    target_hard_testing_labels_dir = os.path.join(target_hard_testing_dir, 'labels')\n",
    "    \n",
    "    os.makedirs(target_easy_training_images_dir, exist_ok=True)\n",
    "    os.makedirs(target_easy_training_labels_dir, exist_ok=True)\n",
    "    os.makedirs(target_easy_testing_images_dir, exist_ok=True)\n",
    "    os.makedirs(target_easy_testing_labels_dir, exist_ok=True)\n",
    "    \n",
    "    os.makedirs(target_hard_training_images_dir, exist_ok=True)\n",
    "    os.makedirs(target_hard_training_labels_dir, exist_ok=True)\n",
    "    os.makedirs(target_hard_testing_images_dir, exist_ok=True)\n",
    "    os.makedirs(target_hard_testing_labels_dir, exist_ok=True)\n",
    "    \n",
    "    # List all label files in one genera directory\n",
    "    label_files = [f for f in os.listdir(genera_dir_labels) if f.endswith('.txt')]\n",
    "    \n",
    "    # Shuffle the list to randomly select samples for testing\n",
    "    random.shuffle(label_files)\n",
    "    \n",
    "    # Calculate the number of samples for testing based on the ratio\n",
    "    num_testing_samples = int(len(label_files) * test_ratio)\n",
    "    \n",
    "    # Split the samples into training and testing sets\n",
    "    training_files = label_files[num_testing_samples:]\n",
    "    testing_files = label_files[:num_testing_samples]\n",
    "    \n",
    "    print(f'Total Training Files: {len(training_files)}')\n",
    "    print(f'Total Testing Files: {len(testing_files)}')\n",
    "    \n",
    "    # Initialize counters for each genera\n",
    "    easy_training_counter = hard_training_counter = 0\n",
    "    \n",
    "    # Iterate through training files and copy images and labels to training directories\n",
    "    for filename in training_files: # filename is the label .txt file\n",
    "        image_filename = os.path.splitext(filename)[0] + '.jpeg'\n",
    "        \n",
    "        # Build source and target paths for images and labels\n",
    "        image_source_path = os.path.join(genera_dir_images, image_filename) #the full path to the image\n",
    "        label_source_path = os.path.join(genera_dir_labels, filename) #the full path to the label\n",
    "        \n",
    "        # Cases where the genera is 'hard' to classify, move to the 'hard' directory\n",
    "        if difficulty == 'Hard':\n",
    "            # Check if the maximum number of samples has been reached for this genera\n",
    "            if hard_training_counter <= max_samples_per_genera:\n",
    "                # For Hard Samples, copy to only the hard directory\n",
    "                _ = shutil.copy2(image_source_path, target_hard_training_images_dir)\n",
    "                _ = shutil.copy2(label_source_path, target_hard_training_labels_dir)\n",
    "                hard_training_counter += 1\n",
    "        else:\n",
    "            # Check if the maximum number of samples has been reached for this genera\n",
    "            if easy_training_counter <= max_samples_per_genera:\n",
    "                # For Easy samples, copy to both easy and hard training directories\n",
    "                _ = shutil.copy2(image_source_path, target_easy_training_images_dir)\n",
    "                _ = shutil.copy2(label_source_path, target_easy_training_labels_dir)\n",
    "                _ = shutil.copy2(image_source_path, target_hard_training_images_dir)\n",
    "                _ = shutil.copy2(label_source_path, target_hard_training_labels_dir)\n",
    "                easy_training_counter += 1\n",
    "        \n",
    "    print(f'Copied Training {hard_training_counter} samples to Hard, {easy_training_counter} samples to Easy and Hard for {genus}')\n",
    "        \n",
    "    # Initialize counters for each genera\n",
    "    easy_training_counter = hard_training_counter = 0\n",
    "    \n",
    "    # Iterate through testing files and copy images and labels to testing directories\n",
    "    for filename in testing_files:\n",
    "        image_filename = os.path.splitext(filename)[0] + '.jpeg'\n",
    "        \n",
    "        # Build source and target paths for images and labels\n",
    "        image_source_path = os.path.join(genera_dir_images, image_filename)\n",
    "        label_source_path = os.path.join(genera_dir_labels, filename)\n",
    "        \n",
    "        if difficulty == 'Hard':\n",
    "            # Check if the maximum number of samples has been reached for this genera\n",
    "            if hard_training_counter <= max_samples_per_genera:\n",
    "                # For Hard samples, copy only to hard training directories\n",
    "                _ = shutil.copy2(image_source_path, target_hard_testing_images_dir)\n",
    "                _ = shutil.copy2(label_source_path, target_hard_testing_labels_dir)\n",
    "                hard_training_counter += 1\n",
    "        else:\n",
    "            # Check if the maximum number of samples has been reached for this genera\n",
    "            if easy_training_counter <= max_samples_per_genera:\n",
    "                # For Easy samples, copy to both easy and hard training directories\n",
    "                _ = shutil.copy2(image_source_path, target_easy_testing_images_dir)\n",
    "                _ = shutil.copy2(label_source_path, target_easy_testing_labels_dir)\n",
    "                _ = shutil.copy2(image_source_path, target_hard_testing_images_dir)\n",
    "                _ = shutil.copy2(label_source_path, target_hard_testing_labels_dir)\n",
    "                easy_training_counter += 1\n",
    "              \n",
    "    print(f'Copied Testing {hard_training_counter} samples to Hard, {easy_training_counter} samples to Easy and Hard for {genus}')\n",
    "          \n",
    "print(\"Images and labels copied successfully.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912217c6-f4f3-4349-acb7-ce59cc2463c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92129f7-443a-4bb6-9a2b-45ce7741302a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83c9c900-17f5-4808-8dae-5dcb1518c066",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Rename/Shuffle Image/Label Filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9ec22-1fc9-4f77-986c-8830fee2d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_name(length=12):\n",
    "    \"\"\"Generate a random alphanumeric name.\"\"\"\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for _ in range(length))\n",
    "\n",
    "def rename_files(image_directory, label_directory):\n",
    "    # Iterate through .txt files in the label directory\n",
    "    for filename in os.listdir(label_directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            label_path = os.path.join(label_directory, filename)\n",
    "\n",
    "            # Construct the path for the corresponding image file\n",
    "            image_filename, _ = os.path.splitext(filename)\n",
    "            image_path = os.path.join(image_directory, image_filename + '.jpeg')\n",
    "\n",
    "            # Generate a unique random name for both image and label files\n",
    "            random_name = generate_random_name()\n",
    "            file_extension = os.path.splitext(image_path)[1]\n",
    "\n",
    "            # Construct the new paths\n",
    "            new_image_path = os.path.join(image_directory, random_name + file_extension)\n",
    "            new_label_path = os.path.join(label_directory, random_name + '.txt')\n",
    "\n",
    "            # Rename the image file\n",
    "            os.rename(image_path, new_image_path)\n",
    "            print(f'Renamed: {image_path} to {new_image_path}')\n",
    "\n",
    "            # Rename the label file\n",
    "            os.rename(label_path, new_label_path)\n",
    "            print(f'Renamed: {label_path} to {new_label_path}')\n",
    "\n",
    "# Example usage\n",
    "images_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/inaturalist_ailanthus_positives_nov1323/test/images'\n",
    "labels_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/inaturalist_ailanthus_positives_nov1323/test/labels'\n",
    "rename_files(images_directory, labels_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c11b6-18ea-4198-afcb-504ea14c3379",
   "metadata": {},
   "source": [
    "# Sort Labels by Bounding Box Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ecaec-60b6-4b3f-af89-f6e41fa93704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarize distribution of bounding boxes dataset\n",
    "\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "#txt_directory = r'C:/Users/talake2/Desktop/ailanthus_labelstudio_nov1323/labels/'\n",
    "txt_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist/test/labels/'\n",
    "\n",
    "# Counters for boxes with width and height over 0.9\n",
    "count_width_over_0_8 = 0\n",
    "count_height_over_0_8 = 0\n",
    "\n",
    "# Iterate through .txt files and modify the content\n",
    "for filename in os.listdir(txt_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        txt_file_path = os.path.join(txt_directory, filename)\n",
    "        with open(txt_file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            lines = file.readlines()\n",
    "            \n",
    "            # Iterate through lines in the file\n",
    "            for line in lines:\n",
    "                values = line.split()\n",
    "                \n",
    "                # Get bounding box data from each box\n",
    "                obj_class = int(values[0])  # Assuming class is an integer\n",
    "                x_value = float(values[1])\n",
    "                y_value = float(values[2])\n",
    "                w_value = float(values[3])\n",
    "                h_value = float(values[4])\n",
    "                \n",
    "                # Check conditions for width and height\n",
    "                if w_value > 0.8:\n",
    "                    count_width_over_0_8 += 1\n",
    "                \n",
    "                if h_value > 0.8:\n",
    "                    count_height_over_0_8 += 1\n",
    "                    \n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of boxes with width over 0.8: {count_width_over_0_8}\")\n",
    "print(f\"Number of boxes with height over 0.8: {count_height_over_0_8}\")\n",
    "            \n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26354d5-b067-4ae4-8310-2a2d57d119ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove labels for images with bounding boxes > 0.95 width and height\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "txt_directory = r'C:/Users/talake2/Desktop/ailanthus_labelstudio_nov1323/labels/'\n",
    "\n",
    "# Temporary list to store files to be removed\n",
    "files_to_remove = []\n",
    "\n",
    "# Iterate through .txt files and identify files to be removed\n",
    "for filename in os.listdir(txt_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        txt_file_path = os.path.join(txt_directory, filename)\n",
    "        with open(txt_file_path, 'r') as file:\n",
    "            # Read the content of the file\n",
    "            lines = file.readlines()\n",
    "            \n",
    "            # Check conditions for width and height\n",
    "            for line in lines:\n",
    "                values = line.split()\n",
    "                w_value = float(values[3])\n",
    "                h_value = float(values[4])\n",
    "                \n",
    "                if w_value > 0.5: #if bounding box is very wide, add as candidate to remove\n",
    "                    files_to_remove.append(txt_file_path)\n",
    "                \n",
    "                if h_value > 0.5: #if bounding box is very tall, add as candidate to remove\n",
    "                    files_to_remove.append(txt_file_path)\n",
    "                    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef75129-af2a-4dbd-ae8e-dfdba825c507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove the identified files\n",
    "\n",
    "for file_to_remove in files_to_remove:\n",
    "    os.remove(file_to_remove)\n",
    "\n",
    "# Print the removed files\n",
    "print(f\"Removed {len(files_to_remove)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b67c43-0a2e-4913-8d96-fc907e0fd1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0cc21-8c3a-443e-afc2-4bf805cdaf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a2d2ff-63cc-4eaa-9816-25157c5f6c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6feeaef-66f6-4146-b1d1-f55d08c83333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow 2.10)",
   "language": "python",
   "name": "tensorflow_210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
