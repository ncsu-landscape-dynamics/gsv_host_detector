{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d7b260-ccf3-4c90-9b59-653f722537b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training and inference of a YoloV5 model\n",
    "For detailed documentation on how to train a model, see: https://docs.ultralytics.com/yolov5/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa154634-03de-4ec5-821c-454a3bacca81",
   "metadata": {},
   "source": [
    "Training a custom YOLOV5 model requires several steps:\n",
    "0. Pull the YOLOv5 Git Repo: https://github.com/ultralytics/yolov5/releases\n",
    "\n",
    "1. Creating a custom dataset\n",
    "    Images (JPEG) and labels (TXT) must be collected and properly formatted. See: https://roboflow.com/formats/yolov5-pytorch-txt\n",
    "    \n",
    "2. Select a model. Several types of Yolo models are available (e.g., Nano: YoloV5n ... Medium: YoloV5m ... XLarge: YoloV5X). In general, larger models perform better, but are slower for training and inference. https://docs.ultralytics.com/models/\n",
    "\n",
    "3. Train the model. Setup a Conda/Python environment (here: Python 3.10; Pytorch with CUDA GPU enabled). Create YAML files specifying where to find the data, and what model architecture you are using. You can also specify different hyperparameters during model training.\n",
    "\n",
    "With your conda environment active, run your model: \n",
    "\n",
    "python train.py --single-cls --rect --batch -1 --epochs 25 --data ./datasets/autoarborist_file_paths_classes_yolov5x.yml --cfg ./datasets/autoarborist_architecture_yolov5x.yml --weights '' --hyp ./datasets/hyp-scratch-custom.yaml\n",
    "\n",
    "--single-cls specifies training with one class\n",
    "--rect specifies images are rectangular (from the Autoarborist dataset)\n",
    "--batch -1 specifies automatic batch size selection\n",
    "--epochs 25 specifies total number of iterations through the entire training/testing set\n",
    "--data points to the YAML file with your training data paths\n",
    "--cfg points to the YAML file with your model architecture \n",
    "--weights specifies whether you want pre-trained weights\n",
    "--hyp points to the YAML file with your hyperparameters\n",
    "\n",
    "Once you train the model... you can view summary statistics (precision, recall) and evaluate it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e4411-1762-49c5-a734-1631deccd77b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effeb0c0-5c3d-4198-b48d-0588a77ebd10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Guide on Prediction with Yolo Model: https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading/#before-you-start\n",
    "\n",
    "# Import Libraries\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "\n",
    "# Notebook and Vis Params\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38fb9c5-07ae-4cb9-9ef6-1d59956d0eba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load a trained YOLOv5 Object Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d1eeb-ac90-41b1-9bce-53dba1e95be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a pretrained/ custom model from disk\n",
    "\n",
    "# Model 1 Detects Trees\n",
    "model1_name = 'yolov5x-oct2323-autoarborist-25epochs'\n",
    "model1_path = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/runs/train/{model1_name}/weights/last.pt'\n",
    "tree_model = torch.hub.load(r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5', 'custom', path=model1_path, source='local')\n",
    "\n",
    "\n",
    "# From Trees, Model 2 Detects Ailanthus\n",
    "model2_name = 'exp-autoarb-with-ailanthus-3600imgstrain-5ktrees-alleasyandhard-yolov5x-imagenet-10epochs-lowaug-imgweights-lr01-dec1123'\n",
    "model2_path = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/runs/train/exp6/weights/last.pt'\n",
    "ailanthus_model = torch.hub.load(r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5', 'custom', path=model2_path, source='local')\n",
    "\n",
    "# Set tree and ailanthus model confidence and iou thresholds\n",
    "tree_model.conf = 0.25  # confidence threshold (0-1)\n",
    "tree_model.iou = 0.45  # NMS IoU threshold (0-1) \n",
    "\n",
    "ailanthus_model.conf = 0.25  # confidence threshold (0-1)\n",
    "ailanthus_model.iou = 0.45  # NMS IoU threshold (0-1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce222a07-81a3-44f1-b145-aaf5d30f2dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and Crop Image by Size\n",
    "\n",
    "#img_path = r'C:/Users/talake2/Desktop/GSV_imgs_ailanthus/imgs/IC9PrL5RaujFWTNLQ6GrhA.jpg' # Simple test case for Ailanthus\n",
    "img_path = r'C:\\Users\\talake2\\Desktop\\GSV_panoramic_images\\GSV_imgs_ailanthus\\r2048\\_6r7Jpnswuc-wB5QNLt_IQ.jpg'\n",
    "img = imread(img_path)\n",
    "img.shape # Google Street View Panorama: 8192, 16384, 3\n",
    "plt.imshow(img[..., 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a5478-6acf-4c7b-a77b-0e249ca3ff42",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Detection on a Single Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0fdb8-3bc1-4ad8-a068-eca83fbdf204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and Crop Image by Size\n",
    "\n",
    "img_path = r'C:\\Users\\talake2\\Desktop\\auto_arborist_cvpr2022_v015\\auto_arborist_jpegs\\jpegs_aerial_streetlevel_raw\\all_cities_streetview\\train\\acer\\streetlevel_4_2.jpg'\n",
    "#img_path = r'C:\\Users\\talake2\\Desktop\\GSV_panoramic_images\\GSV_imgs_ailanthus\\r2048\\_3DIEb8MnUP0LRYicY3dmQ.jpg'\n",
    "img = imread(img_path)\n",
    "img.shape # Google Street View Panorama: 8192, 16384, 3\n",
    "#plt.imshow(img)\n",
    "\n",
    "# Crop image to square\n",
    "img_crop = img[0:8192, 0:8192, ...]\n",
    "\n",
    "# Inference\n",
    "model_results = tree_model(img_crop, size=640) #default size 640. Change for custom inference size\n",
    "\n",
    "# Size 80 Speed: 1.0ms pre-process, 248.5ms inference, 40.1ms NMS per image at shape (1, 3, 64, 96), one tree detected (Ailanthus not detected)\n",
    "# Size 160 Speed: 1.0ms pre-process, 123.8ms inference, 1.0ms NMS per image at shape (1, 3, 96, 160), four trees detected (Ailanthus conf 70)\n",
    "# Size 320 Speed: 1.0ms pre-process, 11.0ms inference, 1.0ms NMS per image at shape (1, 3, 160, 320) six trees detected (Ailanthus conf 93)\n",
    "# Size 640 Speed: 3.0ms pre-process, 10.0ms inference, 1.0ms NMS per image at shape (1, 3, 320, 640) 12 trees detected (Ailanthus conf 71)\n",
    "# Size 768 Speed: 10.5ms pre-process, 163.3ms inference, 8.0ms NMS per image at shape (1, 3, 384, 768) 12 trees detected (Ailanthus not detected)\n",
    "# Size 1280 Speed: 7.0ms pre-process, 15.0ms inference, 2.0ms NMS per image at shape (1, 3, 640, 1280) 18 trees detected (Ailanthus not detected)\n",
    "\n",
    "# Examine results. Show number of bounding boxes and details of an image.\n",
    "model_results.print()\n",
    "model_results_df = model_results.pandas().xyxy[0]\n",
    "print(model_results_df)\n",
    "model_results.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5436e21-1503-453f-9908-8f44b6e893cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Double Inference on Single Panoramic Image: Detect Trees with YOLO-Tree model & Classify with YOLO-Ailanthus model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2c4d4-d3e0-4b0b-825d-294e70313b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crop Detected Trees From Tree Detection on Google Street View Panoramic Image and Apply Detection Again\n",
    "\n",
    "# Dataset Output Directory: googlestreetview_ailanthus_images_labels_dec23\n",
    "\n",
    "# Iterate through a folder containing many .jpg images\n",
    "\n",
    "# For each image in the folder, read:\n",
    "\n",
    "# Original image\n",
    "img_path = r'C:\\Users\\talake2\\Desktop\\GSV_panoramic_images\\GSV_imgs_ailanthus\\r2048\\_3DIEb8MnUP0LRYicY3dmQ.jpg'\n",
    "img = imread(img_path)\n",
    "\n",
    "# Inference using the tree_detection model\n",
    "results = tree_model(img_resize)\n",
    "\n",
    "# Examine results. Show number of bounding boxes and details of an image.\n",
    "results.print()\n",
    "results_df = results.pandas().xyxy[0]\n",
    "\n",
    "# Loop through each bounding box\n",
    "for i in range(results_df.shape[0]):\n",
    "    # Get bounding box coordinates\n",
    "    xmin, ymin, xmax, ymax = results_df.loc[i, ['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "\n",
    "\n",
    "    # Crop the original image based on bounding box coordinates\n",
    "    img_crop = img[int(ymin):int(ymax), int(xmin):int(xmax), ...]\n",
    "\n",
    "    # Display the cropped image\n",
    "    #plt.imshow(img_crop)\n",
    "    #plt.show()\n",
    "\n",
    "    # Inference on the cropped image using the ailanthus_detection model\n",
    "    results_cropped = ailanthus_model(img_crop)\n",
    "    \n",
    "    results_cropped.show()\n",
    "\n",
    "    # Examine results for the cropped image\n",
    "    results_cropped.print()\n",
    "    results_df_cropped = results_cropped.pandas().xyxy[0]\n",
    "\n",
    "    # Display the results for the cropped image\n",
    "    print(results_df_cropped)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88843d3-3553-420c-b771-3eda55a95bcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Double Inference on Directory Panoramic Images\n",
    "\n",
    "First, Detect Trees with YOLO-Tree model. Then, Classify with YOLO-Ailanthus model\n",
    "\n",
    "Ideas:\n",
    "\n",
    "- Crop aspect ratio box around detected tree at 1.5x ratio (same ratio as Autoarborist data)? May help with resizing distortions?\n",
    "\n",
    "- If Ailanthus is detected, apply image augmentations (image/bounding box horizontal shifts).\n",
    "\n",
    "After augmentations, Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef41665-0779-4c99-b55d-719a94ff20ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Script takes images from a Google Street View Folder, Applies two YOLO Models (First: Detect Trees, Second, Detect Ailanthus).\n",
    "\n",
    "# Iterate through Google Street View Panorama folder containing many .jpg images\n",
    "folder_path = r'C:/Users/talake2/Desktop/Ailanthus_altissima/r2048'\n",
    "save_dir_images = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/googlestreetview_ailanthus_images_labels_dec23/images'\n",
    "save_dir_labels = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/googlestreetview_ailanthus_images_labels_dec23/labels'\n",
    "\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = imread(img_path)\n",
    "\n",
    "        # Inference using the tree detection model\n",
    "        results = tree_model(img)\n",
    "        results_df = results.pandas().xyxy[0] # Dataframe of predictions: xmin, ymin, xmax, ymax, confidence, class, name\n",
    "        print(f'Detected {results_df.shape[0]} trees in panoramic image')\n",
    "\n",
    "        # Loop through each bounding box predicted as a tree\n",
    "        for i in range(results_df.shape[0]):\n",
    "            \n",
    "            # Get bounding box predictions of one predicted tree from the tree_detection model\n",
    "            xmin, ymin, xmax, ymax = results_df.loc[i, ['xmin', 'ymin', 'xmax', 'ymax']]\n",
    "            \n",
    "            # Crop panoramic image to bounding box of one predicted tree with padding\n",
    "            buffer_pixels = 200  # You can adjust the buffer size as needed, scale proportion to detected bounding box size?\n",
    "\n",
    "            ymin_cropped = max(int(ymin) - buffer_pixels, 0)\n",
    "            ymax_cropped = min(int(ymax) + buffer_pixels, img.shape[0])\n",
    "            xmin_cropped = max(int(xmin) - buffer_pixels, 0)\n",
    "            xmax_cropped = min(int(xmax) + buffer_pixels, img.shape[1])\n",
    "\n",
    "            img_crop = img[ymin_cropped:ymax_cropped, xmin_cropped:xmax_cropped, ...]\n",
    "\n",
    "            # Inference on the cropped image using the ailanthus detection model\n",
    "            print(f'Running Ailanthus Detection on Tree Number:{i}')\n",
    "            results_cropped = ailanthus_model(img_crop)\n",
    "\n",
    "            # Store bounding box and class results for the cropped image\n",
    "            results_df_cropped = results_cropped.pandas().xyxy[0]\n",
    "            print(results_df_cropped)\n",
    "            \n",
    "            # If results_cropped dataframe contains any instance of class = 1 (Ailanthus), save the image and bounding box\n",
    "            ailanthus_instances = results_df_cropped[results_df_cropped['class'] == 1]\n",
    "\n",
    "            if not ailanthus_instances.empty:\n",
    "                \n",
    "                # Get bounding boxes for cropped image with predicted Ailanthus\n",
    "                xmin_values = results_df_cropped.loc[:, 'xmin']\n",
    "                ymin_values = results_df_cropped.loc[:, 'ymin']\n",
    "                xmax_values = results_df_cropped.loc[:, 'xmax']\n",
    "                ymax_values = results_df_cropped.loc[:, 'ymax']\n",
    "                \n",
    "                # Display prediction on cropped image with Ailanthus\n",
    "                results_cropped.show()\n",
    "                \n",
    "                # Create filestring to save predictions of Ailanthus images/labels\n",
    "                #file_name = os.path.splitext(filename)[0]\n",
    "                #image_save_path = os.path.join(save_dir_images, f'{file_name}_{i}.jpg')\n",
    "                #txt_save_path = os.path.join(save_dir_labels, f'{file_name}_{i}.txt')\n",
    "\n",
    "                # Resize image to match Autoarborist dataset, dimension (768 x 1152)\n",
    "                #resized_img = cv2.resize(img_crop, (768, 1152))\n",
    "\n",
    "                # Save resized image from Google Street View Pano\n",
    "                #resized_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "                #cv2.imwrite(image_save_path, resized_img)\n",
    "\n",
    "                #with open(txt_save_path, 'w') as txt_file:\n",
    "                #    for j in range(len(xmin_values)):\n",
    "                #        # Normalize bounding box coordinates\n",
    "                #        class_id = results_df_cropped['class'].iloc[j]  # Class indices start with 0. 'Trees' class should be index 0, 'Ailanthus' class should be 1.\n",
    "                #        center_x = ((xmin_values[j] + xmax_values[j]) / 2) / img_crop.shape[1]\n",
    "                #        center_y = ((ymin_values[j] + ymax_values[j]) / 2) / img_crop.shape[0]\n",
    "                #        width = (xmax_values[j] - xmin_values[j]) / img_crop.shape[1]\n",
    "                #        height = (ymax_values[j] - ymin_values[j]) / img_crop.shape[0]\n",
    "\n",
    "                        # Write bounding box information to the text file\n",
    "                #        txt_file.write(f'{class_id} {center_x} {center_y} {width} {height}' + os.linesep)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6e40f-ae80-435f-853c-8686880f216c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports for GradCAM (Explainable Object Detection) from: https://github.com/jacobgil/pytorch-grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d8871-3a61-48f0-a204-960d93b27059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import torch    \n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "from pytorch_grad_cam import EigenCAM, ScoreCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d058cf7-d8c4-4e19-8414-887d4bca35b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiments with EigenCAM and Explanable Object Detection Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96ab08-2b8f-4835-9029-ce4f7629022c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLORS = np.random.uniform(0, 255, size=(80, 3))\n",
    "\n",
    "def parse_detections(results):\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    detections = detections.to_dict()\n",
    "    boxes, colors, names = [], [], []\n",
    "\n",
    "    for i in range(len(detections[\"xmin\"])):\n",
    "        confidence = detections[\"confidence\"][i]\n",
    "        if confidence < 0.2:\n",
    "            continue\n",
    "        xmin = int(detections[\"xmin\"][i])\n",
    "        ymin = int(detections[\"ymin\"][i])\n",
    "        xmax = int(detections[\"xmax\"][i])\n",
    "        ymax = int(detections[\"ymax\"][i])\n",
    "        name = detections[\"name\"][i]\n",
    "        category = int(detections[\"class\"][i])\n",
    "        color = COLORS[category]\n",
    "\n",
    "        boxes.append((xmin, ymin, xmax, ymax))\n",
    "        colors.append(color)\n",
    "        names.append(name)\n",
    "    return boxes, colors, names\n",
    "\n",
    "\n",
    "def draw_detections(boxes, colors, names, img):\n",
    "    for box, color, name in zip(boxes, colors, names):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (xmin, ymin),\n",
    "            (xmax, ymax),\n",
    "            color, \n",
    "            5)\n",
    "\n",
    "        cv2.putText(img, name, (xmin, ymin - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,\n",
    "                    lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "layers = [-2, -5, -8, -12, -15, -17, -19, -21] \n",
    "\n",
    "folder_path = r'C:\\Users\\talake2\\Desktop\\auto_arborist_cvpr2022_v015\\yolov5\\datasets\\autoarborist_googlestreetview_images_labels_7300ailanthus_22000trees_jan324\\gradcam_images'\n",
    "# Loop through each image in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        img = imread(img_path)\n",
    "\n",
    "        rgb_img = img.copy()\n",
    "        #img = np.float32(img) / 255\n",
    "        transform = transforms.ToTensor()\n",
    "        tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "        model = ailanthus_model\n",
    "        results = model([rgb_img])\n",
    "        print(results.pandas().xyxy[0])\n",
    "        boxes, colors, names = parse_detections(results)\n",
    "        detections = draw_detections(boxes, colors, names, rgb_img.copy())\n",
    "        Image.fromarray(detections)\n",
    "        # Display CAM Activation Layers\n",
    "        for j in layers:\n",
    "            target_layers = [model.model.model.model[j]]\n",
    "\n",
    "            cam = EigenCAM(model, target_layers)\n",
    "            grayscale_cam = cam(tensor)[0, :, :]\n",
    "            plt.imshow(rgb_img)\n",
    "            plt.imshow(grayscale_cam, alpha=0.8)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc504b3e-9579-40c4-a84e-35b63b5a434c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cam = EigenCAM(model, target_layers)\n",
    "\n",
    "grayscale_cam = cam(tensor)[0, :, :]\n",
    "plt.imshow(grayscale_cam)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530fb2c-c6f1-4b17-bbad-bdadf34fed35",
   "metadata": {},
   "source": [
    "# Inference on a directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448593ab-5d9b-45b1-a25e-518412c74edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define an image to apply the model inference to each image in the directory\n",
    "\n",
    "input_image_directory = r'C:/Users/talake2/Desktop/GSV_imgs_ailanthus/imgs'\n",
    "\n",
    "for filename in os.listdir(input_image_directory):\n",
    "    if filename.endswith('.jpg'):\n",
    "         # Construct the full file path\n",
    "        image_path = os.path.join(input_image_directory, filename)\n",
    "        \n",
    "        # Read image\n",
    "        img = imread(image_path)\n",
    "        \n",
    "        # Crop bottom 1/3 of image\n",
    "        img_resize = img[0:5406, ...]\n",
    "        \n",
    "        # Run model inference on the image\n",
    "        results = model(img_resize)\n",
    "        \n",
    "        # Make into a pandas dataframe\n",
    "        results_df = results.pandas().xyxy[0]\n",
    "        \n",
    "        # Check if the DataFrame is empty\n",
    "        #if not results_df.empty:\n",
    "            # Check if any value in the 'confidence' column is over 0.60\n",
    "        #    if (results_df['confidence'] > 0.8).any():\n",
    "                # Save the plotted image with results\n",
    "        results.save()\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2edeb-3377-4c58-b017-632375eb60b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After inference, move output files to single directory\n",
    "\n",
    "# Source directory containing 'exp', 'exp1', 'exp2', ... folders\n",
    "source_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/jupyter_notebooks/runs/detect'\n",
    "\n",
    "# Destination directory where all JPEG files will be moved\n",
    "destination_directory = r'C:/Users/talake2/Desktop/GSV_imgs_ailanthus/preds'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)\n",
    "\n",
    "# Recursively traverse through the source directory and move JPEG files\n",
    "for root, _, files in os.walk(source_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "            # Get the full path of the JPEG file\n",
    "            source_file_path = os.path.join(root, file)\n",
    "            # Move the file to the destination directory\n",
    "            shutil.move(source_file_path, os.path.join(destination_directory, file))\n",
    "\n",
    "print(\"JPEG files moved successfully to the destination directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0023d1-89c6-4364-93df-c67a5e5113e8",
   "metadata": {},
   "source": [
    "# Plotting Images and Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a3a33-f2e9-41e4-bf63-1b9e12f8f2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting Images and Bounding Boxes\n",
    "\n",
    "classes = ['ailanthus', 'tree']\n",
    "        \n",
    "colors = [[random.randint(0, 255) for _ in range(3)]\n",
    "              for _ in range(len(classes))]\n",
    "\n",
    "# Path to the directory containing .txt files\n",
    "images_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/googlestreetview_ailanthus_images_labels_dec23/images'\n",
    "labels_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/googlestreetview_ailanthus_images_labels_dec23/labels'\n",
    "\n",
    "# Output directory for saving images with bounding boxes\n",
    "output_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/googlestreetview_ailanthus_images_labels_dec23/images-boxes'\n",
    "\n",
    "def plot_one_box(x, image, color=None, label=None, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(\n",
    "        0.002 * (image.shape[0] + image.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(image, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(image, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(image, label, (c1[0], c1[1] - 2), 0, tl / 3,\n",
    "                    [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "# Iterate through .txt files and copy corresponding images\n",
    "for filename in os.listdir(labels_directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Extract the image file name without extension from the .txt file\n",
    "        image_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "        \n",
    "        source_image_file = os.path.join(images_directory, image_filename)\n",
    "        source_label_file = os.path.join(labels_directory, filename)\n",
    "        \n",
    "        print(source_image_file)\n",
    "        print(source_label_file)\n",
    "        \n",
    "        # Open the label and image file\n",
    "        label = open(source_label_file)\n",
    "        image = cv2.imread(source_image_file).copy()  # Create a copy of the image\n",
    "        \n",
    "        # Define image shape\n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        print(height, width, channels)\n",
    "        \n",
    "        box_number = 0\n",
    "        for line in label:\n",
    "            # Skip empty lines\n",
    "            if not line.strip():\n",
    "                continue\n",
    "\n",
    "            box = line.split()\n",
    "            print(box)\n",
    "            class_idx = int(box[0])\n",
    "            \n",
    "            x_center, y_center, w, h = float(box[1])*width, float(box[2])*height, float(box[3])*width, float(box[4])*height\n",
    "            x1 = round(x_center - w/2)\n",
    "            y1 = round(y_center - h/2)\n",
    "            x2 = round(x_center + w/2)\n",
    "            y2 = round(y_center + h/2)\n",
    "\n",
    "            plot_one_box([x1, y1, x2, y2], image, color=colors[class_idx],\n",
    "                         label=classes[class_idx], line_thickness=None)\n",
    "\n",
    "            box_number += 1\n",
    "\n",
    "        # Save the image after processing all bounding boxes\n",
    "        save_file_path = os.path.join(output_directory, image_filename)\n",
    "        cv2.imwrite(save_file_path, image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00eb25-31b6-4161-8a36-9141a9b4ffa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model False Positives/ Error Assessment \n",
    "Apply YOLO model to detect a species across set of images from Autoarborist classified to Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3205f50-b562-4038-806a-b75214b9b053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define an image to apply the model inference to each image in the AutoArborist directory\n",
    "\n",
    "# Define the base image directory\n",
    "base_input_image_directory = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/jpegs/all_cities_streetview/train'\n",
    "\n",
    "# Get a list of genus names (folder names) in the specified directory\n",
    "genus_names = [item for item in os.listdir(base_input_image_directory) if os.path.isdir(os.path.join(base_input_image_directory, item))]\n",
    "\n",
    "# Initialize an empty DataFrame to store the summary statistics\n",
    "summary_df = pd.DataFrame(columns=['Genus', 'Ailanthus Predictions', 'Tree Predictions', 'Average Ailanthus Confidence', 'Average Tree Confidence'])\n",
    "\n",
    "for genus_name in genus_names:\n",
    "    print(genus_name)\n",
    "    \n",
    "    # Construct the full directory path for the current genus\n",
    "    input_image_directory = os.path.join(base_input_image_directory, genus_name)\n",
    "\n",
    "    # Initialize variables to store aggregated results\n",
    "    total_ail_predictions = 0\n",
    "    total_tree_predictions = 0\n",
    "    ail_confidences = []\n",
    "    tree_confidences = []\n",
    "\n",
    "    # Use enumerate to iterate over the first 1000 elements\n",
    "    for i, filename in enumerate(os.listdir(input_image_directory)):\n",
    "        if i >= 1000:\n",
    "            break  # Stop after the first 1000 elements\n",
    "            \n",
    "        # Construct file path\n",
    "        image_path = os.path.join(input_image_directory, filename)\n",
    "\n",
    "        # Run model inference on the image (replace this with your actual model inference code)\n",
    "        results = model(image_path)\n",
    "\n",
    "        # Make into a pandas dataframe\n",
    "        results_df = results.pandas().xyxy[0]\n",
    "\n",
    "        # Check if the DataFrame is empty\n",
    "        if not results_df.empty:\n",
    "            # Count 'ailanthus' and 'tree' predictions\n",
    "            total_ail_predictions += results_df[results_df['name'] == 'ailanthus'].shape[0]\n",
    "            total_tree_predictions += results_df[results_df['name'] == 'tree'].shape[0]\n",
    "\n",
    "            # Extract confidence scores for 'ailanthus' and 'tree'\n",
    "            ail_confidences.extend(results_df[results_df['name'] == 'ailanthus']['confidence'].tolist())\n",
    "            tree_confidences.extend(results_df[results_df['name'] == 'tree']['confidence'].tolist())\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    avg_ail_confidence = np.mean(ail_confidences) if ail_confidences else 0\n",
    "    avg_tree_confidence = np.mean(tree_confidences) if tree_confidences else 0\n",
    "    \n",
    "    std_ail_confidence = np.std(ail_confidences) if ail_confidences else 0\n",
    "    std_tree_confidence = np.std(tree_confidences) if tree_confidences else 0\n",
    "\n",
    "    # Add the summary statistics to the DataFrame\n",
    "    summary_df = summary_df.append({\n",
    "        'Genus': genus_name,\n",
    "        'Ailanthus Predictions': total_ail_predictions,\n",
    "        'Tree Predictions': total_tree_predictions,\n",
    "        'Proportion Predicted Ailanthus:': total_ail_predictions/total_tree_predictions,\n",
    "        'Average Ailanthus Confidence': avg_ail_confidence,\n",
    "        'Average Tree Confidence': avg_tree_confidence,\n",
    "        'STD Ailanthus Confidence': std_ail_confidence,\n",
    "        'STD Tree Confidence': std_tree_confidence\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198d458-1d5c-45e9-9a7b-c26555f67877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df24f71-e287-4629-8312-e9365261127d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(summary_df)\n",
    "summary_df.to_csv(r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/model_classification_by_genus_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d94746-28bd-495e-a5e7-de87c72e4b75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Diagnostics: Check if all training/testing images: label pairs are present.\n",
    "\n",
    "Each image (e.g.,  000038a4-b9a1-4e11-9e92-e8a98a3ebdb7.jpg ) should have a unique, matching label (e.g., 000038a4-b9a1-4e11-9e92-e8a98a3ebdb7.txt)\n",
    "\n",
    "If an image is missing a label, or if we have extra labels, delete these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e4d43-572f-49f2-b99e-26b9865d96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Paths to the image and label folders\n",
    "image_folder = r'/mnt/c/users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist/train/images'\n",
    "label_folder = r'/mnt/c/users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist/train/labels'\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "#print(image_files[0:10])\n",
    "\n",
    "# Get the list of label files\n",
    "label_files = os.listdir(label_folder)\n",
    "\n",
    "#print(label_files[0:10])\n",
    "\n",
    "# Iterate through image files\n",
    "for image_file in image_files:\n",
    "    # Construct the corresponding label file name\n",
    "    label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "    \n",
    "    # Check if the label file exists\n",
    "    if label_file not in label_files:\n",
    "        # If label file doesn't exist, remove the image file\n",
    "        os.remove(os.path.join(image_folder, image_file))\n",
    "        print(f\"Removed {image_file} because corresponding label was not found.\")\n",
    "\n",
    "# Iterate through label files\n",
    "for label_file in label_files:\n",
    "    # Construct the corresponding image file name\n",
    "    image_file = os.path.splitext(label_file)[0] + '.jpeg'\n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if image_file not in image_files:\n",
    "        # If image file doesn't exist, remove the label file\n",
    "        os.remove(os.path.join(label_folder, label_file))\n",
    "        print(f\"Removed {label_file} because corresponding image was not found.\")\n",
    "\n",
    "\n",
    "\n",
    "# Paths to the image and label folders\n",
    "image_folder = r'/mnt/c/users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist/test/images'\n",
    "label_folder = r'/mnt/c/users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/datasets/autoarborist/test/labels'\n",
    "\n",
    "# Get the list of image files\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "#print(image_files[0:10])\n",
    "\n",
    "# Get the list of label files\n",
    "label_files = os.listdir(label_folder)\n",
    "\n",
    "#print(label_files[0:10])\n",
    "\n",
    "# Iterate through image files\n",
    "for image_file in image_files:\n",
    "    # Construct the corresponding label file name\n",
    "    label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "    \n",
    "    # Check if the label file exists\n",
    "    if label_file not in label_files:\n",
    "        # If label file doesn't exist, remove the image file\n",
    "        os.remove(os.path.join(image_folder, image_file))\n",
    "        print(f\"Removed {image_file} because corresponding label was not found.\")\n",
    "\n",
    "# Iterate through label files\n",
    "for label_file in label_files:\n",
    "    # Construct the corresponding image file name\n",
    "    image_file = os.path.splitext(label_file)[0] + '.jpeg'\n",
    "    \n",
    "    # Check if the image file exists\n",
    "    if image_file not in image_files:\n",
    "        # If image file doesn't exist, remove the label file\n",
    "        os.remove(os.path.join(label_folder, label_file))\n",
    "        print(f\"Removed {label_file} because corresponding image was not found.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30621bb-ffce-45a6-870d-7c74d4169de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a directory of images, create text files matching that directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to the directory containing .jpeg images\n",
    "image_directory = r'C:/Users/talake2/Downloads/img-20231030T191435Z-003/img'\n",
    "\n",
    "# Path to the directory where text files will be saved\n",
    "labels_directory = r'C:/Users/talake2/Downloads/img-20231030T191435Z-003/labels'\n",
    "\n",
    "# Get a list of .jpeg files in the image directory\n",
    "jpeg_files = [file for file in os.listdir(image_directory) if file.lower().endswith('.jpg')]\n",
    "\n",
    "# Create the labels directory if it doesn't exist\n",
    "if not os.path.exists(labels_directory):\n",
    "    os.makedirs(labels_directory)\n",
    "\n",
    "# Iterate through the .jpeg files and create corresponding text files\n",
    "for jpeg_file in jpeg_files:\n",
    "    # Extract the file name (without extension)\n",
    "    file_name = os.path.splitext(jpeg_file)[0]\n",
    "    # Create the corresponding text file\n",
    "    text_file_path = os.path.join(labels_directory, file_name + '.txt')\n",
    "    with open(text_file_path, 'w') as text_file:\n",
    "        # You can optionally add content to the text files if needed\n",
    "        pass\n",
    "    print(f\"Created {text_file_path}\")\n",
    "\n",
    "print(\"Text files creation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow 2.10)",
   "language": "python",
   "name": "tensorflow_210"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
