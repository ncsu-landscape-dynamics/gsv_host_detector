{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a04eb38-1fd9-43da-8921-a58b15bfba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from EcoNameTranslator import to_scientific, to_common, to_species\n",
    "import os\n",
    "import csv\n",
    "from pygbif import species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0714eb03-97ef-4e3c-98bd-5ffd227be863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set column options\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc6c2e72-002d-4707-81fb-beb5035a8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreStart - take the lat/long out from the initial vancouver inventory\n",
    "vcCoords = pd.read_csv(\"G:/Shared drives/host_tree_cnn/cleaning_species_names/og_inventories/vancouver_inventory.csv\", delimiter=\";\")\n",
    "vcCoords = vcCoords[\"geo_point_2d\"]\n",
    "vcCoords = vcCoords.str.split(\",\", expand=True)\n",
    "vcCoords.columns = [\"rounded_lat\", \"rounded_lng\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd714ae1-3499-441a-bed8-d641357005c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Synonym Symbol', 'Scientific Name with Author', 'Common Name', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# take in the usda codes\n",
    "usdaDF = pd.read_csv('G:/Shared drives/host_tree_cnn/cleaning_species_names/addl_data/usda_code.txt')\n",
    "print(usdaDF.columns.tolist())\n",
    "usdaDF['Scientific Name with Author'] = usdaDF['Scientific Name with Author'].str.lower()\n",
    "usdaDF['Common Name'] = usdaDF['Common Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c9b1403-1a9c-4213-bf4b-33c7b491d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevFindings = {}\n",
    "# clean up the scientific names\n",
    "def cleanScientific(scientificName):\n",
    "    global prevFindings\n",
    "    if (scientificName == 'NA'):\n",
    "        return [\"NA\", \"NA\"]\n",
    "    if scientificName in prevFindings:\n",
    "        return prevFindings[scientificName]\n",
    "    try:\n",
    "        index = to_species([scientificName])\n",
    "        values = index[scientificName][0].split()\n",
    "        # check to see if there are two possible values\n",
    "        if len(values) > 2:\n",
    "            print(values)\n",
    "        # take the species and genus\n",
    "        prevFindings[scientificName] = [values[-2], values[-1]]\n",
    "        return values[-2], values[-1]\n",
    "    except:\n",
    "        prevFindings[scientificName] = [\"NA\", \"NA\"]\n",
    "        return [\"NA\", \"NA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "25677111-ba25-48e4-8de3-1fd97cd40db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific name to common name\n",
    "noneCount = 0\n",
    "# sNaValues = \n",
    "sNaValues = set()\n",
    "scientificNamesDict = {}\n",
    "def getCommonNames(scientificName):\n",
    "    scientificName = scientificName.lower()\n",
    "    global noneCount\n",
    "    global sNaValues\n",
    "    # check values that were already found\n",
    "    if scientificName in sNaValues:\n",
    "        noneCount += 1\n",
    "        return None\n",
    "    elif scientificName in scientificNamesDict:\n",
    "        return scientificNamesDict[scientificName]\n",
    "    # check USDA for a match\n",
    "    result = usdaDF.loc[usdaDF['Scientific Name with Author'] == scientificName, 'CommonName'].values\n",
    "    if len(result) > 0:\n",
    "      getCommonNames[scientificName] = result[0]\n",
    "      return result[0]\n",
    "    # check econameparser for a match\n",
    "    try:\n",
    "        common_names = to_common([scientificName])[scientificName][1]\n",
    "        if len(common_names) == 0:\n",
    "            raise ValueError()\n",
    "        \n",
    "        scientificNamesDict[scientificName] = common_names\n",
    "        \n",
    "        return common_names\n",
    "    except:\n",
    "        noneCount += 1 \n",
    "        sNaValues.add(scientificName)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d41c7ef-3b56-46d3-a368-825d668e612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Symbol', 'Synonym Symbol', 'Scientific Name with Author', 'Common Name', 'Family']\n"
     ]
    }
   ],
   "source": [
    "# common name to scientific Name\n",
    "\n",
    "print(usdaDF.columns.tolist())\n",
    "# ['Symbol', 'Synonym Symbol', 'Scientific Name with Author', 'Common Name', 'Family']\n",
    "\n",
    "cNaValues = set()\n",
    "common_namesDict = {}\n",
    "def getScientificNames(common_name):\n",
    "    global noneCount\n",
    "    global cNaValues\n",
    "\n",
    "    common_name = common_name.lower()\n",
    "\n",
    "    # check values that were already found\n",
    "    if common_name in cNaValues:\n",
    "        noneCount += 1\n",
    "        return None\n",
    "    elif common_name in common_namesDict:\n",
    "        return common_namesDict[common_name]\n",
    "    # check USDA for a match\n",
    "    result = usdaDF.loc[usdaDF['Common Name'] == common_name, 'Scientific Name with Author'].values\n",
    "    if len(result) > 0:\n",
    "      common_namesDict[common_name] = result[0]\n",
    "      return result[0]\n",
    "    # check econameparsre for a match\n",
    "    try:\n",
    "        sci_name = to_scientific([common_name])[common_name][1]\n",
    "        if len(sci_name) == 0:\n",
    "            raise ValueError()\n",
    "        \n",
    "        common_namesDict[common_name] = sci_name[0]\n",
    "        return sci_name[0]\n",
    "    except:\n",
    "        noneCount += 1 \n",
    "        cNaValues.add(common_name)\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3efcaf5a-9b41-48a8-9bb4-ac3b673a0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolDict = {}\n",
    "synonymDict = {}\n",
    "symbolDF = usdaDF.set_index('Symbol')\n",
    "synonymDF = usdaDF.set_index('Synonym Symbol')\n",
    "\n",
    "symbolDict = symbolDF['Common Name'].to_dict()\n",
    "synonymDict = synonymDF['Common Name'].to_dict()\n",
    "\n",
    "commonDict = symbolDict.copy()  \n",
    "commonDict.update(synonymDict)\n",
    "\n",
    "\n",
    "symbolDict = symbolDF['Scientific Name with Author'].to_dict()\n",
    "synonymDict = synonymDF['Scientific Name with Author'].to_dict()\n",
    "\n",
    "sciDict = symbolDict.copy()  \n",
    "sciDict.update(synonymDict)\n",
    "validCodes = {\n",
    "    \"ABBA\": \"Abies balsamea\",\n",
    "    \"JUVI\": \"Juniperus virginiana\",\n",
    "    \"FRAM\": \"Fraxinus americana\",\n",
    "    \"QUCO\": \"Quercus coccinea\",\n",
    "    \"QUMA1\": \"Quercus macrocarpa\",\n",
    "    \"POTR1\": \"Populus tremuloides\",\n",
    "    \"ULWI\": \"Ulmus wilsoniana\",\n",
    "    \"ACCA\": \"Acer campestre\",\n",
    "    \"ACNI\": \"Acer nigrum\",\n",
    "    \"ACPA\": \"Acer palmatum\",\n",
    "    \"ACPL\": \"Acer platanoides\",\n",
    "    \"ACRU\": \"Acer rubrum\",\n",
    "    \"ACSA1\": \"Acer saccharinum\",\n",
    "    \"ACSA2\": \"Acer saccharum\",\n",
    "    \"AECA\": \"Aesculus californica\",\n",
    "    \"AMLA\": \"Amelanchier laevis\",\n",
    "    \"BENI\": \"Betula nigra\",\n",
    "    \"CABE\": \"Carpinus betulus\",\n",
    "    \"CAGL\": \"Carya glabra\",\n",
    "    \"CAOV\": \"Carya ovata\",\n",
    "    \"CEOC\": \"Celtis occidentalis\",\n",
    "    \"CHLA\": \"Chamaecyparis lawsoniana\",\n",
    "    \"CHOB\": \"Chionanthus virginicus\",\n",
    "    \"CRMO\": \"Crataegus monogyna\",\n",
    "    \"EUAT\": \"Eucommia ulmoides\",\n",
    "    \"FASY\": \"Fagus sylvatica\",\n",
    "    \"FREX\": \"Fraxinus excelsior\",\n",
    "    \"FRNI\": \"Fraxinus nigra\",\n",
    "    \"FROR\": \"Fraxinus ornus\",\n",
    "    \"FRPE\": \"Fraxinus pennsylvanica\",\n",
    "    \"GIBI\": \"Ginkgo biloba\",\n",
    "    \"GLTR\": \"Gleditsia triacanthos\",\n",
    "    \"GYDI\": \"Gymnocladus dioicus\",\n",
    "    \"HAVI\": \"Hamamelis virginiana\",\n",
    "    \"ILCO\": \"Ilex coriaceae\",\n",
    "    \"JUSC\": \"Juglans cinerea\",\n",
    "    \"LIST\": \"Liquidambar styraciflua\",\n",
    "    \"NYSY\": \"Nyssa sylvatica\",\n",
    "    \"PONI\": \"Populus nigra\",\n",
    "    \"POTR\": \"Populus tremuloides\",\n",
    "    \"PRSE\": \"Prunus serotina\",\n",
    "    \"PRSU\": \"Prunus subhirtella\",\n",
    "    \"PRVI\": \"Prunus virginiana\",\n",
    "    \"PYCA\": \"Pyrus calleryana\",\n",
    "    \"QUCO\": \"Quercus coccinea\",\n",
    "    \"QUMA\": \"Quercus macrocarpa\",\n",
    "    \"QUPA\": \"Quercus palustris\",\n",
    "    \"QURO\": \"Quercus robur\",\n",
    "    \"ROPS\": \"Robinia pseudoacacia\",\n",
    "    \"SEGI\": \"Sequoiadendron giganteum\",\n",
    "    \"SOJA\": \"Sophora japonica\",\n",
    "    \"SYRE\": \"Syringa reticulata\",\n",
    "    \"TADI\": \"Taxodium distichum\",\n",
    "    \"THOC\": \"Thuja occidentalis\",\n",
    "    \"THPL\": \"Thuja plicata\",\n",
    "    \"TIAM\": \"Tilia americana\",\n",
    "    \"TICO\": \"Tilia cordata\",\n",
    "    \"TIPL\": \"Tilia platyphyllos\",\n",
    "    \"ULAM\": \"Ulmus americana\",\n",
    "    \"ULPA\": \"Ulmus parvifolia\",\n",
    "    \"ZESE\": \"Zelkova serrata\"\n",
    "}\n",
    "\n",
    "sciDict.update(validCodes)\n",
    "\n",
    "def getSpeciesName(code):\n",
    "    if code in sciDict:\n",
    "        return sciDict[code]\n",
    "    else:\n",
    "        return sciDict.get(code[:4], None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "180bf9a1-25f8-40ef-a111-2e71ea5a51f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse comma ordering\n",
    "def reorganizeComma(name):\n",
    "    if isinstance(name, str):\n",
    "        if ',' in name:\n",
    "            parts = name.split(',', 1)\n",
    "            preComma = parts[0].strip()\n",
    "            postComma = parts[1].strip()\n",
    "            return postComma + ' ' + preComma\n",
    "        else:\n",
    "            return name\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30977597-d847-49c0-9697-258dc45b3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NA Values\n",
    "def handleNA(value):\n",
    "    value = value.replace('.', '')\n",
    "    # questions --- common name as array, or string?\n",
    "    naValues = {'', 'a', 'nan', 'other', 'n/a', ' ', 'not specified', 'na', 'none', 'p', 'f'}\n",
    "    containsNaValues = {'not specified', 'unidentified', 'unsuitable', 'vacant', '*', '_', '-', 'proposed', 'unknown', '#', 'other ', 'no ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "\n",
    "    if value.strip() in naValues or any(word in value for word in containsNaValues):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        # If the value contains there characters, include only the elements before\n",
    "        if \"'\" in value:\n",
    "            return value.split(\"'\")[0]\n",
    "        elif \"(\" in value:\n",
    "            return value.split(\"(\")[0]\n",
    "        elif \":\" in value:\n",
    "            return value.split(\":\")[0]\n",
    "        elif \"`\" in value:\n",
    "            return value.split(\"`\")[0]\n",
    "        elif \"‘\" in value:\n",
    "            return value.split(\"‘\")[0]\n",
    "\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fc35a29-2941-41de-b761-89844e9944e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vancouver_inventory.csv\n",
      "FILE # 0\n",
      "washingtondc_inventory.csv\n",
      "FILE # 1\n",
      "bloomington_inventory.csv\n",
      "FILE # 2\n",
      "boulder_inventory.csv\n",
      "FILE # 3\n",
      "buffalo_inventory.csv\n",
      "FILE # 4\n",
      "calgary_inventory.csv\n",
      "FILE # 5\n",
      "cambridge_inventory.csv\n",
      "FILE # 6\n",
      "charlottesville_inventory.csv\n",
      "FILE # 7\n",
      "columbus_inventory.csv\n",
      "FILE # 8\n",
      "cupertino_inventory.csv\n",
      "FILE # 9\n",
      "denver_inventory.csv\n",
      "FILE # 10\n",
      "edmonton_inventory.csv\n",
      "FILE # 11\n",
      "kitchener_inventory.csv\n",
      "FILE # 12\n",
      "losangeles_inventory.csv\n",
      "FILE # 13\n",
      "montreal_inventory.csv\n",
      "FILE # 14\n",
      "newyorkcity_inventory.csv\n",
      "FILE # 15\n",
      "pittsburgh_inventory.csv\n",
      "FILE # 16\n",
      "sanfrancisco_inventory.csv\n",
      "FILE # 17\n",
      "sanjose_inventory.csv\n",
      "FILE # 18\n",
      "santamonica_inventory.csv\n",
      "FILE # 19\n",
      "['tree', 'site', 'deleted']\n",
      "seattle_inventory.csv\n",
      "FILE # 20\n",
      "siouxfalls_inventory.csv\n",
      "FILE # 21\n",
      "surrey_inventory.csv\n",
      "FILE # 22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# ==================================================================================================================================\n",
    "# Get city and create columns\n",
    "\n",
    "# Find the folder path and create a dataframe from it\n",
    "folder_path = \"G:/Shared drives/host_tree_cnn/cleaning_species_names/og_inventories_modified_labels\"\n",
    "\n",
    "# Iterate through the files\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename == 'usda_code.csv':\n",
    "        continue\n",
    "    print(filename)\n",
    "    print(\"FILE #\", i)\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if not filename.endswith('.csv'):\n",
    "        continue\n",
    "        \n",
    "    # city in to dataframe\n",
    "    cityDF = pd.read_csv(file_path, dtype=str)\n",
    "    cityDF = cityDF.map(reorganizeComma)\n",
    "    if filename == 'vancouver_inventory.csv':\n",
    "        cityDF[\"rounded_lat\"] = vcCoords[\"rounded_lat\"]\n",
    "        cityDF[\"rounded_lng\"] = vcCoords[\"rounded_lng\"]\n",
    "\n",
    "    # Columbus - special case\n",
    "    if filename == 'columbus_inventory.csv':\n",
    "        cityDF['common_name'] = cityDF['SP_CODE'].map(commonDict)\n",
    "        cityDF['species_name'] = cityDF['SP_CODE'].map(getSpeciesName)\n",
    "\n",
    "\n",
    "    # Drop all na values and format the table to a string\n",
    "    cityDF['unique_common_name'] = cityDF['common_name'].astype(str)\n",
    "\n",
    "    # bloomington - special case\n",
    "    if filename == 'bloomington_inventory.csv':\n",
    "      cityDF['species_name'] = cityDF['unique_common_name'].apply(getScientificNames)\n",
    "    cityDF['unique_sciname'] = cityDF['species_name'].astype(str)\n",
    "\n",
    "    # handle space removal and lowercase conversion\n",
    "    cityDF['unique_sciname'] = cityDF['unique_sciname'].str.strip() \n",
    "    cityDF['unique_sciname'] = cityDF['unique_sciname'].str.lower()\n",
    "\n",
    "    cityDF['unique_common_name'] = cityDF['unique_common_name'].str.strip()\n",
    "    cityDF['unique_common_name'] = cityDF['unique_common_name'].str.lower()\n",
    "\n",
    "    cityDF['unique_sciname'] = cityDF['unique_sciname'].map(handleNA)\n",
    "    cityDF['unique_common_name'] = cityDF['unique_common_name'].map(handleNA)\n",
    "    \n",
    "\n",
    "    # clean the scientific name\n",
    "    cityDF[['genus_name', 'species_name']] = cityDF.apply(\n",
    "        lambda row: pd.Series(cleanScientific(row['unique_sciname'])),\n",
    "        axis=1,\n",
    "        result_type='expand'\n",
    "    )\n",
    "    \n",
    "    # take out the columns we need and then reorder them, placing them at the end\n",
    "    cols = [col for col in cityDF.columns if col not in ['unique_common_name', 'unique_sciname', 'genus_name', 'species_name']]\n",
    "    cols += ['unique_common_name', 'unique_sciname', 'genus_name', 'species_name']\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    cityDF = cityDF[cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # save to a csv\n",
    "    cityDF.to_csv(\"G:/Shared drives/host_tree_cnn/cleaning_species_names/og_inventories_w_names_appended/\" + filename, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
