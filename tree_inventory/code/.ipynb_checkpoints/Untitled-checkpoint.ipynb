{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04eb38-1fd9-43da-8921-a58b15bfba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from EcoNameTranslator import to_scientific, to_common, to_species\n",
    "import os\n",
    "import csv\n",
    "from pytaxize import scicomm\n",
    "from pygbif import species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd714ae1-3499-441a-bed8-d641357005c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "usdaDF = pd.read_csv('G:/Shared drives/host_tree_cnn/cleaning_species_names/addl_data/usda_code.txt')\n",
    "print(usdaDF.columns.tolist())\n",
    "usdaDF['Scientific Name with Author'] = usdaDF['Scientific Name with Author'].str.lower()\n",
    "usdaDF['Common Name'] = usdaDF['Common Name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b1403-1a9c-4213-bf4b-33c7b491d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Symbol', 'Synonym Symbol', 'Scientific Name with Author', 'Common Name', 'Family']\n",
    "prevFindings = {}\n",
    "# clean up the scientific names\n",
    "def cleanScientific(scientificName):\n",
    "    global prevFindings\n",
    "    global iterations\n",
    "    if (scientificName == 'NA'):\n",
    "        iterations += 1\n",
    "        return [\"NA\", \"NA\"]\n",
    "    # if iterations % 100 == 0 or iterations == 1:\n",
    "    #     print(str(i) + \"/\" + str(numRows))\n",
    "    if scientificName in prevFindings:\n",
    "        return prevFindings[scientificName]\n",
    "    try:\n",
    "        index = to_species([scientificName])\n",
    "        values = index[scientificName][0].split()\n",
    "        if len(values) > 2:\n",
    "            print(values)\n",
    "        prevFindings[scientificName] = [values[-2], values[-1]]\n",
    "        return values[-2], values[-1]\n",
    "    except:\n",
    "        prevFindings[scientificName] = [\"NA\", \"NA\"]\n",
    "        return [\"NA\", \"NA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981680b8-afec-4779-b407-2557b8b4ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scientific name to common name\n",
    "noneCount = 0\n",
    "sNaValues = set()\n",
    "scientificNamesDict = {}\n",
    "def getCommonNames(scientificName):\n",
    "    global noneCount\n",
    "    global sNaValues\n",
    "\n",
    "    if scientificName in sNaValues:\n",
    "        noneCount += 1\n",
    "        return None\n",
    "    elif scientificName in scientificNamesDict:\n",
    "        return scientificNamesDict[scientificName]\n",
    "    try:\n",
    "        common_names = to_common([scientificName])[scientificName][1]\n",
    "        if len(common_names) == 0:\n",
    "            raise ValueError()\n",
    "        \n",
    "        scientificNamesDict[scientificName] = common_names\n",
    "        \n",
    "        return common_names\n",
    "    except:\n",
    "        noneCount += 1 \n",
    "        sNaValues.add(scientificName)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc35a29-2941-41de-b761-89844e9944e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common name to scientific Name\n",
    "\n",
    "print(usdaDF.columns.tolist())\n",
    "# ['Symbol', 'Synonym Symbol', 'Scientific Name with Author', 'Common Name', 'Family']\n",
    "\n",
    "cNaValues = set()\n",
    "common_namesDict = {}\n",
    "def getScientificNames(common_name):\n",
    "    global noneCount\n",
    "    global cNaValues\n",
    "\n",
    "    common_name = common_name.lower()\n",
    "    print(common_name)\n",
    "\n",
    "\n",
    "    if common_name in cNaValues:\n",
    "        noneCount += 1\n",
    "        return None\n",
    "    elif common_name in common_namesDict:\n",
    "        print(common_namesDict[common_name])\n",
    "        return common_namesDict[common_name]\n",
    "    try:\n",
    "        sci_name = to_scientific([common_name])[common_name][1]\n",
    "        if len(sci_name) == 0:\n",
    "            raise ValueError()\n",
    "        \n",
    "        common_namesDict[common_name] = sci_name[0]\n",
    "        print(sci_name[0])\n",
    "        return sci_name[0]\n",
    "    except:\n",
    "      result = usdaDF.loc[usdaDF['Common Name'] == common_name, 'Scientific Name with Author'].values\n",
    "      if len(result) > 0:\n",
    "          print(\"RESULT\")\n",
    "          print(result[0])\n",
    "          common_namesDict[common_name] = result[0]\n",
    "          return result[0]\n",
    "\n",
    "      print(\"NONE\")\n",
    "      noneCount += 1 \n",
    "      cNaValues.add(common_name)\n",
    "      return \"NA\"\n",
    "\n",
    "\n",
    "\n",
    "# reverse comma ordering\n",
    "def reorganizeComma(name):\n",
    "    if isinstance(name, str):\n",
    "\n",
    "        if ',' in name:\n",
    "            parts = name.split(',', 1)\n",
    "            preComma = parts[0].strip()\n",
    "            postComma = parts[1].strip()\n",
    "            return postComma + ' ' + preComma\n",
    "        else:\n",
    "            return name\n",
    "    else:\n",
    "        return name\n",
    "    \n",
    "# Handle NA Values\n",
    "def handleNA(value):\n",
    "    value = value.replace('.', '')\n",
    "    # questions --- common name as array, or string?\n",
    "    naValues = {'', 'a', 'nan', 'other', 'n/a', ' ', 'not specified', 'na', 'none', 'p', 'f'}\n",
    "    containsNaValues = {'not specified', 'unidentified', 'unsuitable', 'vacant', '*', '_', '-', 'proposed', 'unknown', '#', 'other ', 'no ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "\n",
    "    if value.strip() in naValues or any(word in value for word in containsNaValues):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        # If the value contains there characters, include only the elements before\n",
    "        if \"'\" in value:\n",
    "            return value.split(\"'\")[0]\n",
    "        elif \"(\" in value:\n",
    "            return value.split(\"(\")[0]\n",
    "        elif \":\" in value:\n",
    "            return value.split(\":\")[0]\n",
    "        elif \"`\" in value:\n",
    "            return value.split(\"`\")[0]\n",
    "        elif \"‘\" in value:\n",
    "            return value.split(\"‘\")[0]\n",
    "\n",
    "        return value\n",
    "\n",
    "# ==================================================================================================================================\n",
    "# Get city and create columns\n",
    "\n",
    "# Find the folder path and create a dataframe from it\n",
    "folder_path = \"G:/Shared drives/host_tree_cnn/cleaning_species_names/og_inventories_modified_labels\"\n",
    "# currentCities = {\"columbus_inventory.csv\"}\n",
    "# Iterate through the files\n",
    "\n",
    "for i, filename in enumerate(os.listdir(folder_path)):\n",
    "    if filename == 'usda_code.csv':\n",
    "        continue\n",
    "    if filename != 'columbus_inventory.csv':\n",
    "        continue\n",
    "    # if filename not in currentCities:\n",
    "    #     continue\n",
    "    iterations = 1\n",
    "    print(filename)\n",
    "    print(\"FILE #\", i)\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if not filename.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    cityDF = pd.read_csv(file_path)\n",
    "    \n",
    "    cityDF = cityDF.map(reorganizeComma)\n",
    "    \n",
    "    \n",
    "    if filename == 'columbus_inventory.csv':\n",
    "        symbolDict = {}\n",
    "        synonymDict = {}\n",
    "        symbolDF = usdaDF.set_index('Symbol')\n",
    "        synonymDF = usdaDF.set_index('Synonym Symbol')\n",
    "\n",
    "        symbolDict = symbolDF['Common Name'].to_dict()\n",
    "        synonymDict = synonymDF['Common Name'].to_dict()\n",
    "\n",
    "        commonDict = symbolDict.copy()  \n",
    "        commonDict.update(synonymDict)\n",
    "\n",
    "\n",
    "        symbolDict = symbolDF['Scientific Name with Author'].to_dict()\n",
    "        synonymDict = synonymDF['Scientific Name with Author'].to_dict()\n",
    "\n",
    "        sciDict = symbolDict.copy()  \n",
    "        sciDict.update(synonymDict)\n",
    "\n",
    "        cityDF['common_name'] = cityDF['SP_CODE'].map(commonDict)\n",
    "        cityDF['species_name'] = cityDF['SP_CODE'].map(sciDict)\n",
    "        print(cityDF['common_name'])\n",
    "        na_percentage = cityDF['common_name'].isna().mean() * 100\n",
    "        print(f\"Percentage of NaN values in 'common_name': {na_percentage:.2f}%\")\n",
    "\n",
    "        na_percentage = cityDF['species_name'].isna().mean() * 100\n",
    "        print(f\"Percentage of NaN values in 'species_name': {na_percentage:.2f}%\")\n",
    "\n",
    "    # Drop all na values and format the table to a string\n",
    "    # cityDF.dropna(how='all')\n",
    "    cityDF['unique_common_name'] = cityDF['common_name'].astype(str)\n",
    "\n",
    "    # In case you need to get scientific names from ecotranslator\n",
    "    if filename == 'bloomington_inventory.csv':\n",
    "      print(cityDF[['unique_common_name']])\n",
    "      cityDF['species_name'] = cityDF['unique_common_name'].apply(getScientificNames)\n",
    "      print(cityDF)\n",
    "    cityDF['unique_sciname'] = cityDF['species_name'].astype(str)\n",
    "\n",
    "    # handle space removal and lowercase conversion\n",
    "    cityDF['unique_sciname'] = cityDF['unique_sciname'].str.strip() \n",
    "    cityDF['unique_sciname'] = cityDF['unique_sciname'].str.lower()\n",
    "\n",
    "    cityDF['unique_common_name'] = cityDF['unique_common_name'].str.strip()\n",
    "    cityDF['unique_common_name'] = cityDF['unique_common_name'].str.lower()\n",
    "\n",
    "    cityDF['unique_sciname'] = cityDF['unique_sciname'].map(handleNA)\n",
    "    cityDF['unique_common_name'] = cityDF['unique_common_name'].map(handleNA)\n",
    "    \n",
    "    \n",
    "    cityDF[['genus_name', 'species_name']] = cityDF.apply(\n",
    "        lambda row: pd.Series(cleanScientific(row['unique_sciname'])),\n",
    "        axis=1,\n",
    "        result_type='expand'\n",
    "    )\n",
    "    cols = [col for col in cityDF.columns if col not in ['unique_common_name', 'unique_sciname', 'genus_name', 'species_name']]\n",
    "    # Append the new columns at the end\n",
    "    cols += ['unique_common_name', 'unique_sciname', 'genus_name', 'species_name']\n",
    "\n",
    "    # Reorder the DataFrame\n",
    "    cityDF = cityDF[cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # no longer need to handle duplicates\n",
    "    # Ensure all spaces are the same\n",
    "    # cityDF = cityDF.apply(lambda x: x.str.replace('/xa0', ' ', regex=True) if x.dtype == \"object\" else x)\n",
    "\n",
    "    # handle duplicates, including NA duplicates = longer need to drop dupliacates\n",
    "    # cleaned_df = cityDF.drop_duplicates()\n",
    "    # cleaned_df = cleaned_df[~((cleaned_df['unique_sciname'] == 'NA') & cleaned_df['unique_common_name'].duplicated(keep=False))]\n",
    "\n",
    "    # cleaned_df = cleaned_df[~((cleaned_df['unique_common_name'] == 'NA') & cleaned_df['unique_sciname'].duplicated(keep=False))]\n",
    "    cityDF.to_csv(\"G:/Shared drives/host_tree_cnn/cleaning_species_names/og_inventories_w_names_appended/\" + filename, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
