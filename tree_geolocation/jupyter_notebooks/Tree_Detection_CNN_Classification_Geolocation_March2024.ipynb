{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53ca020-9fa1-4432-b301-4bd1cda9e28f",
   "metadata": {},
   "source": [
    "# Geolocation of Tree Inventory Dataset using Google Street View\n",
    "\n",
    "This notebook outlines workflows for tree geolocation. \n",
    "\n",
    "The workflow combines Google Street View panoramic imagery, object detection, and depth estimation models to infer the geographic location of a tree.\n",
    "\n",
    "Author: Thomas Lake, March 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a870cf5-a678-49d0-bfee-bbcdb8d7fc4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2d819-a399-4fd3-addd-2c36783d328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "# PyTorch\n",
    "import torch # Version 1.13.1\n",
    "print(torch.__version__)\n",
    "from torchvision import transforms\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.image import imread\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# MonoDepth2\n",
    "# https://github.com/nianticlabs/monodepth2\n",
    "#import sys\n",
    "#sys.path.insert(1, 'C:/users/talake2/Desktop/')\n",
    "#sys.path.insert(1, 'C:/users/talake2/Desktop/monodepth2/')\n",
    "#from monodepth2 import networks\n",
    "#from monodepth2.utils import download_model_if_doesnt_exist\n",
    "#from monodepth2 import layers\n",
    "\n",
    "# ZoeDepth\n",
    "# https://github.com/isl-org/ZoeDepth\n",
    "import sys\n",
    "sys.path.insert(1, 'C:/users/talake2/Desktop/ZoeDepth')\n",
    "from zoedepth.models.builder import build_model\n",
    "from zoedepth.utils.config import get_config\n",
    "import timm # timm version 0.6.7 needed to load models\n",
    "\n",
    "# Other\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import PIL.Image as pil\n",
    "from PIL import UnidentifiedImageError\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy.spatial import KDTree, cKDTree\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "from math import asin, atan2, cos, degrees, radians, sin\n",
    "from geopy.distance import geodesic\n",
    "from shapely.geometry import Point, LineString\n",
    "import pyproj\n",
    "from eomaps import Maps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052ee86-92db-4b03-8318-21cc9ec84957",
   "metadata": {},
   "source": [
    "# Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ca4c4-866b-49b4-b116-99a1fe1a762f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### LOAD FUNCTIONS #####\n",
    "\n",
    "def calculate_distance(p1, p2):\n",
    "    \"\"\"Calculate the Euclidean distance between two (lat/lon) shapely Points in Meters.\"\"\"\n",
    "    return p1.distance(p2) * 111139 #multiply by 111139 to convert lat/long dist to meters (approx)\n",
    "\n",
    "def read_image_metadata(img_folder, img_name):\n",
    "    \"\"\"\n",
    "    Read metadata from panoramic images.\n",
    "    Return metadata information: pano_id, image width, height, pano_lat, pano_lon, year, month, elevation.\n",
    "    \"\"\"\n",
    "    img_path = os.path.join(img_folder, img_name)\n",
    "    json_path = img_path.replace('.jpg', '.metadata.json')\n",
    "    \n",
    "    try:\n",
    "        # Read metadata from panoramic image\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            img_metadata = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where metadata file is not found\n",
    "        print(f\"Metadata file not found for image: {img_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Get metadata for panorama\n",
    "    pano_id = img_metadata['panoId']\n",
    "    resolution = img_metadata['resolution']\n",
    "    pano_lat = img_metadata['lat']\n",
    "    pano_lon = img_metadata['lng']\n",
    "    date = img_metadata['date']\n",
    "    elevation = img_metadata['elevation']\n",
    "    \n",
    "    return pano_id, resolution, pano_lat, pano_lon, date, elevation\n",
    "    \n",
    "\n",
    "def read_panoramic_image_and_metadata(img_folder, img_name):\n",
    "    \"\"\"\n",
    "    Read panoramic image and its metadata from the specified folder.\n",
    "    Returns the image, height, width, channels, pano_id, pano_rotation_value, pano_lat, pano_lon.\n",
    "    \"\"\"\n",
    "    img_path = os.path.join(img_folder, img_name)\n",
    "    json_path = img_path.replace('.jpg', '.metadata.json')\n",
    "    \n",
    "    try:\n",
    "        # Read panoramic image\n",
    "        img = imread(img_path)\n",
    "        height, width, channels = img.shape\n",
    "        # Check if image size is correct. Images should be shape (8192,16384,3).\n",
    "        if width != 16384:\n",
    "            print(\"Resizing GSV Image to Dimensions (16384, 8192)\")\n",
    "            img = cv2.resize(img, dsize = (16384, 8192), interpolation = cv2.INTER_AREA)\n",
    "        height, width, channels = img.shape\n",
    "    except (FileNotFoundError, UnidentifiedImageError):\n",
    "        # Handle the case where image file is not found or is not a valid image\n",
    "        print(f\"Image file not found or is not a valid image: {img_name}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Read panoramic image metadata\n",
    "        with open(json_path, 'r') as json_file:\n",
    "            img_metadata = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where metadata file is not found\n",
    "        print(f\"Metadata file not found for image: {img_name}\")\n",
    "        return None\n",
    "\n",
    "    # Get metadata for panorama\n",
    "    pano_id = img_metadata['panoId']\n",
    "    pano_rotation_value = img_metadata['rotation']  # North\n",
    "    pano_lat = img_metadata['lat']\n",
    "    pano_lon = img_metadata['lng']\n",
    "\n",
    "    return img, width, pano_id, pano_rotation_value, pano_lat, pano_lon\n",
    "\n",
    "\n",
    "def calculate_pano_tree_angle(row, img_width, pano_rotation_north):\n",
    "    \"\"\"\n",
    "    Calculate the angle of rotation of a tree in the panoramic image, based on the \n",
    "    vertical center of the bounding box given from a YOLO model.\n",
    "    \"\"\"\n",
    "    # Extract vertical center of the tree bounding box\n",
    "    tree_center_x = (row['xmin'] + row['xmax']) / 2\n",
    "    # Calculate the angle relative to the north\n",
    "    px_per_degree = (img_width/360) # eq. 45.5111\n",
    "    tree_angle = tree_center_x / px_per_degree\n",
    "    # Adjust the angle based on the north rotation value\n",
    "    adjusted_angle = (tree_angle - pano_rotation_north) % 360\n",
    "    return adjusted_angle\n",
    "\n",
    "def get_point_at_distance(lat1, lon1, d, bearing, R=6371):\n",
    "    \"\"\"\n",
    "    lat: initial latitude, in degrees\n",
    "    lon: initial longitude, in degrees\n",
    "    d: target distance from initial\n",
    "    bearing: (true) heading in degrees\n",
    "    R: optional radius of sphere, defaults to mean radius of earth\n",
    "\n",
    "    Returns new lat/lon coordinate {d}km from initial, in degrees\n",
    "    Source: https://stackoverflow.com/questions/7222382/get-lat-long-given-current-point-distance-and-bearing\n",
    "    \"\"\"\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    a = radians(bearing)\n",
    "    d = d/1000 # Convert from Km to meters\n",
    "    lat2 = asin(sin(lat1) * cos(d/R) + cos(lat1) * sin(d/R) * cos(a))\n",
    "    lon2 = lon1 + atan2(\n",
    "        sin(a) * sin(d/R) * cos(lat1),\n",
    "        cos(d/R) - sin(lat1) * sin(lat2)\n",
    "    )\n",
    "    return (degrees(lat2), degrees(lon2),)\n",
    "\n",
    "def extend_lines(row, distance):\n",
    "    '''\n",
    "    Create a shapely.LineString (line) between a panoramic image and detected tree\n",
    "    Given the panoramic image origin (lat, long), and the bearing (angle of tree),\n",
    "    create a line with a distance.\n",
    "    '''\n",
    "    extended_point = get_point_at_distance(row['Pano_Origin_Lat'], row['Pano_Origin_Lon'], distance, row['Pano_Tree_Angle'])\n",
    "    return LineString([(row['Pano_Origin_Lon'], row['Pano_Origin_Lat']), (extended_point[1], extended_point[0])])\n",
    "\n",
    "\n",
    "def process_yolo_results(yolo_results_df, num_detections):\n",
    "    '''\n",
    "    Process results of a YOLO model that detects trees in a panoramic image.\n",
    "    For geolocation: select trees with large bounding boxes that are nearer to the image orign\n",
    "    Calculate area and aspect ratio of each detected tree by bounding box coordinates\n",
    "    Filter by the largest trees with high detection confidence and small aspect ratio\n",
    "    \n",
    "    Parameter: num_detections. Integer specifying how many detected trees are selected by bounding box area (N-largest trees).\n",
    "    '''\n",
    "    # Check if the dataframe is empty\n",
    "    if model_results_df.empty:\n",
    "        print(\"No trees detected in the image.\")\n",
    "        return None\n",
    "\n",
    "    # Calculate bounding box area and aspect ratio\n",
    "    model_results_df['area'] = (model_results_df['xmax'] - model_results_df['xmin']) * (model_results_df['ymax'] - model_results_df['ymin'])\n",
    "    model_results_df['aspect_ratio'] = (model_results_df['xmax'] - model_results_df['xmin']) / (model_results_df['ymax'] - model_results_df['ymin'])\n",
    "\n",
    "    # Set the display format for the area column to non-scientific\n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    \n",
    "    # Select detection by bounding box area. Specify how many detected objects to return with num_detections.\n",
    "    topN_by_area = model_results_df.nlargest(num_detections, 'area', 'all')\n",
    "\n",
    "    # Exclude values with aspect ratio above 1.5\n",
    "    topN_filtered = topN_by_area[(topN_by_area['aspect_ratio'] <= 2.0) & (topN_by_area['confidence'] > 0.6)]\n",
    "\n",
    "    return topN_filtered\n",
    "\n",
    "def predict_genus_tencrop_cnn(img, model, xmin, ymin, xmax, ymax):\n",
    "    '''\n",
    "    Function to apply a trained CNN model to classify trees detected in street view imagery.\n",
    "    Classifies with TenCrop: https://pytorch.org/vision/0.15/generated/torchvision.transforms.TenCrop.html#torchvision.transforms.TenCrop\n",
    "    Takes in a panoramic street view image, applies transformations (crops, normalize) and runs prediction.\n",
    "    Returns the most likely class prediction (argmax) and a dictionary of the predicted class probabilities.\n",
    "    '''\n",
    "    # Genera to detect in google street view images\n",
    "    selected_genera = ['acer', 'ailanthus', 'betula', 'citrus', 'cupaniopsis', 'erythrina', 'fraxinus', 'gleditsia',\n",
    "                       'juglans', 'juniperus', 'magnolia', 'phoenix', 'picea', 'pinus', 'prunus', 'pseudotsuga',\n",
    "                       'pyrus', 'quercus', 'rhus', 'sequoia', 'taxodium', 'thuja', 'tilia', 'ulmus', 'washingtonia']\n",
    "\n",
    "    # Crop image to detected tree bounding box\n",
    "    crop_img = img[ymin:ymax, xmin:xmax, ...]\n",
    "\n",
    "    # Check if image is at least 512 x 512 to run predictions\n",
    "    # Create larger bounding box around detected tree if dimensions are too small\n",
    "    if crop_img.shape[0] < 512:\n",
    "        print(\"Re-cropping image to meet required dimensions: 512 x 512\")\n",
    "        ymin = max(0, ymin - (512 - crop_img.shape[0]) // 2)\n",
    "        ymax = ymin + 512\n",
    "        crop_img = img[ymin:ymax, xmin:xmax, ...]\n",
    "\n",
    "    if crop_img.shape[1] < 512:\n",
    "        print(\"Re-cropping image to meet required dimensions: 512 x 512\")\n",
    "        xmin = max(0, xmin - (512 - crop_img.shape[1]) // 2)\n",
    "        xmax = xmin + 512\n",
    "        crop_img = img[ymin:ymax, xmin:xmax, ...]    \n",
    "\n",
    "        \n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),  # Convert to PIL Image\n",
    "        transforms.TenCrop(512),  # Apply TenCrop augmentation\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),  # Convert cropped images to tensor\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))(crop) for crop in crops]))  # Normalize each cropped image\n",
    "    ])\n",
    "\n",
    "    # Apply transformations\n",
    "    cropped_imgs = transform(crop_img)\n",
    "\n",
    "    # Run CNN model prediction on each cropped image\n",
    "    predictions = []\n",
    "    for cropped_img_tensor in cropped_imgs:\n",
    "        cropped_img_tensor = cropped_img_tensor.unsqueeze(0).cuda()  # add first dimension of batch size and push to GPU\n",
    "        output = model(cropped_img_tensor)\n",
    "        predictions.append(output)\n",
    "\n",
    "    # Aggregate predictions from all crops\n",
    "    aggregated_output = torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "    # Get the softmax class probability for each genus\n",
    "    class_probs = torch.softmax(aggregated_output, dim=1)\n",
    "\n",
    "    # Get the argmax predicted class\n",
    "    class_argmax = torch.argmax(aggregated_output).item()\n",
    "\n",
    "    # From predicted class index, get genus name\n",
    "    predicted_tree_genus = selected_genera[class_argmax]\n",
    "\n",
    "    # Initialise a dictionary to hold the output genus probabilities\n",
    "    genus_softmax_dict = {}\n",
    "    for i, genus in enumerate(selected_genera):\n",
    "        genus_softmax_dict[f'{genus}_prob'] = class_probs[0][i].item()\n",
    "\n",
    "    return predicted_tree_genus, genus_softmax_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01780bc6-e201-4ba9-bfec-ffe183dd3e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a5ed6-10fc-4788-ac53-441f61a7ac23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12392526-8a88-41f4-8df0-997bddb29b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34e3b0cf-89fd-4ba1-bb89-1c55bac94d76",
   "metadata": {},
   "source": [
    "# Load Object Detection and Depth Estimation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c60ad-4721-4597-8850-c3ec4eaa65d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Models: Object Detection and Depth Estimation\n",
    "\n",
    "### YOLO Model to Detect Trees ###\n",
    "# Load a pretrained YOLO model that detects trees\n",
    "model1_name = 'tree-detector-yolov5x-oct2323-autoarborist-25epochs'\n",
    "model1_path = f'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5/runs/train/{model1_name}/weights/last.pt'\n",
    "tree_model = torch.hub.load(r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/yolov5', 'custom', path=model1_path, source='local')\n",
    "tree_model.conf = 0.25  # confidence threshold (0-1)\n",
    "\n",
    "# Paths for MonoDepth2 Encoder and Decoder\n",
    "# https://github.com/nianticlabs/monodepth2\n",
    "encoder_path = \"C:/users/talake2/Desktop/monodepth2/models/mono+stereo_1024x320/encoder.pth\"\n",
    "depth_decoder_path = \"C:/users/talake2/Desktop/monodepth2/models/mono+stereo_1024x320/depth.pth\"\n",
    "\n",
    "# Load ZoeDepth Model\n",
    "# ZoeD_K\n",
    "conf = get_config(\"zoedepth\", \"infer\", config_version=\"kitti\", config_mode=\"eval\")\n",
    "model_zoe_k = build_model(conf)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "zoe = model_zoe_k.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16f6118-a40b-4f6c-b7ee-0577a53fdf0a",
   "metadata": {},
   "source": [
    "# Load Tree Inventory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b33ae0-8f2e-4c05-90c4-6359f5b10c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geolocation Inputs: Tree Inventories and Panoramic Image\n",
    "\n",
    "### Tree Inventory ###\n",
    "# Read in Tree Inventory .csv file containing 'latitude' and 'longitude' columns information on tree locations\n",
    "tree_inventory_df = pd.read_csv(r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/auto_arborist_tfrecords_data/auto_arborist_tfrecords_csv/tfrecords_locs_all.csv')\n",
    "# Create a GeoDataFrame from the tree_inventory_df\n",
    "tree_geometry = [Point(lon, lat) for lon, lat in zip(tree_inventory_df['Longitude'], tree_inventory_df['Latitude'])]\n",
    "tree_gdf = gpd.GeoDataFrame(tree_inventory_df, geometry=tree_geometry)\n",
    "\n",
    "\n",
    "### Google Street View Panoramic Images ###\n",
    "# Define directory containing panoramic images and .JSON metadata files\n",
    "testing_city = r'sioux-falls'\n",
    "img_folder = f'C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-testing-tiny/{testing_city}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13795e0e-2469-45fc-ae44-0bd38a7bf5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77e36418-6784-476e-89f2-dac5e7facc92",
   "metadata": {},
   "source": [
    "# Load Image Classifier (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebcef0-7f85-4863-b5f6-24b39f8d746b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97446ad-b251-4dc9-9e64-2d04431239ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a Basic Model for Image Classification\n",
    "\n",
    "import torch.nn as nn # contains base class for all neural network modules\n",
    "import torch.nn.functional as F #https://pytorch.org/docs/stable/nn.functional.html contains common functions for training NNs (convolutions, losses, etc..)\n",
    "import torchvision # version 0.16.2\n",
    "\n",
    "class ImageClassificationBase(nn.Module): # https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
    "    # Define a base class with functionality for model training, validation, and evaluation per epoch\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images) # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        acc = accuracy(out, labels) # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7866c-b5ba-4bad-8276-e970c6f8e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a CNN Model using ResNet50\n",
    "class ResNet50ImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained ResNet model\n",
    "        self.network = torchvision.models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V2')\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = 25 # Set number of output classes\n",
    "        in_features = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    \n",
    "    \n",
    "# # Define a CNN Model using EfficientNetV2-S\n",
    "class EfficientNetImageClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained EfficientNetV2-L Model\n",
    "        self.network = torchvision.models.efficientnet_v2_s(pretrained=True)\n",
    "        # Modify the final fully connected layer to match the number of classes in your dataset\n",
    "        num_classes = 25 # Set number of output classes\n",
    "        in_features = self.network.classifier[1].in_features\n",
    "        self.network.classifier = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81a53e-9c82-4f5b-ad36-c8be84e9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function and class to load data to GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\" Set Device to GPU or CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"Move data to the device\"\n",
    "    if isinstance(data,(list,tuple)):\n",
    "        return [to_device(x,device) for x in data]\n",
    "    return data.to(device,non_blocking = True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n",
    "    \n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\" Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b,self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        \"\"\" Number of batches \"\"\"\n",
    "        return len(self.dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e36d3-1f90-43c2-bb23-df9d6776f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model_path = r'C:\\Users\\talake2\\Desktop\\auto_arborist_cvpr2022_v015\\pytorch_cnn_classifier\\pytorch_cnn_autoarborist_inaturalist_models_march2024\\tree-classification-autoarb-25-genera-1000imgs-effnet2s-10epochs-lr001-march724\\last.pth'\n",
    "\n",
    "# Get GPU Device\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "# Instantiate the model with the same architecture as the model which parameters you saved\n",
    "model = EfficientNetImageClassification()\n",
    "\n",
    "#load the model to the device\n",
    "model = to_device(EfficientNetImageClassification(), device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval() # Call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6342b51-5882-4350-88d7-2c751c2768bf",
   "metadata": {},
   "source": [
    "# Apply classification on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169be2a-37aa-4736-ba06-bc6900ff103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classification on single image\n",
    "# Constant for classes    \n",
    "selected_genera = ['acer','ailanthus','betula','citrus','cupaniopsis','erythrina','fraxinus','gleditsia','juglans','juniperus',\n",
    "                   'magnolia','phoenix','picea','pinus','prunus','pseudotsuga','pyrus','quercus','rhus','sequoia','taxodium',\n",
    "                   'thuja','tilia','ulmus','washingtonia']\n",
    "\n",
    "img_path = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/auto_arborist_jpegs/jpegs_aerial_streetlevel_raw/all_cities_streetview/train/acer/streetlevel_4_7.jpg'\n",
    "img = imread(img_path)\n",
    "img.shape\n",
    "\n",
    "# Resize the image\n",
    "img = cv2.resize(img, (512, 512))\n",
    "\n",
    "# Convert image to tensor using torchvision.transforms.ToTensor()\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "img = transform(img) #Transforms image to [0-1] and channels first\n",
    "img = img.unsqueeze(0) #add first dimension of batch size\n",
    "img = img.cuda() #push to GPU\n",
    "\n",
    "# Predict on an image\n",
    "output = model(img)\n",
    "\n",
    "# Get the index of the maximum value in the output tensor\n",
    "predicted_class_index = torch.argmax(output)\n",
    "\n",
    "# Use the index to get the corresponding class label\n",
    "predicted_class_label = selected_genera[predicted_class_index.item()]\n",
    "\n",
    "print(\"Predicted Class Label:\", predicted_class_label)\n",
    "\n",
    "# Get the top 5 class predictions\n",
    "top5_probabilities, top5_indices = torch.topk(output, 5)\n",
    "\n",
    "# Convert indices to class labels\n",
    "top5_class_labels = [selected_genera[i] for i in top5_indices.squeeze().tolist()]\n",
    "\n",
    "print(\"Top 5 Predicted Class Labels:\", top5_class_labels)\n",
    "print(\"Top 5 Predicted Probabilities:\", top5_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95464e13-049f-40a3-9b57-874c23ce355e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apply classification with TenCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d54a0-9c42-43da-b902-7a97661dc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera to detect in google street view images\n",
    "selected_genera = ['acer', 'ailanthus', 'betula', 'citrus', 'cupaniopsis', 'erythrina', 'fraxinus', 'gleditsia',\n",
    "                   'juglans', 'juniperus', 'magnolia', 'phoenix', 'picea', 'pinus', 'prunus', 'pseudotsuga',\n",
    "                   'pyrus', 'quercus', 'rhus', 'sequoia', 'taxodium', 'thuja', 'tilia', 'ulmus', 'washingtonia']\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert to PIL Image\n",
    "    transforms.TenCrop(512),  # Apply TenCrop augmentation\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),  # Convert cropped images to tensor\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))(crop) for crop in crops]))  # Normalize each cropped image\n",
    "])\n",
    "\n",
    "img_path = r'C:/Users/talake2/Desktop/auto_arborist_cvpr2022_v015/auto_arborist_jpegs/jpegs_aerial_streetlevel_raw/all_cities_streetview/train/acer/streetlevel_4_7.jpg'\n",
    "img = imread(img_path)\n",
    "img.shape\n",
    "\n",
    "# Apply transformations: ten cropping, normalization\n",
    "cropped_imgs = transform(img)\n",
    "\n",
    "# Run CNN model prediction on each cropped image\n",
    "predictions = [] # A Tensor of 10 predictions, each with 25 class probabilities\n",
    "for cropped_img_tensor in cropped_imgs:\n",
    "    cropped_img_tensor = cropped_img_tensor.unsqueeze(0).cuda()  # add first dimension of batch size and push to GPU\n",
    "    output = model(cropped_img_tensor) # CNN prediction on image\n",
    "    predictions.append(output)\n",
    "\n",
    "# Aggregate/ average across 10 predictions from all crops\n",
    "aggregated_output = torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "# Get the softmax class probability for each genus\n",
    "class_probs = torch.softmax(aggregated_output, dim=1)\n",
    "\n",
    "# Get the argmax predicted class genus\n",
    "class_argmax = torch.argmax(aggregated_output).item()\n",
    "\n",
    "# From predicted class index, get genus name\n",
    "predicted_tree_genus = selected_genera[class_argmax]\n",
    "\n",
    "# Initialise a dictionary to hold the output genus probabilities\n",
    "genus_softmax_dict = {}\n",
    "for i, genus in enumerate(selected_genera):\n",
    "    genus_softmax_dict[f'{genus}_prob'] = class_probs[0][i].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c5a28-d0d4-4791-a4bc-6c640358a1d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65959b52-27ce-4167-82f9-b0e2fe302740",
   "metadata": {},
   "source": [
    "# Plotting Panoramic Image Locations and Tree Inventory Data on Satellite Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8a12d-61cc-4588-96f6-25d185204dfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Lines and Intersections\n",
    "from eomaps import Maps\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles\n",
    "%matplotlib inline\n",
    "\n",
    "panos_df = pd.DataFrame(columns=['Pano_ID', 'Pano_Origin_Lon', 'Pano_Origin_Lat'])\n",
    "\n",
    "# Iterate over each image in the directory.\n",
    "for img_name in os.listdir(img_folder):\n",
    "    if img_name.endswith('.jpg'):\n",
    "        \n",
    "        # Read Panoramic image and Metadata .JSON file, return image and metadata\n",
    "        pano_id, resolution, pano_lat, pano_lon, date, elevation = read_image_metadata(img_folder, img_name)\n",
    "\n",
    "        new_row = {\n",
    "        'Pano_ID': pano_id,\n",
    "        'Pano_Origin_Lon': pano_lon,\n",
    "        'Pano_Origin_Lat': pano_lat,\n",
    "        }\n",
    "                        \n",
    "        panos_df = pd.concat([panos_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "# Define the bounding box for the plotting area\n",
    "bbox = [\n",
    "    panos_df['Pano_Origin_Lon'].min() - 0.0003,\n",
    "    panos_df['Pano_Origin_Lon'].max() + 0.0003,\n",
    "    panos_df['Pano_Origin_Lat'].min() - 0.0003,\n",
    "    panos_df['Pano_Origin_Lat'].max() + 0.0003\n",
    "]\n",
    "\n",
    "# Crop the tree invenntory records to the bounding box where trees are predicted\n",
    "cropped_tree_inventory = tree_inventory_df[\n",
    "    (tree_inventory_df['Longitude'] >= bbox[0]) &\n",
    "    (tree_inventory_df['Longitude'] <= bbox[1]) &\n",
    "    (tree_inventory_df['Latitude'] >= bbox[2]) &\n",
    "    (tree_inventory_df['Latitude'] <= bbox[3])\n",
    "]\n",
    "\n",
    "# Convert panos_df to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(panos_df['Pano_Origin_Lon'], panos_df['Pano_Origin_Lat'])]\n",
    "panos_gdf = gpd.GeoDataFrame(panos_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Reproject pano gdf to meters\n",
    "panos_gdf_reproj = panos_gdf.to_crs(epsg=3395) # Reproject to UTM Zome 13N Meters 32613\n",
    "#panos_gdf_reproj.plot()\n",
    "\n",
    "# Create a 20 meter buffer around the tree_inventory_gdf points\n",
    "buffer_distance = 20  # in meters\n",
    "panos_gdf_reproj_buffer = panos_gdf_reproj.geometry.buffer(buffer_distance)\n",
    "panos_gdf_reproj_buffer_polygon = panos_gdf_reproj_buffer.geometry.unary_union\n",
    "#panos_gdf_reproj_buffer_polygon\n",
    "\n",
    "# Convert cropped_tree_inventory to a Geodataframe\n",
    "tree_geometry = [Point(xy) for xy in zip(cropped_tree_inventory['Longitude'], cropped_tree_inventory['Latitude'])]\n",
    "tree_inventory_gdf = gpd.GeoDataFrame(cropped_tree_inventory, geometry=tree_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "tree_inv_gdf_reproj = tree_inventory_gdf.to_crs(epsg=3395) # Reproject to UTM Zome 13N Meters\n",
    "#tree_inv_gdf_reproj.plot()\n",
    "\n",
    "# Subset tree inventory to within buffer distance of panoramic images\n",
    "tree_inv_within_panos = tree_inv_gdf_reproj[tree_inv_gdf_reproj.geometry.within(panos_gdf_reproj_buffer_polygon)]\n",
    "\n",
    "# Convert the tree_inventory_gdf to EPSG4326\n",
    "tree_inventory_gdf = tree_inv_within_panos.to_crs(epsg=4326)\n",
    "# Reset index\n",
    "tree_inventory_gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Plotting:\n",
    "# Define a map and extent\n",
    "m = Maps(crs=Maps.CRS.Mercator.GOOGLE, figsize=(20, 20))\n",
    "m.set_extent((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "\n",
    "# Plot the GeoDataFrame onto the map\n",
    "m.add_gdf(panos_gdf, marker='x', color='blue', alpha=0.80, markersize = 250, label='Panoramic Points')\n",
    "m.add_gdf(tree_inventory_gdf, marker='^', color='orange', alpha=0.80, markersize = 250, label='Tree Inventory')\n",
    "m.add_wms.ESRI_ArcGIS.SERVICES.World_Imagery.add_layer.xyz_layer()\n",
    "\n",
    "# Show the map\n",
    "#m.savefig(f\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-ailanthus-testing-cities-results/{testing_city}/{testing_city}-geolocation-ailanthus-map.png\")\n",
    "m.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab02515-1066-481f-983b-bb2e0f66c08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36ed1822-5a32-4d16-8122-5c504c6cfc79",
   "metadata": {},
   "source": [
    "# Run Initial Tree Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e558bb-0f40-4300-9d5b-7a0948b73d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store resulting data from tree detection and initial geolocation\n",
    "tree_geolocation_results_df = pd.DataFrame(columns=['Pano_ID', 'Pano_Origin_Lon', 'Pano_Origin_Lat', 'Est_Tree_Lon', 'Est_Tree_Lat', 'Predicted_Genus', 'Pano_Tree_Angle', 'Est_Depth', 'Bbox_Area', 'Bbox_Aspect'])\n",
    "\n",
    "# Multiply depth estimates by 3.0 to correct for scale distortion in equirectangular panoramic images\n",
    "DEPTH_SCALING_FACTOR = 3.0 # Default scaling factor, seems to work decent for close-trees but not for far-trees\n",
    "\n",
    "# Iterate over each image in the directory.\n",
    "for img_name in os.listdir(img_folder):\n",
    "    if img_name.endswith('.jpg'):\n",
    "        \n",
    "        # Read Panoramic image and Metadata .JSON file, return image and metadata\n",
    "        img, width, pano_id, pano_rotation_value, pano_lat, pano_lon = read_panoramic_image_and_metadata(img_folder, img_name)\n",
    "\n",
    "        print(f\"Running Tree Detection and Initial Geolocation on: {pano_id}\")\n",
    "\n",
    "        # Apply YOLO model to detect all trees in image\n",
    "        model_results = tree_model(img) # Run YOLO Inference\n",
    "        model_results_df = model_results.pandas().xyxy[0] # Store YOLO results\n",
    "\n",
    "        # Subset trees from YOLO model by detection heuristics: bounding box size, aspect ratio, confidence\n",
    "        top_detection_results = process_yolo_results(model_results_df, 3)\n",
    "        print(top_detection_results)\n",
    "\n",
    "        if top_detection_results is not None: # if trees are detected in the image:\n",
    "            \n",
    "            # Depth Estimation with ZoeDepth\n",
    "            metric_depth_resized_zoe = zoe.infer_pil(img)\n",
    "\n",
    "            # Geolocate all detected trees\n",
    "            for index, row in top_detection_results.iterrows():\n",
    "\n",
    "                # Get bounding box for detected tree in the image\n",
    "                xmin, ymin, xmax, ymax = (\n",
    "                    int(row['xmin']),\n",
    "                    int(row['ymin']),\n",
    "                    int(row['xmax']),\n",
    "                    int(row['ymax'])\n",
    "                )\n",
    "                \n",
    "                # Run Ten-Crop CNN Model Classification on Detected Tree\n",
    "                predicted_genus, genus_softmax_dict = predict_genus_tencrop_cnn(img, model, xmin, ymin, xmax, ymax)\n",
    "\n",
    "                # Crop the depth map to the tree matched from panoramic image to inventory\n",
    "                cropped_depth = metric_depth_resized_zoe[ymin:ymax, xmin:xmax]\n",
    "\n",
    "                # Estimate depth as the median of the depthmap\n",
    "                est_tree_depth = np.median(cropped_depth) * DEPTH_SCALING_FACTOR\n",
    "\n",
    "                # Get index and rotation (0-360 degrees) for detected tree in the panoramic image\n",
    "                tree_rotation_value = calculate_pano_tree_angle(row, width, pano_rotation_value)\n",
    "                \n",
    "                # Geolocate tree given pano origin, distance, and bearing\n",
    "                est_tree_lat, est_tree_lon = get_point_at_distance(pano_lat, pano_lon, est_tree_depth, tree_rotation_value)\n",
    "\n",
    "                # Capture outputs for each predicted tree as a new_row in a dataframe\n",
    "                new_row = {\n",
    "                    'Pano_ID': pano_id,\n",
    "                    'Pano_Origin_Lon': pano_lon,\n",
    "                    'Pano_Origin_Lat': pano_lat,\n",
    "                    'Est_Tree_Lon': est_tree_lon,\n",
    "                    'Est_Tree_Lat': est_tree_lat,\n",
    "                    'Predicted_Genus': predicted_genus,\n",
    "                    'Pano_Tree_Angle': tree_rotation_value,\n",
    "                    'Est_Depth': est_tree_depth,\n",
    "                    'Bbox_Area': row['area'],\n",
    "                    'Bbox_Aspect': row['aspect_ratio']\n",
    "                }\n",
    "\n",
    "                # Extend the new_row dictionary with predicted genus softmax values\n",
    "                new_row.update(genus_softmax_dict)\n",
    "\n",
    "                # Concatenate results to output dataframe\n",
    "                tree_geolocation_results_df = pd.concat([tree_geolocation_results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        else: print(\"No trees detected in the image.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af1c33-8842-4edb-8aad-d8cd051f1827",
   "metadata": {},
   "source": [
    "# Initial Tree Geolocation Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894c868-08f1-494c-8e6a-2d79415b6d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "tree_geolocation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712e3ee-486b-47a0-9ff9-eca5e3805e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export initial geolocation estimates as .csv\n",
    "tree_geolocation_results_df.to_csv(f\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-testing-tiny/{testing_city}-initial-tree-detection-geolocation-results-argmax-genus.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda46a5-8444-4970-bad0-9d1e436f0017",
   "metadata": {},
   "source": [
    "# Plot Initial Geolocation Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df5c83-c3f9-41ba-94f8-07b62eaa9d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Lines and Intersections\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the bounding box for the plotting area\n",
    "bbox = [\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].max() + 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].max() + 0.0003\n",
    "]\n",
    "\n",
    "# Crop the tree invenntory records to the bounding box where trees are predicted\n",
    "cropped_tree_inventory = tree_inventory_df[\n",
    "    (tree_inventory_df['Longitude'] >= bbox[0]) &\n",
    "    (tree_inventory_df['Longitude'] <= bbox[1]) &\n",
    "    (tree_inventory_df['Latitude'] >= bbox[2]) &\n",
    "    (tree_inventory_df['Latitude'] <= bbox[3])\n",
    "]\n",
    "\n",
    "\n",
    "# Convert panos_df to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(tree_geolocation_results_df['Pano_Origin_Lon'], tree_geolocation_results_df['Pano_Origin_Lat'])]\n",
    "panos_gdf = gpd.GeoDataFrame(tree_geolocation_results_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert cropped_tree_inventory to a Geodataframe\n",
    "tree_geometry = [Point(xy) for xy in zip(cropped_tree_inventory['Longitude'], cropped_tree_inventory['Latitude'])]\n",
    "tree_inventory_gdf = gpd.GeoDataFrame(cropped_tree_inventory, geometry=tree_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "# Define unique colors for each predicted genus\n",
    "unique_genera = tree_geolocation_results_df['Predicted_Genus'].unique()\n",
    "num_colors = len(unique_genera)\n",
    "color_map = plt.cm.get_cmap('tab10', num_colors)  # You can choose any colormap here\n",
    "\n",
    "# Create a dictionary mapping predicted genera to colors\n",
    "genus_color_dict = {genus: color_map(i) for i, genus in enumerate(unique_genera)}\n",
    "\n",
    "# Convert estimated tree geolocations to a Geodataframe - categorize by detected class (here: trees and ailanthus)\n",
    "tree_est_geometry = [Point(xy) for xy in zip(tree_geolocation_results_df['Est_Tree_Lon'], tree_geolocation_results_df['Est_Tree_Lat'])]\n",
    "tree_est_gdf = gpd.GeoDataFrame(tree_geolocation_results_df, geometry=tree_est_geometry, crs=\"EPSG:4326\")\n",
    "# Apply colors based on predicted genus\n",
    "tree_est_gdf['color'] = tree_est_gdf['Predicted_Genus'].map(genus_color_dict)\n",
    "\n",
    "\n",
    "# Define a map and extent\n",
    "m = Maps(crs=Maps.CRS.Mercator.GOOGLE, figsize=(20, 20))\n",
    "m.set_extent((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "\n",
    "# Plot the GeoDataFrame onto the map\n",
    "m.add_gdf(panos_gdf, marker='x', color='blue', alpha=0.75, markersize = 300, label='Panoramic Points')\n",
    "m.add_gdf(tree_inventory_gdf, marker='^', color='orange', alpha=0.75, markersize = 300, label='Tree Inventory')\n",
    "m.add_gdf(tree_est_gdf, marker='.', color=tree_est_gdf['color'], alpha=1.0, markersize=600, label='Estimated Tree Geolocation')\n",
    "\n",
    "\n",
    "m.add_wms.ESRI_ArcGIS.SERVICES.World_Imagery.add_layer.xyz_layer()\n",
    "\n",
    "# Show and save the map\n",
    "#m.savefig(f\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-testing-cities-results/{testing_city}-initial-tree-geolocation-estimates.png\")\n",
    "m.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65002d4-dfb7-4105-b641-bfafb4b9972e",
   "metadata": {},
   "source": [
    "# Geolocate Trees with Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc40c1-2f98-42b2-8f13-2b396d3c818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lines from panoramic image origin to estimated tree location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6a4ca-83c7-49a2-a99c-4e870cd36784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lines from Panoramic Image to Detected Tree\n",
    "\n",
    "# Distance of line from origin to detected tree (meters)\n",
    "line_distance = 20\n",
    "\n",
    "# Group the tree_geolocation_results_df by Pano_ID and apply LineString to each group\n",
    "panos_grouped = tree_geolocation_results_df.groupby('Pano_ID').apply(lambda x:[extend_lines(row, line_distance) for idx, row in x.iterrows()])\n",
    "\n",
    "# Each line connects the panoramic image origin to the estimated tree location\n",
    "lines = []\n",
    "for sublist in panos_grouped:\n",
    "    for line in sublist:\n",
    "        lines.append(line)\n",
    "        \n",
    "print(f'Created', len(lines), \"lines between panoramic image and detected trees\")\n",
    "\n",
    "# Create a GeoDataFrame from the lines\n",
    "lines_gdf = gpd.GeoDataFrame(geometry=lines, columns=['geometry'], crs=\"EPSG:4326\")\n",
    "\n",
    "# Combine the detected and classified trees with lines\n",
    "combined_geolocation_lines = pd.concat([tree_geolocation_results_df, lines_gdf], axis=1)\n",
    "combined_geolocation_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8357d4-01c2-43ae-bf59-146a6f604356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09f8f9f0-763e-402e-b20a-ce1f1199b14e",
   "metadata": {},
   "source": [
    "# Triangulate lines to create intersections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7783ce2-a664-4866-8306-763d5ad6560a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty DataFrame to store outputs\n",
    "triangulated_tree_detections = pd.DataFrame(columns=['Intersection', 'Pano_ID_1', 'Pano_Origin_Lon_1', 'Pano_Origin_Lat_1', \n",
    "                                   'Est_Depth_1', 'Pano_ID_2', 'Pano_Origin_Lon_2', \n",
    "                                   'Pano_Origin_Lat_2', 'Est_Depth_2'])\n",
    "\n",
    "tolerance = 1e-6  # Tolerance for overlapping intersections based on location coordinates\n",
    "\n",
    "# Iterate through all detected trees and triangulate detected trees\n",
    "for i in range(len(combined_geolocation_lines)):\n",
    "    # Get the origin of the current line\n",
    "    origin = combined_geolocation_lines.geometry[i].coords[0]\n",
    "    for j in range(i+1, len(combined_geolocation_lines)):\n",
    "        if combined_geolocation_lines.geometry[i].intersects(combined_geolocation_lines.geometry[j]): # If the two lines intersect\n",
    "            intersection_point = combined_geolocation_lines.geometry[i].intersection(combined_geolocation_lines.geometry[j]) # Get the intersection point\n",
    "            # Check if intersection is not the origin of the current line and the other line\n",
    "            if (abs(intersection_point.x - origin[0]) > tolerance or abs(intersection_point.y - origin[1]) > tolerance) and \\\n",
    "               (abs(intersection_point.x - lines[j].coords[0][0]) > tolerance or abs(intersection_point.y - lines[j].coords[0][1]) > tolerance):\n",
    "                           \n",
    "                # Get Pano ID and Location For Intersection Point 1\n",
    "                pano_i_id = combined_geolocation_lines.iloc[i]['Pano_ID']\n",
    "                pano_i_lon = combined_geolocation_lines.iloc[i]['Pano_Origin_Lon']\n",
    "                pano_i_lat = combined_geolocation_lines.iloc[i]['Pano_Origin_Lat']\n",
    "                est_depth_i = combined_geolocation_lines.iloc[i]['Est_Depth']\n",
    "                \n",
    "                # Get Pano ID and Location For Intersection Point 2\n",
    "                pano_j_id = combined_geolocation_lines.iloc[j]['Pano_ID']\n",
    "                pano_j_lon = combined_geolocation_lines.iloc[j]['Pano_Origin_Lon']\n",
    "                pano_j_lat = combined_geolocation_lines.iloc[j]['Pano_Origin_Lat']\n",
    "                est_depth_j = combined_geolocation_lines.iloc[j]['Est_Depth']\n",
    "                \n",
    "                # Get the class probabilities for image i and j\n",
    "                pano_i_genus_probs = combined_geolocation_lines.iloc[i, 10:35] # Probabilities for 25 classes of tree genera prediction from CNN model\n",
    "                pano_j_genus_probs = combined_geolocation_lines.iloc[j, 10:35] # Probabilities for 25 classes of tree genera prediction from CNN model\n",
    "                \n",
    "                # Combine and average the class probabilities\n",
    "                combined_probs = pano_i_genus_probs.add(pano_j_genus_probs)\n",
    "                average_genus_probs = combined_probs / 2\n",
    "                \n",
    "                # Append the data to the output DataFrame\n",
    "                output_data = {\n",
    "                    'Intersection': intersection_point,\n",
    "                    'Pano_ID_1': pano_i_id, \n",
    "                    'Pano_Origin_Lon_1': pano_i_lon, \n",
    "                    'Pano_Origin_Lat_1': pano_i_lat, \n",
    "                    'Est_Depth_1': est_depth_i,\n",
    "                    'Pano_ID_2': pano_j_id, \n",
    "                    'Pano_Origin_Lon_2': pano_j_lon, \n",
    "                    'Pano_Origin_Lat_2': pano_j_lat, \n",
    "                    'Est_Depth_2': est_depth_j,\n",
    "                    **average_genus_probs.to_dict()  # Convert average_genus_probs to a dictionary and unpack into the DataFrame\n",
    "                }\n",
    "                triangulated_tree_detections = pd.concat([triangulated_tree_detections, pd.DataFrame([output_data])], ignore_index=True)\n",
    "\n",
    "                \n",
    "# Convert to a GeoDataFrame\n",
    "intersection_geometry = [Point(xy) for xy in triangulated_tree_detections['Intersection']]\n",
    "triangulated_tree_detections_gdf = gpd.GeoDataFrame(triangulated_tree_detections, geometry=intersection_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "triangulated_tree_detections_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee99e02a-678d-4cf9-a799-d47cc8bcf949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaca5e5-bc62-448f-b1f1-2c4bce5e9bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f6bcdfa-0f3b-434e-8512-4f5799e38edf",
   "metadata": {},
   "source": [
    "# Plot Triangulated Geolocation Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc645fa7-2992-4e4c-b758-e108b9f0ca55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Lines and Intersections\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the bounding box for the plotting area\n",
    "bbox = [\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].max() + 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].max() + 0.0003\n",
    "]\n",
    "\n",
    "# Crop the tree invenntory records to the bounding box where trees are predicted\n",
    "cropped_tree_inventory = tree_inventory_df[\n",
    "    (tree_inventory_df['Longitude'] >= bbox[0]) &\n",
    "    (tree_inventory_df['Longitude'] <= bbox[1]) &\n",
    "    (tree_inventory_df['Latitude'] >= bbox[2]) &\n",
    "    (tree_inventory_df['Latitude'] <= bbox[3])\n",
    "]\n",
    "\n",
    "\n",
    "# Define a map and extent\n",
    "m = Maps(crs=Maps.CRS.Mercator.GOOGLE, figsize=(20, 20))\n",
    "m.set_extent((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "\n",
    "# Plot the GeoDataFrames onto the map\n",
    "# Ground Truth Tree Inventory and Street View Image Locations\n",
    "m.add_gdf(panos_gdf, marker='x', color='blue', alpha=0.80, markersize = 350, label='Panoramic Points')\n",
    "m.add_gdf(tree_inventory_gdf, marker='^', color='orange', alpha=0.80, markersize = 350, label='Tree Inventory')\n",
    "m.add_gdf(tree_est_gdf, marker='.', color=tree_est_gdf['color'], alpha=1.0, markersize=700, label='Estimated Tree Geolocation')\n",
    "\n",
    "# Plot triangulared intersections\n",
    "m.add_gdf(triangulated_tree_detections_gdf, marker='*', color='red', alpha=0.7, markersize = 400, label='Triangulated Intersections')\n",
    "m.add_gdf(lines_gdf, color='black', alpha=0.7, label='Lines from Panoramic Images to Detected Trees')\n",
    "\n",
    "m.add_wms.ESRI_ArcGIS.SERVICES.World_Imagery.add_layer.xyz_layer()\n",
    "\n",
    "# Show and save the map\n",
    "#m.savefig(f\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-ailanthus-testing-cities-results/{testing_city}/{testing_city}-initial-tree-geolocation-estimates-ailanthus-yolo.png\")\n",
    "m.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6258aa-e75b-4e1d-beca-fd329819855b",
   "metadata": {},
   "source": [
    "# Find Estimated Tree Locations Near Intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b0fd1-efea-4505-9e88-a0a69f491b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KDTree to search for nearest neighbor search of intersection points by estimated tree locations\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "# Create a KD-Tree from the estimated tree locations to query against the intersections\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html\n",
    "tree_points = tree_geolocation_results_df[['Est_Tree_Lon', 'Est_Tree_Lat']].values\n",
    "tree_points_kdtree = KDTree(tree_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e053ae-1504-42f9-b4fa-d24a92c8c735",
   "metadata": {},
   "source": [
    "# Filter Intersections Less Than MaxDist from Estimated Tree Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4707922b-b948-4fdf-982c-a7a5cb7a27e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5bc8db-2cfc-4d17-a6a1-d6a21a496d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filter intersections based on distance ('maxdist') between estimated tree locations\n",
    "filtered_intersections = []\n",
    "\n",
    "# This dictionary will store the index of tree positions as keys and the \n",
    "# shortest distance to an assigned intersection and its point as values\n",
    "assigned_positions = {}\n",
    "\n",
    "# Define a maximum distance (meters) to search for intersections near two estimated tree geolocations\n",
    "# If no intersections are found within (maxdist) of estimated tree locations, discard those intersections\n",
    "#tree_geolocation_results_df['maxdist'] = 3 + (0.65 * tree_geolocation_results_df['Est_Depth'])\n",
    "tree_geolocation_results_df['maxdist'] = 5\n",
    "\n",
    "for point in range(len(triangulated_tree_detections_gdf.geometry)):\n",
    "    intersection_point = triangulated_tree_detections_gdf.geometry[point]\n",
    "    distances, indices = tree_points_kdtree.query((intersection_point.x, intersection_point.y), 2)\n",
    "    distances_meters = distances * 111139  # Convert distances to meters\n",
    "    \n",
    "    # Loop through each of the closest tree position indices to this intersection\n",
    "    for i, index in enumerate(indices):\n",
    "        # Proceed only if the distance is within the max distance criteria.\n",
    "        if distances_meters.max() <= tree_geolocation_results_df.loc[indices, 'maxdist'].max():\n",
    "            # If this position is already assigned\n",
    "            if index in assigned_positions:\n",
    "                # Check if the current intersection is closer than the previously assigned one\n",
    "                if distances_meters[i] < assigned_positions[index]['distance']:\n",
    "                    # Update the stored distance and intersection point for this position\n",
    "                    assigned_positions[index] = {'distance': distances_meters[i], 'intersection': intersection_point}\n",
    "            else:\n",
    "                # If it's not already assigned, assign this intersection to this tree position\n",
    "                assigned_positions[index] = {'distance': distances_meters[i], 'intersection': intersection_point}\n",
    "\n",
    "                \n",
    "# After iterating through all intersections, add the assigned intersection points to filtered_intersections\n",
    "for _, info in assigned_positions.items():\n",
    "    # Add unique intersection points to the filtered list (checking existing points to avoid duplicates)\n",
    "    if info['intersection'] not in filtered_intersections:\n",
    "        filtered_intersections.append(info['intersection'])\n",
    "\n",
    "df_intersections_filtered = pd.DataFrame([(point.x, point.y) for point in filtered_intersections], columns=['Lon', 'Lat'])\n",
    "\n",
    "print(f'Filtering intersections to:', tree_geolocation_results_df['maxdist'][0], \"meters from at least two estimated tree locations.\")\n",
    "print(f\"Intersections before filtering:\", len(triangulated_tree_detections_gdf.geometry))\n",
    "print(f\"Intersections after filtering:\", len(filtered_intersections))\n",
    "\n",
    "\n",
    "# Convert the list of Point objects to a GeoSeries\n",
    "filtered_intersections_series = gpd.GeoSeries(filtered_intersections)\n",
    "\n",
    "# Filter the triangulated_tree_detections_gdf to keep only the rows with 'Intersection' points present in filtered_intersections\n",
    "filtered_tree_detections_gdf = triangulated_tree_detections_gdf[triangulated_tree_detections_gdf['geometry'].isin(filtered_intersections_series)]\n",
    "\n",
    "# Convert to geodataframe\n",
    "filtered_intersection_geometry = [Point(xy) for xy in filtered_tree_detections_gdf['Intersection']]\n",
    "filtered_triangulated_tree_detections_gdf = gpd.GeoDataFrame(filtered_tree_detections_gdf, geometry=filtered_intersection_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "print(filtered_triangulated_tree_detections_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17634b11-a6da-4f3d-a9c1-c8a5c6d65c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6910bd8-537c-4626-baa5-697b808be8d5",
   "metadata": {},
   "source": [
    "# Plot Triangulated Geolocation Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8cd9eb-bec5-45c0-8d86-e00bd21ef0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Lines and Intersections\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the bounding box for the plotting area\n",
    "bbox = [\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].max() + 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].max() + 0.0003\n",
    "]\n",
    "\n",
    "# Crop the tree invenntory records to the bounding box where trees are predicted\n",
    "cropped_tree_inventory = tree_inventory_df[\n",
    "    (tree_inventory_df['Longitude'] >= bbox[0]) &\n",
    "    (tree_inventory_df['Longitude'] <= bbox[1]) &\n",
    "    (tree_inventory_df['Latitude'] >= bbox[2]) &\n",
    "    (tree_inventory_df['Latitude'] <= bbox[3])\n",
    "]\n",
    "\n",
    "\n",
    "# Define a map and extent\n",
    "m = Maps(crs=Maps.CRS.Mercator.GOOGLE, figsize=(20, 20))\n",
    "m.set_extent((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "\n",
    "# Plot the GeoDataFrames onto the map\n",
    "# Ground Truth Tree Inventory and Street View Image Locations\n",
    "m.add_gdf(panos_gdf, marker='x', color='blue', alpha=0.80, markersize = 350, label='Panoramic Points')\n",
    "m.add_gdf(tree_inventory_gdf, marker='^', color='orange', alpha=0.80, markersize = 350, label='Tree Inventory')\n",
    "m.add_gdf(tree_est_gdf, marker='.', color=tree_est_gdf['color'], alpha=1.0, markersize=700, label='Estimated Tree Geolocation')\n",
    "\n",
    "# Plot triangulared intersections\n",
    "m.add_gdf(filtered_triangulated_tree_detections_gdf, marker='*', color='red', alpha=0.7, markersize = 400, label='Triangulated Intersections')\n",
    "m.add_gdf(lines_gdf, color='black', alpha=0.7, label='Lines from Panoramic Images to Detected Trees')\n",
    "\n",
    "m.add_wms.ESRI_ArcGIS.SERVICES.World_Imagery.add_layer.xyz_layer()\n",
    "\n",
    "# Show and save the map\n",
    "#m.savefig(f\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-ailanthus-testing-cities-results/{testing_city}/{testing_city}-initial-tree-geolocation-estimates-ailanthus-yolo.png\")\n",
    "m.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cca1b5-aef9-4f68-97d3-7d64ea8e2677",
   "metadata": {},
   "source": [
    "# Classify Tree Genus From Filtered Trianguled Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4486afb-ae73-4eb8-add0-a68631633929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "filtered_triangulated_tree_detections_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577f1fe-94ec-49dd-96df-93a274215976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the columns ending with '_prob'\n",
    "prob_columns = [col for col in filtered_triangulated_tree_detections_gdf.columns if col.endswith('_prob')]\n",
    "\n",
    "# Plot bar plots for each of the selected columns\n",
    "filtered_triangulated_tree_detections_gdf[prob_columns].plot(kind='bar', figsize=(12, 6))\n",
    "plt.xlabel('Genus')  # Set x-axis label\n",
    "plt.ylabel('Probability')  # Set y-axis label\n",
    "plt.title('Probability of Each Genus')  # Set plot title\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.legend(loc='upper right')  # Show legend\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376aa684-dcb2-478d-97dd-7cd13fd2e8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822dc472-4318-4229-b548-2cd2570c50e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b39c81-150a-4227-bc94-2c0e850ddd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8190672d-9c80-4067-a3d4-33eafeb2ce93",
   "metadata": {},
   "source": [
    "# Apply Clustering to Group Adjacent Intersections based on Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe19d40-3781-453e-871e-521328298cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Hierarchical Clustering Based on Distance to Remaining Intersections/ Geolocated Tree Estimates\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# https://scikit-learn.org/stable/modules/clustering.html\n",
    "\n",
    "final_tree_coordinates = []\n",
    "\n",
    "# Convert the filtered intersection points to numpy array\n",
    "intersection_points = np.array([(point.x, point.y) for point in filtered_intersections])\n",
    "\n",
    "# Perform hierarchical clustering on the intersection points\n",
    "# Distance threshold is in lat/long distances. \n",
    "# 10 meters/ 111139 = 9e-5\n",
    "# 3 meters/ 111139 = 2.7e-5 Used by Lumnitz et al. 2021.\n",
    "clustering = AgglomerativeClustering(distance_threshold=2.7e-5, n_clusters=None).fit(intersection_points)\n",
    "\n",
    "# Assign cluster labels to each intersection point\n",
    "cluster_labels = clustering.labels_\n",
    "\n",
    "# Create a dictionary to store the cluster centers\n",
    "cluster_centers = {}\n",
    "\n",
    "# Organize the intersection points into clusters in the cluster_centers dictionary\n",
    "for i, point in enumerate(intersection_points):\n",
    "    if cluster_labels[i] not in cluster_centers:\n",
    "        cluster_centers[cluster_labels[i]] = []\n",
    "        cluster_centers[cluster_labels[i]].append((point[0], point[1]))\n",
    "        \n",
    "# Calculate the average location for each cluster and appends it to the final_tree_coordinates list\n",
    "for cluster_label in cluster_centers:\n",
    "    cluster_points = np.array(cluster_centers[cluster_label])\n",
    "    average_location = np.mean(cluster_points, axis=0)\n",
    "    final_tree_coordinates.append(average_location)\n",
    "\n",
    "# # Convert the final tree coordinates back to DataFrame\n",
    "df_final_tree_coordinates = pd.DataFrame(final_tree_coordinates, columns=['Lon', 'Lat'])\n",
    "\n",
    "# Convert final geolocated trees to a Geodataframe\n",
    "geolocated_trees_geometry = [Point(xy) for xy in zip(df_final_tree_coordinates['Lon'], df_final_tree_coordinates['Lat'])]\n",
    "geolocated_trees_gdf = gpd.GeoDataFrame(df_final_tree_coordinates, geometry=geolocated_trees_geometry, crs=\"EPSG:4326\")\n",
    "geolocated_trees_gdf_reproj = geolocated_trees_gdf.to_crs(epsg=3395)\n",
    "\n",
    "\n",
    "print(f\"Applying Hierarchical Clustering to Geolocated Intersection Points\")\n",
    "print(f\"Intersections before clustering:\", len(filtered_intersections))\n",
    "print(f\"Intersections after clustering:\", len(df_final_tree_coordinates))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851c44d-846d-47e2-8c16-c9b5913be996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geolocated_trees_gdf_reproj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa728513-f108-41a4-ab5e-46040ea6daae",
   "metadata": {},
   "source": [
    "# Assign Predicted Genus to Final Geolocated Tree Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8eba8c-198c-41dd-ab50-d7c8c9befb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geolocated_trees_gdf # Contains final geolocated trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d0534-466c-445b-ba50-ad0f7ad92425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree_est_gdf # Contains initial geolocation estimates with predicted genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278a47b-44f2-4d02-a789-31a02b78a10a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Contains final geolocated tree coordinates\n",
    "# Reproject to meters\n",
    "geolocated_trees_gdf_reproj = geolocated_trees_gdf.to_crs(epsg=3395) # Reproject to meters\n",
    "\n",
    "# Create a meter buffer around the tree_inventory_gdf points\n",
    "buffer_distance = 5  # in meters\n",
    "geolocated_trees_gdf_reproj_buffer = geolocated_trees_gdf_reproj.geometry.buffer(buffer_distance)\n",
    "\n",
    "# Contains initial geolocation estimates with predicted genus\n",
    "# Reproject to meters\n",
    "tree_est_gdf_reproj = tree_est_gdf.to_crs(epsg=3395)# Reproject to meters\n",
    "\n",
    "# Iterate over each buffer around geolocated trees\n",
    "for idx, buffer_tree in enumerate(geolocated_trees_gdf_reproj_buffer):\n",
    "    # Get initial geolocated tree estimates within buffer around final geolocated tree\n",
    "    tree_est_in_geolocated = tree_est_gdf_reproj[tree_est_gdf_reproj.geometry.within(buffer_tree)]\n",
    "    # Count the number of predicted genera near each final geolocated tree, and get most frequently predicted genus\n",
    "    top_predicted_genera = tree_est_in_geolocated['Predicted_Genus'].value_counts().idxmax()\n",
    "    # Assign the predicted genus to the final geolocated tree geodataframe\n",
    "    geolocated_trees_gdf.loc[idx, 'Assigned_Genus'] = top_predicted_genera\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c362e-5379-4e62-8f08-1756c08066b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211f52e-c201-462a-806f-b7d168f32e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea003879-07f3-415d-b24f-a1ac72e5c975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f59089-19c8-4ae4-be2b-169ba87431e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919a78c5-a86f-45a5-a8ca-e02f43cb6417",
   "metadata": {},
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Final Geolocated Tree Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d670b30-4d80-4a9b-a259-fc6e6e8afd5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Lines and Intersections\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the bounding box for the plotting area\n",
    "bbox = [\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].max() + 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].max() + 0.0003\n",
    "]\n",
    "\n",
    "# Crop the tree invenntory records to the bounding box where trees are predicted\n",
    "cropped_tree_inventory = tree_inventory_df[\n",
    "    (tree_inventory_df['Longitude'] >= bbox[0]) &\n",
    "    (tree_inventory_df['Longitude'] <= bbox[1]) &\n",
    "    (tree_inventory_df['Latitude'] >= bbox[2]) &\n",
    "    (tree_inventory_df['Latitude'] <= bbox[3])\n",
    "]\n",
    "\n",
    "\n",
    "# Define a map and extent\n",
    "m = Maps(crs=Maps.CRS.Mercator.GOOGLE, figsize=(20, 20))\n",
    "m.set_extent((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "\n",
    "\n",
    "# Define unique colors for each predicted genus\n",
    "unique_genera = geolocated_trees_gdf['Assigned_Genus'].unique()\n",
    "num_colors = len(unique_genera)\n",
    "color_map = plt.cm.get_cmap('tab10', num_colors)  # You can choose any colormap here\n",
    "\n",
    "# Create a dictionary mapping predicted genera to colors\n",
    "genus_color_dict = {genus: color_map(i) for i, genus in enumerate(unique_genera)}\n",
    "\n",
    "# Apply colors based on predicted genus\n",
    "geolocated_trees_gdf['color'] = geolocated_trees_gdf['Assigned_Genus'].map(genus_color_dict)\n",
    "\n",
    "# Plot the GeoDataFrame onto the map\n",
    "m.add_gdf(panos_gdf, marker='x', color='blue', alpha=0.75, markersize = 300, label='Panoramic Points')\n",
    "m.add_gdf(tree_inventory_gdf, marker='^', color='orange', alpha=0.75, markersize = 300, label='Tree Inventory')\n",
    "m.add_gdf(tree_est_gdf, marker='.', color=tree_est_gdf['color'], alpha=0.75, markersize=300, label='Estimated Tree Geolocation')\n",
    "m.add_gdf(geolocated_trees_gdf, marker='o', color=geolocated_trees_gdf['color'], alpha=0.75, markersize = 500, label='Triangulated Intersections')\n",
    "m.add_wms.ESRI_ArcGIS.SERVICES.World_Imagery.add_layer.xyz_layer()\n",
    "\n",
    "# Show the map\n",
    "#m.savefig(f'C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-testing-cities-results/{testing_city}-tree-geolocation-results-pre-matching.png')\n",
    "m.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21080c4-a334-43d6-86cf-5061f4127604",
   "metadata": {},
   "source": [
    "# Tree Geolocation Model Evaluation by Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec02c1b-8122-4328-9f95-e6ba3c2dcd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def greedy_matching(tree_inventory_gdf, geolocated_trees_gdf, max_distance=15):\n",
    "    \"\"\"\n",
    "    Greedy algorithm to match closest trees and calculate RMSE.\n",
    "    Args:\n",
    "        tree_inventory_gdf (gpd.GeoDataFrame): ground truth tree locations.\n",
    "        geolocated_trees_gdf (gpd.GeoDataFrame): predicted tree locations.\n",
    "        max_distance (float): maximum distance to consider a match as valid (in meters).\n",
    "    Returns:\n",
    "        (list of tuple): List of matched pairs (ground_truth_index, prediction_index).\n",
    "        (gpd.GeoDataFrame): Dataframe of true positive matches with their distances.\n",
    "        (float): RMSE of the matched pairs.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    distances = []\n",
    "    squared_distances = []\n",
    "    for idx1, tree1 in tree_inventory_gdf.iterrows():\n",
    "        closest_tree = None\n",
    "        closest_dist = float('inf')\n",
    "        for idx2, tree2 in geolocated_trees_gdf.iterrows():\n",
    "            dist = calculate_distance(tree1.geometry, tree2.geometry)\n",
    "            if dist < closest_dist:\n",
    "                closest_dist = dist\n",
    "                closest_tree = idx2\n",
    "        if closest_tree is not None and closest_dist <= max_distance:\n",
    "            matches.append((idx1, closest_tree))\n",
    "            distances.append(closest_dist)\n",
    "            squared_distances.append(closest_dist ** 2)  # Square the distance for RMSE calculation\n",
    "            geolocated_trees_gdf = geolocated_trees_gdf.drop(closest_tree)\n",
    "            \n",
    "    true_positive_matches = tree_inventory_gdf.loc[[idx1 for idx1, idx2 in matches]]\n",
    "    true_positive_matches['distance'] = [dist ** 0.5 for dist in squared_distances]  # Store sqrt(distance) which is the actual distance\n",
    "    rmse = np.sqrt(np.mean(squared_distances)) if squared_distances else None\n",
    "    mae = np.mean(distances) if distances else None\n",
    "    return matches, true_positive_matches, rmse, mae\n",
    "\n",
    "# Assuming tree_inventory_gdf and geolocated_trees_gdf are your ground truth and prediction GeoDataFrames respectively\n",
    "matches, true_positives_gdf, rmse, mae = greedy_matching(tree_inventory_gdf, geolocated_trees_gdf, max_distance=15)\n",
    "\n",
    "print(f\"Number of true positive matches: \", len(matches), \"out of total inventory trees: \", len(tree_inventory_gdf))\n",
    "print(f\"Root Mean Square Error (RMSE) between geolocated trees and inventory trees : {rmse:.2f} meters\")\n",
    "print(f\"Mean Absolute Error (MAE) between geolocated trees and inventory trees : {mae:.2f} meters\")\n",
    "\n",
    "# Get Geolocated Trees that Match with Ground Truth \n",
    "matched_predictions_indices = [pred for _, pred in matches]\n",
    "matched_predictions_gdf = geolocated_trees_gdf.loc[matched_predictions_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e6e1b-49fa-458a-90cc-abb933321015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6d081-3e5b-4d04-915b-fa0658806598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create histogram\n",
    "plt.hist(list(true_positives_gdf['distance']), bins=100, range=(0, 30), color='blue', edgecolor='black');\n",
    "plt.title(f'Distance From Matched Geolocated Tree to Ground Truth in {testing_city}');\n",
    "plt.xlabel('Distance (meters)');\n",
    "plt.ylabel('Frequency');\n",
    "#plt.savefig(f'C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-evaluation/geolocation-panos-testing-cities-tree-detection-results/{testing_city}_matched_geolocated_trees_distance_ground_truth.png')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9f9e3-43ac-4270-9f54-0135d2eec000",
   "metadata": {},
   "source": [
    "# Plot final geolocation estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f080f-bc50-4181-8709-3bbdf8268672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Pano Locations, Estimated Tree Locations, Lines and Intersections\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.io import img_tiles\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the bounding box for the plotting area\n",
    "bbox = [\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lon'].max() + 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].min() - 0.0003,\n",
    "    tree_geolocation_results_df['Est_Tree_Lat'].max() + 0.0003\n",
    "]\n",
    "\n",
    "# Crop the tree invenntory records to the bounding box where trees are predicted\n",
    "cropped_tree_inventory = tree_inventory_df[\n",
    "    (tree_inventory_df['Longitude'] >= bbox[0]) &\n",
    "    (tree_inventory_df['Longitude'] <= bbox[1]) &\n",
    "    (tree_inventory_df['Latitude'] >= bbox[2]) &\n",
    "    (tree_inventory_df['Latitude'] <= bbox[3])\n",
    "]\n",
    "\n",
    "\n",
    "# Convert panos_df to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(tree_geolocation_results_df['Pano_Origin_Lon'],  tree_geolocation_results_df['Pano_Origin_Lat'])]\n",
    "panos_gdf = gpd.GeoDataFrame(tree_geolocation_results_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert cropped_tree_inventory to a Geodataframe\n",
    "tree_geometry = [Point(xy) for xy in zip(cropped_tree_inventory['Longitude'], cropped_tree_inventory['Latitude'])]\n",
    "tree_inventory_gdf = gpd.GeoDataFrame(cropped_tree_inventory, geometry=tree_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert estimated tree geolocations to a Geodataframe\n",
    "tree_est_geometry = [Point(xy) for xy in zip(tree_geolocation_results_df['Est_Tree_Lon'], tree_geolocation_results_df['Est_Tree_Lat'])]\n",
    "tree_est_gdf = gpd.GeoDataFrame(tree_geolocation_results_df, geometry=tree_est_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert geolocated trees to a Geodataframe\n",
    "geolocated_trees_geometry = [Point(xy) for xy in zip(df_final_tree_coordinates['Lon'], df_final_tree_coordinates['Lat'])]\n",
    "geolocated_trees_gdf = gpd.GeoDataFrame(df_final_tree_coordinates, geometry=geolocated_trees_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "# Define a map and extent\n",
    "m = Maps(crs=Maps.CRS.Mercator.GOOGLE, figsize=(20, 20))\n",
    "m.set_extent((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
    "\n",
    "# Plot the GeoDataFrame onto the map\n",
    "m.add_gdf(panos_gdf, marker='x', color='blue', alpha=0.75, markersize = 300, label='Panoramic Points')\n",
    "m.add_gdf(tree_inventory_gdf, marker='^', color='orange', alpha=0.75, markersize = 300, label='Tree Inventory')\n",
    "m.add_gdf(matched_predictions_gdf, marker='.', color='purple', alpha=0.75, markersize = 300, label='Matched Geolocated Trees')\n",
    "m.add_wms.ESRI_ArcGIS.SERVICES.World_Imagery.add_layer.xyz_layer()\n",
    "\n",
    "# Show the map\n",
    "#m.savefig(f\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-evaluation/geolocation-panos-testing-cities-tree-detection-results/{testing_city}-tree-geolocation-results-final.png\")\n",
    "m.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b40b8e1-61d1-4611-baa9-8883299b2b00",
   "metadata": {},
   "source": [
    "# Exports as .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f05f2b-a41b-4379-a75e-87ce7af2b4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and format geolocation summary statistics for export\n",
    "\n",
    "# Define the values for the geolocation summary statistics\n",
    "city = testing_city\n",
    "num_inventory_trees = len(cropped_tree_inventory)\n",
    "num_matched_trees = len(matched_predictions_gdf)\n",
    "freq_matched_trees = num_matched_trees / num_inventory_trees\n",
    "min_geo_distance = np.min(list(true_positives_gdf['distance']))\n",
    "max_geo_distance = np.max(list(true_positives_gdf['distance']))\n",
    "mean_geo_distance = np.mean(list(true_positives_gdf['distance']))\n",
    "median_geo_distance = np.median(list(true_positives_gdf['distance']))\n",
    "avg_distance_pano_to_tree = np.mean(closest_distances)\n",
    "\n",
    "# Create a dictionary with the summary statistics\n",
    "summary_stats = {\n",
    "    \"Region\": [city],\n",
    "    \"Number of inventory trees\": [num_inventory_trees],\n",
    "    \"Number of matched trees\": [num_matched_trees],\n",
    "    \"Error distance (RMSE)\": [rmse],\n",
    "    \"Frequency of matched trees\": [freq_matched_trees],\n",
    "    \"Minimum geolocation distance\": [min_geo_distance],\n",
    "    \"Maximum geolocation distance\": [max_geo_distance],\n",
    "    \"Mean geolocation distance\": [mean_geo_distance],\n",
    "    \"Median geolocation distance\": [median_geo_distance],\n",
    "    \"Average distance from pano to tree\": [avg_distance_pano_to_tree]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "summary_df.to_csv(f'C:/Users/talake2/Desktop/tree-geolocation/geolocation-panos-testing-cities-results/{testing_city}_geolocation_summary.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd2b2b-e8c8-46e0-8d52-d3b7a2b6cb50",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate Data Metrics: Nearest Neighbor Distances (Pano-Pano, Tree-Tree, Pano-Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c683b31-c176-417c-8e1c-4d808e02d9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "panos_df = pd.DataFrame(columns=['Pano_ID', 'Pano_Origin_Lon', 'Pano_Origin_Lat'])\n",
    "\n",
    "# Iterate over each image in the directory.\n",
    "for img_name in os.listdir(img_folder):\n",
    "    if img_name.endswith('.jpg'):\n",
    "        \n",
    "        # Read Panoramic image and Metadata .JSON file, return image and metadata\n",
    "        img, width, pano_id, pano_rotation_value, pano_lat, pano_lon = read_panoramic_image_and_metadata(img_folder, img_name)\n",
    "\n",
    "        new_row = {\n",
    "        'Pano_ID': pano_id,\n",
    "        'Pano_Origin_Lon': pano_lon,\n",
    "        'Pano_Origin_Lat': pano_lat,\n",
    "        }\n",
    "                        \n",
    "        panos_df = pd.concat([panos_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "        \n",
    "\n",
    "# Convert panos_df to a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(panos_df['Pano_Origin_Lon'], panos_df['Pano_Origin_Lat'])]\n",
    "panos_gdf = gpd.GeoDataFrame(panos_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Convert cropped_tree_inventory to a Geodataframe\n",
    "tree_geometry = [Point(xy) for xy in zip(cropped_tree_inventory['Longitude'], cropped_tree_inventory['Latitude'])]\n",
    "tree_inventory_gdf = gpd.GeoDataFrame(cropped_tree_inventory, geometry=tree_geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "# Reproject to CRS that measures distances in meters (World Mercator)\n",
    "pano_gdf = panos_gdf.to_crs(epsg=3395)  # World Mercator\n",
    "\n",
    "# Extract the x and y coordinates of each point\n",
    "pano_coordinates = np.array(list(pano_gdf.geometry.apply(lambda geom: (geom.x, geom.y))))\n",
    "\n",
    "# Create a cKDTree for efficient spatial querying\n",
    "tree = cKDTree(pano_coordinates)\n",
    "\n",
    "# Query the nearest neighbor for each point (excluding itself). k=2 returns the first and second nearest neighbors, but we exclude the first as it is the point itself.\n",
    "distances, _ = tree.query(pano_coordinates, k=2)\n",
    "# distances contains two columns, where the second column is the distance to the nearest neighbor since the first is the distance to itself (zero)\n",
    "\n",
    "# Get all nearest-neighbor distances\n",
    "nearest_neighbor_distances = distances[:, 1]\n",
    "\n",
    "# Calculate the average distance among the nearest neighbors\n",
    "average_pano_pano_distance = np.mean(distances[:, 1]) # We select the second column corresponding to nearest neighbors\n",
    "min_pano_pano_distance = np.max(distances[:, 1])\n",
    "max_pano_pano_distance = np.min(distances[:, 1])\n",
    "\n",
    "print(f\"Average distance of panoramic images to the nearest neighbor: {average_pano_pano_distance} meters\")\n",
    "print(f\"Max distance of panoramic images to the nearest neighbor: {min_pano_pano_distance} meters\")\n",
    "print(f\"Min distance of panoramic images to the nearest neighbor: {max_pano_pano_distance} meters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e118f-e4bf-41d0-8ece-cb718a4e6e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assuming panos_gdf is your GeoDataFrame with Point geometries\n",
    "# Ensure it is in a projected CRS that measures distances in meters (World Mercator)\n",
    "inventory_gdf = tree_inventory_gdf.to_crs(epsg=3395)  # World Mercator\n",
    "\n",
    "# Extract the x and y coordinates of each point\n",
    "inv_coordinates = np.array(list(inventory_gdf.geometry.apply(lambda geom: (geom.x, geom.y))))\n",
    "\n",
    "# Create a cKDTree for efficient spatial querying\n",
    "tree = cKDTree(inv_coordinates)\n",
    "\n",
    "# Query the nearest neighbor for each point (excluding itself). k=2 returns the first and second nearest neighbors, but we exclude the first as it is the point itself.\n",
    "distances, _ = tree.query(inv_coordinates, k=2)\n",
    "# distances contains two columns, where the second column is the distance to the nearest neighbor since the first is the distance to itself (zero)\n",
    "\n",
    "# Get all nearest-neighbor distances\n",
    "nearest_neighbor_distances = distances[:, 1]\n",
    "\n",
    "# Calculate the average distance among the nearest neighbors\n",
    "average_tree_tree_distance = np.mean(distances[:, 1]) # We select the second column corresponding to nearest neighbors\n",
    "min_tree_tree_distance = np.max(distances[:, 1])\n",
    "max_tree_tree_distance = np.min(distances[:, 1])\n",
    "\n",
    "print(f\"Average distance of tree inventory to the nearest neighbor: {average_tree_tree_distance} meters\")\n",
    "print(f\"Max distance of tree inventory to the nearest neighbor: {min_tree_tree_distance} meters\")\n",
    "print(f\"Min distance of tree inventory to the nearest neighbor: {max_tree_tree_distance} meters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9144808-64c5-42df-9a8b-24fce9b82a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b991aec4-fcc6-4daa-ba84-d8fbeff80dc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Build a spatial index (cKDTree) for 'inventory_gdf' coordinates\n",
    "inventory_tree = cKDTree(inv_coordinates)\n",
    "\n",
    "# For each point in 'panos_gdf', find the distance to the nearest point in 'inventory_gdf'\n",
    "distances, _ = inventory_tree.query(pano_coordinates, k=1)\n",
    "\n",
    "# Calculate the average distance between 'panos_gdf' points and nearest 'inventory_gdf' points\n",
    "average_pano_tree_distance = np.mean(distances)\n",
    "median_pano_tree_distance = np.median(distances)\n",
    "min_pano_tree_distance = np.min(distances)\n",
    "max_pano_tree_distance = np.max(distances)\n",
    "\n",
    "\n",
    "print(f\"Average nearest neighbor distance from panoramic images to inventory items: {average_pano_tree_distance} meters\")\n",
    "print(f\"Median nearest neighbor distance from panoramic images to inventory items: {median_pano_tree_distance} meters\")\n",
    "print(f\"Min nearest neighbor distance from panoramic images to inventory items: {min_pano_tree_distance} meters\")\n",
    "print(f\"Max nearest neighbor distance from panoramic images to inventory items: {max_pano_tree_distance} meters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7df151-3312-4475-a0d5-29ec3f306bc7",
   "metadata": {},
   "source": [
    "# Inspect Panoramic Imagery Dimensions for Potential Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9376b9-9909-4c1b-8a0a-d157966010b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect Panoramic Imagery Dimensions for Potential Issues\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "panos_dir = r\"C:/Users/talake2/Desktop/tree-geolocation/geolocation-pano-testing-cities\"\n",
    "\n",
    "# Dictionary to store counts of images for each size\n",
    "image_counts = {}\n",
    "\n",
    "# For every directory in panos_dir\n",
    "for folder in os.listdir(panos_dir):\n",
    "    folder_path = os.path.join(panos_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"Folder Name: {folder}\")\n",
    "        image_counts[folder] = {}\n",
    "        json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "        \n",
    "        # Iterate through all .json files\n",
    "        for json_file in json_files:\n",
    "            json_path = os.path.join(folder_path, json_file)\n",
    "            with open(json_path, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "                resolution = metadata.get('resolution', {})\n",
    "                width = resolution.get('width', None)\n",
    "                height = resolution.get('height', None)\n",
    "                dimensions = (width, height)\n",
    "                pano_id = metadata.get('panoId', None)\n",
    "                date = metadata.get('date', None)\n",
    "                   \n",
    "                # Check if width is not 16384\n",
    "                if width != 16384:\n",
    "                    print(f\"PanoID: {pano_id}, Width: {width}, Height: {height}\")\n",
    "                    print(f\"Date: {date}\")\n",
    "                \n",
    "                # Count number of .json files for each size\n",
    "                if dimensions not in image_counts[folder]:\n",
    "                    image_counts[folder][dimensions] = 1\n",
    "                else:\n",
    "                    image_counts[folder][dimensions] += 1\n",
    "\n",
    "# Summarize folder name, number of files in each folder, and number of files of each size (width, height)\n",
    "for folder, counts in image_counts.items():\n",
    "    print(f\"\\nFolder Name: {folder}\")\n",
    "    print(\"Number of files in folder:\", sum(counts.values()))\n",
    "    for size, count in counts.items():\n",
    "        print(f\"File Size: {size}, Count: {count}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd91001-cfe0-47b7-bdc2-18643ee5112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TreeGeo-torch",
   "language": "python",
   "name": "tree_geolocation_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
